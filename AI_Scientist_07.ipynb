{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPDvpmnsVbAAnj+50aQGjw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173_Fall2025/blob/main/AI_Scientist_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ],
      "metadata": {
        "id": "b_7ZtOqzuPlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ],
      "metadata": {
        "id": "T1MqPE_puPYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Module 6: Advanced Topics**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Biology, Health and the Environment](https://sciences.utsa.edu/bhe/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 6 Material\n",
        "\n",
        "* Part 6.1: Reenforcement Learning\n",
        "* **Part 6.2: AI-Scientist**\n",
        "* Part 6.3: Generative AI\n",
        "* Part 6.4: Text to Images with Stable Diffusion\n"
      ],
      "metadata": {
        "id": "KO49Tsxzue8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ],
      "metadata": {
        "id": "Kod6uWwDu8nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You must run this cell first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    # from google.colab import auth\n",
        "    # auth.authenticate_user()\n",
        "    COLAB = True\n",
        "    print(\"Note: Using Google CoLab\")\n",
        "    # import requests\n",
        "    # gcloud_token = !gcloud auth print-access-token\n",
        "    # gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    # print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this lesson.\")\n",
        "    COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g7XGhn1ggT_",
        "outputId": "74ac3419-75f6-4ea3-8541-d58ec8734f86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: Using Google CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your GMAIL address is included as the last line in the output above."
      ],
      "metadata": {
        "id": "KWgr-KEzvFQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Packages"
      ],
      "metadata": {
        "id": "Kf1wbBeqiidz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "\n",
        "import importlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# List of packages to check and install if necessary\n",
        "packages = {\n",
        "    \"anthropic\": \"anthropic\",\n",
        "    \"aider-chat\": \"aider_chat\",\n",
        "    \"backoff\": \"backoff\",\n",
        "    \"openai\": \"openai\",\n",
        "    \"google-generativeai\": \"google.generativeai\",\n",
        "    \"pypdf\": \"PyPDF2\",\n",
        "    \"pymupdf4llm\": \"pymupdf4llm\",\n",
        "    \"torch\": \"torch\",\n",
        "    \"numpy\": \"numpy\",\n",
        "    \"transformers\": \"transformers\",\n",
        "    \"datasets\": \"datasets\",\n",
        "    \"tiktoken\": \"tiktoken\",\n",
        "    \"wandb\": \"wandb\",\n",
        "    \"tqdm\": \"tqdm\"\n",
        "}\n",
        "\n",
        "# Function to install missing packages\n",
        "for package, module in packages.items():\n",
        "    try:\n",
        "        importlib.import_module(module)\n",
        "        print(f\"'{package}' is already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"'{package}' is not installed. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s3Hxwtwihjz",
        "outputId": "36c411b3-0a6c-4d32-aaeb-8daad06b0cbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'anthropic' is not installed. Installing...\n",
            "'aider-chat' is not installed. Installing...\n",
            "'backoff' is already installed.\n",
            "'openai' is already installed.\n",
            "'google-generativeai' is already installed.\n",
            "'pypdf' is not installed. Installing...\n",
            "'pymupdf4llm' is not installed. Installing...\n",
            "'torch' is already installed.\n",
            "'numpy' is already installed.\n",
            "'transformers' is already installed.\n",
            "'datasets' is not installed. Installing...\n",
            "'tiktoken' is already installed.\n",
            "'wandb' is already installed.\n",
            "'tqdm' is already installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Latex"
      ],
      "metadata": {
        "id": "PLViGwuWkd-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y texlive texlive-latex-extra texlive-fonts-recommended dvipng\n",
        "!sudo apt-get install -y chktex\n"
      ],
      "metadata": {
        "id": "8hAQesZnkdlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI-Scientist Project by SakanaAI**\n",
        "\n",
        "The **AI-Scientist project** by SakanaAI is an ambitious initiative aimed at automating the entire scientific research process. It leverages advanced **Large Language Models (LLMs)** and other AI technologies to independently conduct research, from generating ideas to writing full scientific papers.\n",
        "\n"
      ],
      "metadata": {
        "id": "LHLlCwFJnq6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Key"
      ],
      "metadata": {
        "id": "hZy1cW0IURtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the OpenAI API key and store it in a variable\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the OpenAI API key and store it in a variable\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_KEY')\n",
        "\n",
        "# Ensure that the API key is correctly set\n",
        "if not OPENAI_API_KEY:\n",
        "    raise ValueError(\"OpenAI API key is not set. Please check if you have stored the API key in userdata.\")"
      ],
      "metadata": {
        "id": "cHsw65BoURdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uXl7NealYFJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install GitHub AI-Scientist**"
      ],
      "metadata": {
        "id": "n4QPVySIikYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!apt-get install git -y\n",
        "!git clone https://github.com/SakanaAI/AI-Scientist.git\n",
        "%cd AI-Scientist\n",
        "!cp -r /content/AI-Scientist/* /content/\n",
        "!ls /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7JP2hOWif9y",
        "outputId": "5079eea9-5b7c-4beb-c823-1797e3b97b6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Cloning into 'AI-Scientist'...\n",
            "remote: Enumerating objects: 2638, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 2638 (delta 3), reused 1 (delta 1), pack-reused 2628 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2638/2638), 116.87 MiB | 13.42 MiB/s, done.\n",
            "Resolving deltas: 100% (464/464), done.\n",
            "Updating files: 100% (2319/2319), done.\n",
            "/content/AI-Scientist\n",
            "ai_scientist  docs\t      experimental\t   README.md\t\treview_iclr_bench\n",
            "AI-Scientist  drive\t      launch_scientist.py  requirements.txt\tsample_data\n",
            "data\t      example_papers  LICENSE\t\t   review_ai_scientist\ttemplates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "~~~text\n",
        "Reading package lists... Done\n",
        "Building dependency tree... Done\n",
        "Reading state information... Done\n",
        "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
        "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
        "Cloning into 'AI-Scientist'...\n",
        "remote: Enumerating objects: 2638, done.\n",
        "remote: Counting objects: 100% (10/10), done.\n",
        "remote: Compressing objects: 100% (9/9), done.\n",
        "remote: Total 2638 (delta 3), reused 1 (delta 1), pack-reused 2628 (from 2)\n",
        "Receiving objects: 100% (2638/2638), 116.87 MiB | 34.45 MiB/s, done.\n",
        "Resolving deltas: 100% (464/464), done.\n",
        "Updating files: 100% (2319/2319), done.\n",
        "/content/AI-Scientist/AI-Scientist\n",
        "ai_scientist  docs\t      experimental\t   README.md\t\treview_iclr_bench\n",
        "AI-Scientist  drive\t      launch_scientist.py  requirements.txt\tsample_data\n",
        "data\t      example_papers  LICENSE\t\t   review_ai_scientist\ttemplates\n",
        "\n",
        "~~~"
      ],
      "metadata": {
        "id": "eCrHdt-pFt05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z-FGk8N1ifoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ypeYhMdvOACz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RptHCHvuOJbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Jason Idea File**"
      ],
      "metadata": {
        "id": "lahDP7s2QHNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Idea file\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Example data (replace this with your actual \"ideas\" data)\n",
        "ideas = {\n",
        "      \"Name\": \"CNN analysis of non-coding genetic variants\",\n",
        "      \"Title\": \"Identifying Functional Non-Coding Variants\",\n",
        "      \"Experiment\": \"Use CNNs to predict the regulatory roles of non-coding genetic variants identified in GWAS.\",\n",
        "      \"Interestingness\": 9,\n",
        "      \"Feasibility\": 7,\n",
        "      \"Novelty\": 8\n",
        "}\n",
        "\n",
        "# Define the target directory\n",
        "output_dir = \"/content/AI-Scientist/templates/mobilenetV3/\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
        "\n",
        "# Define the full path for the output file\n",
        "output_file = os.path.join(output_dir, \"seed_ideas.json\")\n",
        "\n",
        "# Save the data as a JSON file\n",
        "with open(output_file, \"w\") as json_file:\n",
        "    json.dump(ideas, json_file, indent=4)\n",
        "\n",
        "print(f\"Your ideas have been saved to {output_file}!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkYKkEA1PlPF",
        "outputId": "903f0934-f18c-4d31-aa2e-60cd4fa4c549"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your ideas have been saved to /content/AI-Scientist/templates/mobilenetV3/seed_ideas.json!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Print out `seed_ideas_jason`**"
      ],
      "metadata": {
        "id": "GHznz3VvR7lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out jason file\n",
        "\n",
        "import json\n",
        "\n",
        "# Path to your JSON file (adjust the path as needed)\n",
        "file_path = '/content/AI-Scientist/templates/mobilenetV3/seed_ideas.json'\n",
        "\n",
        "# Open and load the JSON file\n",
        "with open(file_path, 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# Print the contents of the JSON file\n",
        "print(data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6LkoqWV3a7E",
        "outputId": "769c9cd5-7c24-42a9-9668-c75d0bfd463e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Name': 'CNN analysis of non-coding genetic variants', 'Title': 'Identifying Functional Non-Coding Variants', 'Experiment': 'Use CNNs to predict the regulatory roles of non-coding genetic variants identified in GWAS.', 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Jason Prompt File**"
      ],
      "metadata": {
        "id": "fnrOmur5XzlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prompt file\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Example data (replace this with your actual \"ideas\" data)\n",
        "prompt = {\n",
        "    \"system\": \"You are an ambitious AI PhD student who is looking to publish a paper that will contribute significantly to the field.\",\n",
        "    \"task_description\": \"You are given the following file to work with, which studies Convolutional neural networks by training CNN models on multiple GWAS datasets. Please come up with interesting experiments to investigate the best architectures for these convolutional networks.\"\n",
        "}\n",
        "\n",
        "# Define the target directory\n",
        "output_dir = \"/content/AI-Scientist/templates/mobilenetV3/\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
        "\n",
        "# Define the full path for the output file\n",
        "output_file = os.path.join(output_dir, \"prompt.json\")\n",
        "\n",
        "# Save the data as a JSON file\n",
        "with open(output_file, \"w\") as json_file:\n",
        "    json.dump(ideas, json_file, indent=4)\n",
        "\n",
        "print(f\"Your ideas have been saved to {output_file}!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f771f453-2011-4082-d54f-8c09f56af525",
        "id": "lTyeMCngXzlI"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your ideas have been saved to /content/AI-Scientist/templates/mobilenetV3/prompt.json!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Print out `prompt.json`**"
      ],
      "metadata": {
        "id": "gZmtgObzev4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out jason file\n",
        "\n",
        "import json\n",
        "\n",
        "# Path to your JSON file (adjust the path as needed)\n",
        "file_path = '/content/AI-Scientist/templates/mobilenetV3/prompt.json'\n",
        "\n",
        "# Open and load the JSON file\n",
        "with open(file_path, 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# Print the contents of the JSON file\n",
        "print(data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42752ea6-d023-4696-b0c9-5f3c727af35e",
        "id": "abLbA8509hIe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Name': 'CNN analysis of non-coding genetic variants', 'Title': 'Identifying Functional Non-Coding Variants', 'Experiment': 'Use CNNs to predict the regulatory roles of non-coding genetic variants identified in GWAS.', 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3zGR1f8VlALD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set key\n",
        "os.environ[\"OPENAI_API_KEY\"] ="
      ],
      "metadata": {
        "id": "QHPr9_1Lk_-l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Launch AI-Scientist\n",
        "\n",
        "~~~text\n",
        "colab_kernel_launcher.py [-h] [--skip-idea-generation] [--skip-novelty-check]\n",
        "                                [--experiment EXPERIMENT]\n",
        "                                [--model {claude-3-5-sonnet-20240620,claude-3-5-sonnet-20241022,gpt-4o-mini-2024-07-18,gpt-4o-2024-05-13,gpt-4o-2024-08-06,o1-preview-2024-09-12,o1-mini-2024-09-12,o1-2024-12-17,llama3.1-405b,bedrock/anthropic.claude-3-sonnet-20240229-v1:0,bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0,bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0,bedrock/anthropic.claude-3-haiku-20240307-v1:0,bedrock/anthropic.claude-3-opus-20240229-v1:0,vertex_ai/claude-3-opus@20240229,vertex_ai/claude-3-5-sonnet@20240620,vertex_ai/claude-3-5-sonnet-v2@20241022,vertex_ai/claude-3-sonnet@20240229,vertex_ai/claude-3-haiku@20240307,deepseek-chat,deepseek-coder,deepseek-reasoner,gemini-1.5-flash,gemini-1.5-pro}]\n",
        "                                [--writeup {latex}] [--parallel PARALLEL] [--improvement]\n",
        "                                [--gpus GPUS] [--num-ideas NUM_IDEAS]\n",
        "                                [--engine {semanticscholar,openalex}]\n",
        "~~~"
      ],
      "metadata": {
        "id": "izV8IuE5fQHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/AI-Scientist/launch_scientist.py \"--skip-novelty-check\" --experiment \"nanoGPT\" --model \"gpt-4o-2024-05-13\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL95GU1EoPHl",
        "outputId": "fd116526-e529-4573-edfe-bd6335f70f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPUs: [0]\n",
            "Using OpenAI API with model gpt-4o-2024-05-13.\n",
            "\n",
            "Generating idea 1/50\n",
            "Iteration 1/3\n",
            "{'Name': 'dynamic_layer_addition', 'Title': 'Dynamic Layer Addition: Progressive Transformer Complexity for Efficient Training', 'Experiment': 'Modify the training loop to dynamically add transformer layers at predefined intervals during training. Implement functions to seamlessly integrate new layers into the existing model without disrupting the ongoing training process. Compare the training dynamics, convergence speed, and final performance with a baseline model trained with a static architecture.', 'Interestingness': 8, 'Feasibility': 5, 'Novelty': 7}\n",
            "Iteration 2/3\n",
            "{'Name': 'dynamic_layer_addition', 'Title': 'Dynamic Layer Addition: Progressive Transformer Complexity for Efficient Training', 'Experiment': 'Modify the training loop to dynamically add transformer layers at predefined intervals during training (e.g., every 1000 iterations). Implement a function `add_layer_to_model` to add new layers to the existing model without disrupting the ongoing training process. Modify the `train` function to call this layer addition function at the specified intervals. Compare the training dynamics, convergence speed, and final performance with a baseline model trained with a static architecture. Use evaluation metrics such as training time, validation loss, and final test performance.', 'Interestingness': 8, 'Feasibility': 6, 'Novelty': 7}\n",
            "Idea generation converged after 2 iterations.\n",
            "\n",
            "Generating idea 2/50\n",
            "Iteration 1/3\n",
            "{'Name': 'attention_window', 'Title': 'Attention Window: Reducing Computational Complexity in Transformer Models', 'Experiment': 'Modify the CausalSelfAttention class to include an additional parameter for the window size. Update the attention mask to restrict attention to a fixed window of tokens. Compare the training and inference times, as well as the validation and test performance, with the baseline model.', 'Interestingness': 7, 'Feasibility': 7, 'Novelty': 6}\n",
            "Iteration 2/3\n",
            "{'Name': 'attention_window', 'Title': 'Attention Window: Reducing Computational Complexity in Transformer Models', 'Experiment': \"Modify the CausalSelfAttention class to include an additional parameter for the window size. Update the attention mask to restrict attention to a fixed window of tokens. Compare the training and inference times, as well as the validation and test performance, with the baseline model. Specifically, add a 'window_size' attribute to the CausalSelfAttention class and adjust the mask in the forward method to only consider tokens within this window. Use metrics such as training time per epoch, inference speed, and validation loss to evaluate the effectiveness.\", 'Interestingness': 7, 'Feasibility': 7, 'Novelty': 6}\n",
            "Idea generation converged after 2 iterations.\n",
            "\n",
            "Generating idea 3/50\n",
            "Iteration 1/3\n",
            "{'Name': 'dynamic_attention_span', 'Title': 'Dynamic Attention Span Adjustment for Efficient Transformer Models', 'Experiment': 'Modify the CausalSelfAttention class to include a dynamic mechanism for adjusting the attention span based on input sequence characteristics. Implement an auxiliary network that predicts the optimal attention span for each input sequence. Train this auxiliary network jointly with the main model. Compare the training dynamics, convergence speed, and final performance with the baseline model. Use metrics such as training time per epoch, inference speed, and validation loss to evaluate the effectiveness.', 'Interestingness': 9, 'Feasibility': 5, 'Novelty': 8}\n",
            "Iteration 2/3\n",
            "{'Name': 'dynamic_attention_span', 'Title': 'Dynamic Attention Span Adjustment for Efficient Transformer Models', 'Experiment': 'Modify the CausalSelfAttention class to include a heuristic-based mechanism for adjusting the attention span based on input sequence complexity. Implement a function to compute the complexity of the input sequence (e.g., token entropy) and adjust the attention span accordingly. Compare the training dynamics, convergence speed, and final performance with the baseline model. Use metrics such as training time per epoch, inference speed, and validation loss to evaluate the effectiveness.', 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}\n",
            "Iteration 3/3\n",
            "{'Name': 'dynamic_attention_span', 'Title': 'Dynamic Attention Span Adjustment for Efficient Transformer Models', 'Experiment': 'Modify the CausalSelfAttention class to include a heuristic-based mechanism for adjusting the attention span based on input sequence complexity. Implement a function to compute the complexity of the input sequence (e.g., token entropy) and adjust the attention span accordingly. Compare the training dynamics, convergence speed, and final performance with the baseline model. Use metrics such as training time per epoch, inference speed, and validation loss to evaluate the effectiveness.', 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}\n",
            "Idea generation converged after 3 iterations.\n",
            "\n",
            "Generating idea 4/50\n",
            "Iteration 1/3\n",
            "{'Name': 'curriculum_learning', 'Title': 'Curriculum Learning: Gradual Complexity Increase for Efficient Language Model Training', 'Experiment': 'Implement a curriculum learning strategy in the training loop. First, create a function to sort the dataset based on a complexity heuristic (e.g., sentence length or token entropy). Modify the get_batch function to start with simpler examples and gradually include more complex examples as training progresses. Compare the training dynamics, convergence speed, and final performance with a baseline model trained without curriculum learning. Use evaluation metrics such as training time per epoch, validation loss, and final test performance.', 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}\n",
            "Iteration 2/3\n",
            "{'Name': 'curriculum_learning', 'Title': 'Curriculum Learning: Gradual Complexity Increase for Efficient Language Model Training', 'Experiment': 'Implement a curriculum learning strategy in the training loop. First, create a function to sort the dataset based on a complexity heuristic, such as sentence length or token entropy. Modify the get_batch function to start with simpler examples and gradually include more complex examples as training progresses. Specifically, maintain a list of indices sorted by complexity and use slices of this list to fetch batches of increasing complexity. Compare the training dynamics, convergence speed, and final performance with a baseline model trained without curriculum learning. Use evaluation metrics such as training time per epoch, validation loss, and final test performance.', 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}\n",
            "Iteration 3/3\n",
            "{'Name': 'curriculum_learning', 'Title': 'Curriculum Learning: Gradual Complexity Increase for Efficient Language Model Training', 'Experiment': 'Implement a curriculum learning strategy in the training loop. First, create a function to sort the dataset based on a complexity heuristic, such as sentence length or token entropy. Modify the get_batch function to start with simpler examples and gradually include more complex examples as training progresses. Specifically, maintain a list of indices sorted by complexity and use slices of this list to fetch batches of increasing complexity. Compare the training dynamics, convergence speed, and final performance with a baseline model trained without curriculum learning. Use evaluation metrics such as training time per epoch, validation loss, and final test performance.', 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}\n",
            "Idea generation converged after 3 iterations.\n",
            "\n",
            "Generating idea 5/50\n",
            "Iteration 1/3\n",
            "{'Name': 'mixture_of_experts', 'Title': 'Mixture of Experts: Dynamic Expert Selection for Efficient Transformer Models', 'Experiment': 'Implement a mixture of experts (MoE) mechanism within the transformer architecture. Add a gating mechanism that dynamically selects a subset of transformer blocks (experts) to activate for each input sequence. Modify the forward pass to route the input through only the selected experts. Update the training loop to accommodate the MoE mechanism and compare the training dynamics, convergence speed, and final performance with the baseline model. Use metrics such as training time per epoch, inference speed, validation loss, and computational efficiency (e.g., FLOPs) to evaluate the effectiveness.', 'Interestingness': 9, 'Feasibility': 6, 'Novelty': 8}\n",
            "Iteration 2/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oBoQhpoafnD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -Fla /content/AI-Scientist/AI-Scientist/ai_scientist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXAWQdM2DCZi",
        "outputId": "83427c0b-315d-41ad-91f9-ccac1abc3a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Mar 24 21:41 ./\n",
            "drwxr-xr-x 3 root root 4096 Mar 24 21:41 ../\n",
            "drwxr-xr-x 3 root root 4096 Mar 24 21:41 templates/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yfpWvvbdN-38"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "18orCxP4IEio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}