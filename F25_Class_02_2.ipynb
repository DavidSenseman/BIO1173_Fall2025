{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173_Fall2025/blob/main/F25_Class_02_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZVwSpdbE3Y"
      },
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExN-OzpYbE3Y"
      },
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4imk1kbE3Y"
      },
      "source": [
        "##### **Module 2: Neural Networks with Tensorflow and Keras**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Biology, Health and the Environment](https://sciences.utsa.edu/bhe/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 2 Material\n",
        "\n",
        "* Part 2.1: Introduction to Neural Networks with Tensorflow and Keras\n",
        "* **Part 2.2: Encoding Feature Vectors**\n",
        "* Part 2.3: Early Stopping and Dropout to Prevent Overfitting\n",
        "* Part 2.4: Saving and Loading a Keras Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_-lPkxLbE3Z"
      },
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seXFCYH4LDUM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# You must run this cell first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    COLAB = True\n",
        "    print(\"Note: Using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this lesson.\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your GMAIL address is included as the last line in the output above."
      ],
      "metadata": {
        "id": "xG3_sXTDfyjA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdeDojEDbE3Z"
      },
      "source": [
        "## **Datasets for Class_02_2**\n",
        "\n",
        "For Class_02_2 we will be using the Wisconsin Breast Cancer dataset for the Examples and the Heart Disease dataset for the **Exercises**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "g9F_7m3ObE3Z"
      },
      "source": [
        "### **Breast Cancer Wisconsin (Diagnostic) Data Set**\n",
        "\n",
        "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)\n",
        "\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/breast_cancer.png)\n",
        "\n",
        "\n",
        "The average risk of developing breast cancer in the United States is 13%, or 1 in 8. Approximately 42,000 women in the US die from breast cancer each year. Like most cancers, early detection and treatment is singularily important in preventing mortallity.\n",
        "\n",
        "The Breast Cancer Wisconsin (BCW) dataset contains detailed microscopic measurements of cell nuclei obtained by fine needle aspirates (FNAs) from breast tumors found in 569 women. Some of these tumors were later determined to be **_malignant_** (cancerous), while other tumors were found to be **_benign_** (non-cancerous). Being able to differentiate cancerous from non-cancerous tumors is of obvious importance.  \n",
        "\n",
        "Fine needle aspiration (FNA), also called a fine needle aspiration biopsy, is a minimally invasive procedure that uses a thin needle and syringe to extract a sample of cells, tissue, or fluid from an abnormal area or lump in the body. The sample is then examined under a microscope to confirm a diagnosis or guide treatment.\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/fna_tech.png)\n",
        "\n",
        "\n",
        "The list of features computed from digitized images of breast mass cell nuclei obtained from by FNA in the Breast Cancer Wisconsing datasete are as follows:\n",
        "\n",
        "**Attribute Information:**\n",
        "\n",
        "* **ID number**\n",
        "* **Diagnosis:** (M = malignant, B = benign)\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "*  **radius:** (mean of distances from center to points on the perimeter)\n",
        "* **texture:** (standard deviation of gray-scale values)\n",
        "* **perimeter:**\n",
        "* **area:**\n",
        "* **smoothness:** (local variation in radius lengths)\n",
        "* **compactness:** (perimeter<sup>2</sup> / area - 1.0)\n",
        "* **concavity:** (severity of concave portions of the contour)\n",
        "* **concave points:** (number of concave portions of the contour)\n",
        "* **symmetry:**\n",
        "* **fractal dimension:** (\"coastline approximation\" - 1)\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three\n",
        "largest values) of these features were computed for each image,\n",
        "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
        "13 is Radius SE, field 23 is Worst Radius.1) ID number\n",
        "2) Diagnosis (M = malignant, B = benign)\n",
        "3-32)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlZI4yH4bE3Z"
      },
      "source": [
        "### **Heart Disease Dataset**\n",
        "\n",
        "[Heart Disease Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)\n",
        "\n",
        "\n",
        "![___](https://biologicslab.co/BIO1173/images/HD.jpg)\n",
        "\n",
        "**Description**\n",
        "\n",
        "Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Four out of 5CVD deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age. Heart failure is a common event caused by CVDs and this dataset contains 11 features that can be used to predict a possible heart disease.\n",
        "\n",
        "People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.\n",
        "\n",
        "* **Age:** age of the patient [years]\n",
        "* **Sex:** sex of the patient [M: Male, F: Female]\n",
        "* **ChestPainType:** chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n",
        "* **RestingBP:** resting blood pressure [mm Hg]\n",
        "* **Cholesterol:** serum cholesterol [mm/dl]\n",
        "* **FastingBS:** fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]\n",
        "* **RestingECG:** resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n",
        "* **MaxHR:** maximum heart rate achieved [Numeric value between 60 and 202]\n",
        "* **ExerciseAngina:** exercise-induced angina [Y: Yes, N: No]\n",
        "* **Oldpeak:** oldpeak = ST [Numeric value measured in depression]\n",
        "* **ST_Slope:** the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n",
        "* **HeartDisease:** output class [1: heart disease, 0: Normal]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVa1JySMbE3Z"
      },
      "source": [
        "# **Encoding a Feature Vector for Keras Deep Learning**\n",
        "\n",
        "In Module 4 we will take a closer look at some of the topics introduced previously in Module 3 (e.g., One-Hot Encoding).\n",
        "\n",
        "Neural networks can accept many types of data. We will continue our focus on tabular data, where there are well-defined rows and columns. This kind of data is what you would typically see in Microsoft Excel spreadsheet.\n",
        "\n",
        "Neural networks require numeric input. This numeric form is called a **_feature vector_**. Each input neurons receive one feature (or column) from this vector. Each row of training data typically becomes one vector.\n",
        "\n",
        "In this lesson, we will revist how to encode tabular data stored in a Pandas DataFrame into a feature vector that can be used by two types of neural networks: (1) classification and (2) regression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX3Hp1tybE3a"
      },
      "source": [
        "### Example 1 - Step 1: Read dataset and store values in a DataFrame\n",
        "\n",
        "Data is the essence of neural networks and deep learning. Neural networks are of little use until they have been trained on **large** datasets. Only by making repeated adjustments in the weights of their neural connections, during many rounds of training (epochs) on a particular dataset, can a neural network **learn** to make accurate predictions.  \n",
        "\n",
        "Not surprisingly, building and training neural networks begins with a dataset. The code in the cell below reads the Breast Cancer Wisconsin (BCW) dataset file, `wcbreast.csv`, on the course HTTPS server using the Pandas `pd.read_csv()` function:\n",
        "~~~text\n",
        "# Read file and create DataFrame\n",
        "bcwDF = pd.read_csv(\n",
        "    \"https://biologicslab.co/BIO1173/data/wcbreast.csv\",\n",
        "    index_col=0,\n",
        "    na_values=['NA','?'])\n",
        "~~~\n",
        "As the file is read, the function creates a new DataFrame called `bcwDF`. This name was chosen to remind us that the DataFrame contains the **b** reast **c** ancer **_w_** isconsin dataset.\n",
        "\n",
        "As a general rule, it is always a good idea to display at least part of your new DataFrame to make sure it was read correctly. Since large DataFrames can have many columns and many, many rows --too many to display in Jupyterlab -- it is helpful to specify the maximum number of rows and columns to display. This is accomplished in the cell below using this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', 4)\n",
        "pd.set_option('display.max_rows', 4)\n",
        "~~~\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmjrLkDwK1AM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Example 1 - Step 1: Read data and create dataframe\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Read file and create DataFrame\n",
        "bcwDF = pd.read_csv(\n",
        "    \"https://biologicslab.co/BIO1173/data/wcbreast.csv\",\n",
        "    index_col=0,\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', 4)\n",
        "pd.set_option('display.max_rows', 4)\n",
        "\n",
        "# Display DataFrame\n",
        "display(bcwDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19UPLcZQbE3a"
      },
      "source": [
        "If your code is correct you should see the following table:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04_1_Exm1B.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJTs4WQQbE3a"
      },
      "source": [
        "There are several observations that you should make from this table. First, looking at the very bottom you see:\n",
        "~~~text\n",
        "569 rows x 32 columns\n",
        "~~~\n",
        "This means that our DataFrame `bcwDF` has clinical information for `569` subjects (i.e. 1 row/subject) and that there are `32` clinical features (1 feature/column) recorded for each subject.\n",
        "\n",
        "By inspection, we can see at least one column, `diagnosis` has non-numerical values (the strings \"M\" and \"B\"), but there could be more, since we can only see a small fraction of the entire 32 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZy-feihbE3a"
      },
      "source": [
        "### Example 1 - Step 2: Display data types\n",
        "\n",
        "In order to create a feature vector, we need to know which columns in our DataFrame are non-numeric, i.e., which columns contains string values. We can easily print out the different data types in a DataFrame using the Pandas method `df.info`.   \n",
        "\n",
        "However, in order see **_all_** of the different data types, we need to change the number of rows to display. While we could simply set this option to `33`, (i.e. the number of columns in the DataFrame), here we used a slightly more elegant method using `len(bcwDF.columns)`. This code will automatically computer the number of columns for us.     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "lABXUQ8nbE3a"
      },
      "outputs": [],
      "source": [
        "# Example 1 - Step 2: Find data types\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Set max rows to the number of columns\n",
        "pd.set_option('display.max_rows', len(bcwDF.columns))\n",
        "\n",
        "# Print data types\n",
        "bcwDF.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8otBpc4rbE3a"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 569 entries, 0 to 568\n",
        "Data columns (total 32 columns):\n",
        " #   Column                   Non-Null Count  Dtype  \n",
        "---  ------                   --------------  -----  \n",
        " 0   id                       569 non-null    int64  \n",
        " 1   diagnosis                569 non-null    object\n",
        " 2   mean_radius              569 non-null    float64\n",
        " 3   mean_texture             569 non-null    float64\n",
        " 4   mean_perimeter           569 non-null    float64\n",
        " 5   mean_area                569 non-null    float64\n",
        " 6   mean_smoothness          569 non-null    float64\n",
        " 7   mean_compactness         569 non-null    float64\n",
        " 8   mean_concavity           569 non-null    float64\n",
        " 9   mean_concave_points      569 non-null    float64\n",
        " 10  mean_symmetry            569 non-null    float64\n",
        " 11  mean_fractal_dimension   569 non-null    float64\n",
        " 12  se_radius                569 non-null    float64\n",
        " 13  se_texture               569 non-null    float64\n",
        " 14  se_perimeter             569 non-null    float64\n",
        " 15  se_area                  569 non-null    float64\n",
        " 16  se_smoothness            569 non-null    float64\n",
        " 17  se_compactness           569 non-null    float64\n",
        " 18  se_concavity             569 non-null    float64\n",
        " 19  se_concave_points        569 non-null    float64\n",
        " 20  se_symmetry              569 non-null    float64\n",
        " 21  se_fractal_dimension     569 non-null    float64\n",
        " 22  worst_radius             569 non-null    float64\n",
        " 23  worst_texture            569 non-null    float64\n",
        " 24  worst_perimeter          569 non-null    float64\n",
        " 25  worst_area               569 non-null    float64\n",
        " 26  worst_smoothness         569 non-null    float64\n",
        " 27  worst_compactness        569 non-null    float64\n",
        " 28  worst_concavity          569 non-null    float64\n",
        " 29  worst_concave_points     569 non-null    float64\n",
        " 30  worst_symmetry           569 non-null    float64\n",
        " 31  worst_fractal_dimension  569 non-null    float64\n",
        "dtypes: float64(30), int64(1), object(1)\n",
        "memory usage: 146.7+ KB\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiFxcRkHbE3b"
      },
      "source": [
        "You should make the following observations from this output:\n",
        "* The target column is the column that you seek to predict. By convention, the target column, containing the Y-values, will usually, be the rightmost column in a display, or last column in a list. In this particular example, the target column, `diagnosis`, is the second column in the list.   \n",
        "* There is a column called `id` which identifies each subject. We should exclude this columns from our analysis because it contains no information useful for making a prediction.\n",
        "* From the data types output, we can see that with the exception of the column `diagnois`, all of the fields, are **_numeric_**. Non-numeric values are classified as `object` while numeric values are classified as being either `int64` or `float64`. Numeric columns might not require further processing before there are used to generate our X-values.\n",
        "* Categorical values (strings) are only found in the target column (`diagnosis`) which we will take care of later when we generate our Y-values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOAb250SbE3b"
      },
      "source": [
        "### **Exercise 1 - Step 1: Read dataset and store values in a DataFrame**\n",
        "\n",
        "In the cell below, use the Pandas function `pd.read_csv()` to read the Heart Disease data file `heart_disease.csv` located on the course HTTPS server. Save the data to a new DataFrame called `hdDF`.\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "1. In order to read this file correctly, you **must** comment out the following line of code:\n",
        "\n",
        "~~~text    \n",
        "# index_col=0,\n",
        "~~~\n",
        "\n",
        "If you don't comment out that line the column `Age` will not be placed in your DataFrame `hdDF` correctly.\n",
        "\n",
        "Set the display for 6 rows and 6 columns and then print out a display of `hdDF`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy7HbReObE3b"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 1 - Step 1 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJHzhkBHbE3b"
      },
      "source": [
        "If your code is correct, you should see the following table.\n",
        "\n",
        "![Heart Failure DataFrame](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image01a.png)\n",
        "\n",
        "Check your output carefully. From left to right, there should be an unamed index column with descending numbers (i.e, 0, 1, 2, ...) and just to the right of the index column there should be a column called `Age`. If your output doesn't have an index column, and the column `Age` is the first column on the left, go back and re-read the instruction for **Exercise 1A**.\n",
        "\n",
        "Your `hdDF` DataFrame has information on `918` subjects (number of rows = 918) and `12` clinical values for each subject (number of columns = 12). There are clearly more than one column with non-numeric values, but you won't know exactly how many until you run **Exercise 1B**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bsPm7cabE3b"
      },
      "source": [
        "### **Exercise 1 - Step 2: Display data types**\n",
        "\n",
        "In the cell below, write the code to print out the different data types in your DataFrame `hdDF` using the Pandas method `df.info()`. Use `len(hdDF.columns)` to set the number of rows to display, before you print out the data types.     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "SN86CHXrbE3b"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 1 - Step 2 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HwK4dm6bE3b"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "~~~text\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 918 entries, 0 to 917\n",
        "Data columns (total 12 columns):\n",
        " #   Column          Non-Null Count  Dtype  \n",
        "---  ------          --------------  -----  \n",
        " 0   Age             918 non-null    int64  \n",
        " 1   Sex             918 non-null    object\n",
        " 2   ChestPainType   918 non-null    object\n",
        " 3   RestingBP       918 non-null    int64  \n",
        " 4   Cholesterol     918 non-null    int64  \n",
        " 5   FastingBS       918 non-null    int64  \n",
        " 6   RestingECG      918 non-null    object\n",
        " 7   MaxHR           918 non-null    int64  \n",
        " 8   ExerciseAngina  918 non-null    object\n",
        " 9   Oldpeak         918 non-null    float64\n",
        " 10  ST_Slope        918 non-null    object\n",
        " 11  HeartDisease    918 non-null    int64  \n",
        "dtypes: float64(1), int64(6), object(5)\n",
        "memory usage: 86.2+ KB\n",
        "~~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dCjDEVJbE3b"
      },
      "source": [
        "You should make the following observations from the above output:\n",
        "* The target column is the column that you usually want to predict with a classification neural network. In this instance, the last column in this list, `HeartDisease`, will be your target column (Y-values).\n",
        "* The column `FastingBS` doesn't appear to contain information that would be especially useful for predicting heart disease, so you will need to drop it.\n",
        "* Some fields are numeric (data type `int64` or `float64`) and might not require further processing.\n",
        "* There are categorical values (data type `object`) in 5 columns including: `Sex`, `ChestPainType`, `RestingECG`, `ExerciseAngina` and `ST_Slope`. The categorical values (strings) in these columns will need to be taken care of, before you can use them in generating your X-values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyVh55smbE3b"
      },
      "source": [
        "### Example 2: Drop unecessary columns\n",
        "\n",
        "The `id` column in the `bcwDF` DataFrame does not contain information useful for predicting breast cancer, so it will be excluded from the feature vector containing the X-values, using the Pandas method `df.drop()` as shown by the next code chunk:\n",
        "~~~text\n",
        "bcwDF.drop('id', axis=1, inplace=True)\n",
        "~~~\n",
        "The argument `axis=1` means to drop the entire column, while the argument `inplace=True` means to change the DataFrame **_permanently_**.\n",
        "\n",
        "**NOTE:** After you run a code cell where you drop a column, you will get an error if you try to re-run the same cell, since there is no longer any column to drop. To run the cell again, you will need to re-read the datafile and re-create the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmIasmvIbE3b"
      },
      "outputs": [],
      "source": [
        "# Example 2: Drop unecesary columns\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Drop specific column\n",
        "bcwDF.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# Set the max rows and max columns\n",
        "pd.set_option('display.max_columns', 4)\n",
        "pd.set_option('display.max_rows', 4)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "display(bcwDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZglkxDzDbE3c"
      },
      "source": [
        "If you code is correct you should see the following table:\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image02a.png)\n",
        "\n",
        "You should note that the column `id` has been removed. Instead of the original `32` columns, there are now only `31` columns.\n",
        "\n",
        "NOTE: If you get an error that column `id` doesn't exist, it probably means that you have already run this cell and dropped the column. To correct this error, simply go back and re-read the datafile to create a fresh copy of `bcwDF`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmUbjPt6bE3c"
      },
      "source": [
        "### **Exercise 2: Drop unecessary columns**\n",
        "\n",
        "Since the column `FastingBS` in the Heart Disease dataset doesn't contain information that will be especially useful for predicting heart disease, this column should not be included in the analysis. In the cell below, write the code to drop this column. Display 6 rows and 6 columns of your updated DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fo895DRibE3c"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 2 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fURmKEkbE3c"
      },
      "source": [
        "If your code is correct you should see the following table:\n",
        "\n",
        "![_ _](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image03a.png)\n",
        "\n",
        "Since the column `FastingBS` wasn't displayed previously (**Example 1A**), you can't tell if it was dropped. However, the number of columns is now `11`, instead of the original `12` so you can assume your code was successful.\n",
        "\n",
        "**NOTE:** If you get an error that column `FastingBS` doesn't exist, it probably means that you have already run this cell and dropped the column. To correct this error, simply go back and re-read the datafile to create a fresh copy of `hdDF` by running all of the code cells starting with **Exercise 1** again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8P-sfz-bE3c"
      },
      "source": [
        "### Example 3: One-Hot Encode Categorical Variables\n",
        "\n",
        "For Example 3, we are going to use your Heart Disease DataFrame, `hdDF`, for the example.  \n",
        "\n",
        "Your `hdDF` DataFrame has 5 columns that have categorical variables (strings):\n",
        "1. `Sex`\n",
        "2. `ChestPainType`\n",
        "3. `RestingECG`\n",
        "4. `ExerciseAngina`\n",
        "5. `ST_Slope`.\n",
        "\n",
        "You will need to One-Hot Encode each of these `5` columns separately.\n",
        "\n",
        "To help you get started, Example 3 illustrates how to One-Hot encode the first column, `Sex`.\n",
        "\n",
        "The following line of code uses the Pandas function, `pd.get_dummies()` to One-Hot encode the string values in the `Sex` column and turn them into the integer values `0` and `1`.\n",
        "\n",
        "You should notice that the code below uses `try:` and `except:` blocks. Normally, you would **not** use `try` and `except` when creating a feature vector. They have been added here simply as a teaching aid.\n",
        "\n",
        "The `try` block lets you test a block of code for errors while the `except` block lets you handle the error. The `try` block demonstrates the 3 steps you need to One-Hot Encode the column `Sex`. The `except` block is there in case you try to re-run this cell after you have already dropped the column `Sex`. Instead of giving an error message and stopping, the `except` block simply warns you that the column has already been dropped.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdQT9kPvbE3c"
      },
      "outputs": [],
      "source": [
        "# Example 3: One-Hot encode categorical variables\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Adding try and except blocks as teaching aid-------------------------\n",
        "try:\n",
        "    # Step 1 - Get dummy values\n",
        "    dummies = pd.get_dummies(hdDF['Sex'],prefix=\"Sex\", dtype=int)\n",
        "\n",
        "    # Step 2 - Add dummies to DataFrame\n",
        "    hdDF = pd.concat([hdDF,dummies],axis=1)\n",
        "\n",
        "    # Step 3- Drop column replaced by dummies\n",
        "    hdDF.drop('Sex', axis=1, inplace=True)\n",
        "    print(\"Column 'Sex' has been dropped\")\n",
        "\n",
        "except:\n",
        "    print(\"ERROR: Column 'Sex' may have been already been dropped\")\n",
        "\n",
        "# Set the max rows and max columns\n",
        "pd.set_option('display.max_columns', 6)\n",
        "pd.set_option('display.max_rows', 6)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "display(hdDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GkWug2HbE3c"
      },
      "source": [
        "If your code is correct, you should see the following table.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image04a.png)\n",
        "\n",
        "\n",
        "If you happen to re-run this cell again, you would see the following error message at the top:\n",
        "~~~text\n",
        "ERROR: Column 'Sex' may have been already been dropped\n",
        "~~~\n",
        "\n",
        "If you receive this error, you will need to re-run your **Exercise 1A** and **Exercise 1B**  to regenerate your DataFrame. You will also have to run all of your code cells up to this one.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuvYXa8ZbE3c"
      },
      "source": [
        "### **Exercise 3: One-Hot encode categorical variables**\n",
        "\n",
        "Your `hdDF` DataFrame still has 4 columns with categorical variables:\n",
        "1. `ChestPainType`\n",
        "2. `RestingECG`\n",
        "3. `ExerciseAngina`\n",
        "4. `ST_Slope`.\n",
        "\n",
        "For **Exercise 3**, you are to One-Hot Encode these remaining `4` columns using the example shown in Example 3. To help you with your coding, **Exercise 3** has been divided into a series of steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8-5ar6BbE3c"
      },
      "source": [
        "### **Exercise 3 - Step 1: One-Hot encode the column `ChestPainType`**\n",
        "\n",
        "In the cell below, One-Hot encode the column `ChestPainType` in the Heart Disease DataFrame `hdDf`. Use the word `Pain` as the dummy `prefix`.\n",
        "\n",
        "After you add the dummies back into to the DataFrame, drop the column `ChestPainType`.\n",
        "\n",
        "Set the display for 6 columns and 6 rows and print out a display of your updated DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Nc3G3JjebE3c"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 3 - Step 1 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzytwMwzbE3c"
      },
      "source": [
        "If your code is correct, you should see the following table.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image05a.png)\n",
        "\n",
        "\n",
        "If you happen to re-run this cell again, you would see the following error message at the top:\n",
        "~~~text\n",
        "ERROR: Column 'ChestPainType' may have been already been dropped\n",
        "~~~\n",
        "\n",
        "If you receive this error, you will need to re-run your **Exercise 1A** and **Exercise 1B**  to regenerate your DataFrame. You will also have to run all of your code cells up to this one.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKPY5lPJbE3d"
      },
      "source": [
        "### **Exercise 3 - Step 2: One-Hot encode the column `RestingECG`**\n",
        "\n",
        "In the cell below, One-Hot encode the column `RestingECG` in the Heart Disease DataFrame, `hdDF`. Use the word `RestingECG` as the dummy `prefix`.\n",
        "\n",
        "Add the dummies to the DataFrame and then drop the column `RestingECG`. Set the display for 6 columns and 6 rows and print out a display of your updated DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBUdrNJAbE3f"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 3 - Step 2 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct, you should see the following table.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image06a.png)\n",
        "\n",
        "\n",
        "If you happen to re-run this cell again, you would see the following error message at the top:\n",
        "~~~text\n",
        "ERROR: Column 'RestingECG' may have been already been dropped\n",
        "~~~\n",
        "\n",
        "If you receive this error, you will need to re-run your **Exercise 1A** and **Exercise 1B**  to regenerate your DataFrame. You will also have to run all of your code cells up to this one.  "
      ],
      "metadata": {
        "id": "niEUTkDmvtma"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPl1h8J1bE3g"
      },
      "source": [
        "### **Exercise 3 - Step 3: One-Hot encode the column `ExerciseAngina`**\n",
        "\n",
        "In the cell below, One-Hot encode the column `ExerciseAngina` in the Heart Disease DataFrame, `hdDF`. Use the word `ExAngina` as the dummy `prefix`.\n",
        "\n",
        "Add the dummies to the DataFrame and then drop the column `ExerciseAngina`. Set the display for 6 columns and 6 rows and print out a display of your updated DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq0HD9HhbE3g"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 3 - Step 3 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct, you should see the following table.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image07a.png)\n",
        "\n",
        "\n",
        "If you happen to re-run this cell again, you would see the following error message at the top:\n",
        "~~~text\n",
        "ERROR: Column 'RestingECG' may have been already been dropped\n",
        "~~~\n",
        "\n",
        "If you receive this error, you will need to re-run your **Exercise 1A** and **Exercise 1B**  to regenerate your DataFrame. You will also have to run all of your code cells up to this one.  "
      ],
      "metadata": {
        "id": "vEqkWdX2w8fg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ulNLm55bE3g"
      },
      "source": [
        "### **Exercise 3 - Step 4: One-Hot encode the column `ST_Slope`**\n",
        "\n",
        "In the cell below, One-Hot encode the column `ST_Slope` in the Heart Disease DataFrame, `hdDF`. Use the word `ST_Slope` as the dummy `prefix`.\n",
        "\n",
        "Add the dummies to the DataFrame and then drop the column `ST_Slope`. Set the display for 6 columns and 6 rows and print out a display of your updated DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXUjzaIWbE3g"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 3 - Step 4 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your code is correct, you should see the following table.\n",
        "\n",
        "![__](https://biologicslab.co/BIO1173/images/class_04/class_04_1_image08a.png)\n",
        "\n",
        "\n",
        "If you happen to re-run this cell again, you would see the following error message at the top:\n",
        "~~~text\n",
        "ERROR: Column 'RestingECG' may have been already been dropped\n",
        "~~~\n",
        "\n",
        "If you receive this error, you will need to re-run your **Exercise 1A** and **Exercise 1B**  to regenerate your DataFrame. You will also have to run all of your code cells up to this one.  "
      ],
      "metadata": {
        "id": "kL09y_dZxBsO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZabPdNCkbE3g"
      },
      "source": [
        "You should notice that the number of columns in your DataFrame, `hdDF`, has increased from the `12` original columns to total of **20** columns!. This a clear example of **_column inflation_** in an invariable consequence of using One-Hot Encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzTd6KMWbE3g"
      },
      "source": [
        "### Sample Code: Print out column names\n",
        "\n",
        "If your coding has been correct so far, your DataFrame, `hdDF` should have 20 columns. This is an inconviently large number of columns to display on your computer screen. In this situation, you can take advantage of the Pandas method `pd.columns` to print out a complete list of all the column names in DataFrame, using this line of code:\n",
        "~~~text\n",
        "print(list(hdDF.columns))\n",
        "~~~\n",
        "Run the next cell to check whether your coding is correct so far, before going on to the next part of the lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI0n-fiabE3g"
      },
      "outputs": [],
      "source": [
        "# Run this cell to print the column names in hdDF\n",
        "\n",
        "print(list(hdDF.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbsr9X2ibE3g"
      },
      "source": [
        "If your coding has been correct so far, you should see the following list of `20` column names:\n",
        "~~~text\n",
        "['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak', 'HeartDisease', 'Sex_F', 'Sex_M', 'ChestPainType_ASY', 'ChestPainType_ATA', 'ChestPainType_NAP', 'ChestPainType_TA', 'RestingECG_LVH', 'RestingECG_Normal', 'RestingECG_ST', 'ExerciseAngina_N', 'ExerciseAngina_Y', 'ST_Slope_Down', 'ST_Slope_Flat', 'ST_Slope_Up']\n",
        "~~~\n",
        "\n",
        "If your output does _not_ start with the name `Age`, it probably means that you didn't read the datafile correctly. Go back and re-read the instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWimTgJ3bE3g"
      },
      "source": [
        "If the output from `print(list(hfDF.columns))` doesn't match the output above, figure out which columns have not successfully One-Hot encoded, and/or dropped, and make the necessary code fixes.\n",
        "\n",
        "When you are making significant changes to a DataFrame, its always a good idea to go back to where you originally created the DataFrame, in the lesson, **Exercise 1A**, re-run this cell make a new copy of `hdDF` and then re-run your code cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFw_Ff5qbE3h"
      },
      "source": [
        "## **Generate X and Y for a Classification Neural Network**\n",
        "\n",
        "Now that unecessary columns have been dropped, and all of the string data has been One-Hot encoded (except for the target column), we are ready to use the data stored in the updated DataFrame as input for a neural network.\n",
        "\n",
        "There are two basic ways to used tabular data as input into a neural network. The neural network can perform **_classification_** or **_regression_**. There are small number of very important differences in how you generate X and Y values for these different functions.\n",
        "\n",
        "We will begin creating a feature vector for a classification neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onW_b5thbE3h"
      },
      "source": [
        "### Example 4: Create Feature Vector for _Classification_ Neural Network\n",
        "\n",
        "The goal of a classification neural network is to accurately categorize input data (X-values) into predefined classes or categories (Y-values). The network learns to identify patterns and features within the input data that are associated with each class, allowing it to make predictions about the class of new, unseen data. During training (fitting), the neural network tries to minimize the classification error as a way to improve the overall accuracy of the network's predictions.\n",
        "\n",
        "When using tabular data, i.e. data stored in a DataFrame, the first step is to figure out which columns in the DataFrame will be used to generate the X-values and which column will be used for the Y-values. For the Breast Cancer Wisconsin dataset, our goal will be to classify tumor cells as cancerous or non-cancerous so the information in the column `diagnois` will be our Y-values and the remaining columns will be our X-values.\n",
        "\n",
        "In a classification neural network, the output layer will have exactly the same number of neurons as the number of predefined classes or categories. Since the Breast Cancer Wisconsin dataset has only two predifined classes/categories: (1) `M` for malignant and (2) `B` for benign, the output layer will have exactly two neurons. One neuron will represent `Malignant` and the other `Benign`.\n",
        "\n",
        "At the end of each run (epoch) both the `Malignant` output neuron and the `Benign` output neuron will have a \"voltage\" (numerical value). The  \"voltage\" will be close to `1` in the `Malignant` output neuron if the neural network predicted the breast tumor was cancerous. On the other hand, the `Benign` output neuron will have a much smaller value, closer to `0`. Conversely, if the neural network predicted the tumor was non-cancerous, the `Benign` output neuron will have a value close to `1` while the `Malignant` output neuron will have a much lower voltage, closer to `0`. In other words, the output neuron with the highest value represents the neural network's classification prediction.\n",
        "\n",
        "In Module 3, we created our X-values by specifying the name of each column in the DatFrame that we wanted to include. This approach works fine when there are a relatively small number of columns, but becomes tedious with DataFrames will a large number of columns.\n",
        "\n",
        "In the code in the cell below, demonstrates an alternative approach better suited for large DataFrames. We start by creating a Python `list` variable called `bcwX_columns`. This variable will contain the name of every column in the DataFrame, except if one (or more) column names are dropped. Here is the code chunk:\n",
        "\n",
        "~~~text\n",
        "# Create list of column names for X-values\n",
        "bcwX_columns = bcwDF.columns.drop('diagnosis')\n",
        "~~~\n",
        "As you can see, we dropped the column `diagnosis` from our list. The column `diagnosis` contains our Y-values, and we don't want them mixed in with our X-values!\n",
        "\n",
        "We next use the Pandas method `df.values`, to convert each numerical value in the columns specified by `bcwX_columns` into a Numpy array called `bcwX` using this code chunk:\n",
        "~~~text\n",
        "# Generate X feature vector\n",
        "bcwX = bcwDF[bcwX_columns].values\n",
        "~~~~\n",
        "Keep in mind that the real work of this code chunk is `.values` at the end of the code line. It is this little bit of code that converts the numerical values in the DataFrame into a Numpy array. Feature vectors for neural network are Numpy arrays, **not** DataFrames.\n",
        "\n",
        "The next line of code `bcwX = np.asarray(bcwX).astype('float32')` makes sure that all of our X-values of given the same `float32` data type. If you fail to do this, Keras/Tensorflow will sometimes generate an error.\n",
        "\n",
        "Now that our X-values have been generated, we can now generate our Y-values. How you generate Y-values is different for classification neural networks than for regression neural networks. Here is the rule:\n",
        "\n",
        "#### **RULE: For Classification Neural Networks, Y-values must always be _One-Hot Encoded_**\n",
        "\n",
        "This rule is true even if the column holding the Y-values is numeric. In addition to converting stings to integers, One-Hot Encoding also provides the correct **_format_** for the Y-values.\n",
        "\n",
        "Here is the code chunk for generating the Y-values using One-Hot Encoding:\n",
        "\n",
        "~~~text\n",
        "# Generate Y feature vector\n",
        "dummies = pd.get_dummies(bcwDF['diagnosis'], dtype=int)\n",
        "bcwY = dummies.values\n",
        "~~~\n",
        "The first code line creates a new DataFrame called `dummies` containing just the values in the `diagnosis` column. The second code line uses the `value` method to convert the numerical values in `dummies` into a Numpy array called `bcwY`.\n",
        "\n",
        "As above, we use the line of code `bcwY = np.asarray(bcwY).astype('float32')` to sure all of the Y-values are type `float32`.\n",
        "\n",
        "To verify our X and Y feature vectors are in the correct format, the first 4 values in `bcwX` and `bcwY` are printed out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1jWRz3ybE3h"
      },
      "outputs": [],
      "source": [
        "# Example 4: Create feature vector\n",
        "\n",
        "# Create list of column names for X-values\n",
        "bcwX_columns = bcwDF.columns.drop('diagnosis')\n",
        "\n",
        "# Generate X feature vector\n",
        "bcwX = bcwDF[bcwX_columns].values\n",
        "bcwX = np.asarray(bcwX).astype('float32')\n",
        "\n",
        "# Generate Y feature vector\n",
        "dummies = pd.get_dummies(bcwDF['diagnosis'], dtype=int)\n",
        "bcwY = dummies.values\n",
        "bcwY = np.asarray(bcwY).astype('float32')\n",
        "\n",
        "# Print out X and Y\n",
        "np.set_printoptions(suppress=True,precision=4)\n",
        "print(\"The first 4 X-values are:\")\n",
        "print(bcwX[0:4])\n",
        "print(\"\\nTheir corresponding Y-values are:\")\n",
        "print(bcwY[0:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyX7aiSNbE3h"
      },
      "source": [
        "If your code is correct you should see the following output:\n",
        "~~~text\n",
        "The first 4 X-values are:\n",
        "[[  17.99     10.38    122.8    1001.        0.1184    0.2776    0.3001\n",
        "     0.1471    0.2419    0.0787    1.095     0.9053    8.589   153.4\n",
        "     0.0064    0.049     0.0537    0.0159    0.03      0.0062   25.38\n",
        "    17.33    184.6    2019.        0.1622    0.6656    0.7119    0.2654\n",
        "     0.4601    0.1189]\n",
        " [  20.57     17.77    132.9    1326.        0.0847    0.0786    0.0869\n",
        "     0.0702    0.1812    0.0567    0.5435    0.7339    3.398    74.08\n",
        "     0.0052    0.0131    0.0186    0.0134    0.0139    0.0035   24.99\n",
        "    23.41    158.8    1956.        0.1238    0.1866    0.2416    0.186\n",
        "     0.275     0.089 ]\n",
        " [  19.69     21.25    130.     1203.        0.1096    0.1599    0.1974\n",
        "     0.1279    0.2069    0.06      0.7456    0.7869    4.585    94.03\n",
        "     0.0061    0.0401    0.0383    0.0206    0.0225    0.0046   23.57\n",
        "    25.53    152.5    1709.        0.1444    0.4245    0.4504    0.243\n",
        "     0.3613    0.0876]\n",
        " [  11.42     20.38     77.58    386.1       0.1425    0.2839    0.2414\n",
        "     0.1052    0.2597    0.0974    0.4956    1.156     3.445    27.23\n",
        "     0.0091    0.0746    0.0566    0.0187    0.0596    0.0092   14.91\n",
        "    26.5      98.87    567.7       0.2098    0.8663    0.6869    0.2575\n",
        "     0.6638    0.173 ]]\n",
        "\n",
        "Their corresponding Y-values are:\n",
        "[[0. 1.]\n",
        " [0. 1.]\n",
        " [0. 1.]\n",
        " [0. 1.]]\n",
        "~~~\n",
        "\n",
        "As you can see, our two feature vectors, `bcwX` and `bcwY`, are Numpy arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-TUKZcJbE3h"
      },
      "source": [
        "### **Exercise 4: Create Feature Vectors for _Classification_ Neural Network**\n",
        "\n",
        "In the cell below, create X and Y feature vectors for a classification neural network. Use the column `HeartDisease` for your Y-values, and all of the other columns for your X-values.\n",
        "\n",
        "_Code Hint:_\n",
        "\n",
        "Use this code chunk to get your list of column names:\n",
        "\n",
        "~~~text\n",
        "# Create list of column names for X-values\n",
        "hdX_columns = hdDF.columns.drop('HeartDisease')\n",
        "~~~\n",
        "\n",
        "Even though the values in the column `HeartDisease` are already numerical (not strings), you will still need to One-Hot encode this column to create the correct format for a Classification neural network.\n",
        "\n",
        "Call your X-feature vector, `hdX` and your Y feature vector, `hdY`. After generating these variables, print out their first 4 values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N_yjyU7bE3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fafb6b-61ca-4573-be1a-35e4cc596390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 4 X-values are:\n",
            "[[ 40.  140.  289.  172.    0.    0.    1.    0.    1.    0.    0.    0.\n",
            "    1.    0.    1.    0.    0.    0.    1. ]\n",
            " [ 49.  160.  180.  156.    1.    1.    0.    0.    0.    1.    0.    0.\n",
            "    1.    0.    1.    0.    0.    1.    0. ]\n",
            " [ 37.  130.  283.   98.    0.    0.    1.    0.    1.    0.    0.    0.\n",
            "    0.    1.    1.    0.    0.    0.    1. ]\n",
            " [ 48.  138.  214.  108.    1.5   1.    0.    1.    0.    0.    0.    0.\n",
            "    1.    0.    0.    1.    0.    1.    0. ]]\n",
            "\n",
            "Their corresponding Y-values are:\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# Insert your code for Exercise 4 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8G5KZX4bE3h"
      },
      "source": [
        "If your code is correct you should see the following output:\n",
        "~~~text\n",
        "The first 4 X-values are:\n",
        "[[ 40.  140.  289.  172.    0.    0.    1.    0.    1.    0.    0.    0.\n",
        "    1.    0.    1.    0.    0.    0.    1. ]\n",
        " [ 49.  160.  180.  156.    1.    1.    0.    0.    0.    1.    0.    0.\n",
        "    1.    0.    1.    0.    0.    1.    0. ]\n",
        " [ 37.  130.  283.   98.    0.    0.    1.    0.    1.    0.    0.    0.\n",
        "    0.    1.    1.    0.    0.    0.    1. ]\n",
        " [ 48.  138.  214.  108.    1.5   1.    0.    1.    0.    0.    0.    0.\n",
        "    1.    0.    0.    1.    0.    1.    0. ]]\n",
        "\n",
        "The corresponding Y-values are:\n",
        "[[1 0]\n",
        " [0 1]\n",
        " [1 0]\n",
        " [0 1]]\n",
        "~~~\n",
        "\n",
        "You might notice that there are a lot of `1s` and `0s` in your `X feature vector`. This is because you One-Hot Encoded several non-numeric columns in **Exercise 3**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-SEwUxCbE3i"
      },
      "source": [
        "### Example 5:  Construct, Compile and Train _Classification_ Neural Network\n",
        "\n",
        "When building a **classification** neural network, there are two important points to remember:\n",
        "\n",
        "* Classification neural networks have an output neuron count equal to the number of classes.\n",
        "* Classification neural networks should use the **softmax** activation function in the output layer and **categorical_crossentropy** as the loss function when you compile your neural network.\n",
        "\n",
        "When building a new neural network, you must begin by telling Keras the name we what for our new network, what kind of neural network we want to build. In this example, we are building a simple linear network with the name `bcwModel`, so we begin construction with the line:\n",
        "\n",
        "~~~text\n",
        "bcwModel = Sequential()\n",
        "~~~\n",
        "\n",
        "Next we have to tell Keras how many inputs the model will receive. This is done in the following line of code:\n",
        "\n",
        "~~~text\n",
        "bcwModel.add(Input(shape=(bcwX.shape[1],)))  # Hidden 1\n",
        "~~~\n",
        "\n",
        "1. `bcwModel.add():` This method is used to add layers to the neural network model named `bcwModel`.\n",
        "2. `Input()`: This function defines the input layer for the neural network.\n",
        "3. `shape=(bcwX.shape[1],)`: The shape parameter specifies the shape of the input data. Here, `bcwX.shape[1]` represents the number of features in your input dataset `bcwX`. The shape is provided as a tuple, indicating that each input sample has `bcwX.shape[1]` features.\n",
        "\n",
        "Next we start adding \"hidden\" layers to our network in sequential order. There are no \"hard-and-fast\" rules when it comes to how many layers a network should have and how many neurons should be put in each layer. There are trade offs when it comes to the number of layers and neurons that will discussed later in this course.\n",
        "\n",
        "For this example, we will put 50 neurons in the first layer, and half that many (25) in the next (2nd) hidden layer. The argument `Dense` tell Keras to connect every neuron in that layer to every neuron in the next layer. We use the `relu` activation function since it is considered to be the \"best\" for hidden layer neurons in this kind of simple neural network.\n",
        "\n",
        "As mentioned at the beginning of Example 5, we need to make sure there is one neuron in the output layer for **_each_** category that we want to classify. This is accomplished by the argument `bcwY.shape[1]` in this line of code:\n",
        "\n",
        "~~~text\n",
        "bcwModel.add(Dense(bcwY.shape[1],activation='softmax')) # Output\n",
        "~~~\n",
        "\n",
        "The other point to remember is to use the loss function `categorical_crossentropy` and the `adam` optimizer when compiling a classification neural network.\n",
        "\n",
        "Once the neural network has been successfully compliled (one of the jobs of the compiler is to spot errors in your neural network), it can be \"fitted\" (trained) to the X and Y feature vectors. A complete \"run\" of the neural network is called an `epoch`. At the end of each epoch, the model evaluates its \"inaccuracy\" (loss), prints it out (if `verbose=2`), makes small modifications to the weigth/strength of each connection between neurons, and runs again using the updated weights.\n",
        "\n",
        "By minimumizing the loss function, the model should gradually find the best weight for each neural connection.\n",
        "\n",
        "In this example, the number of epochs is set to 100.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "m_YQ9hBKbE3i"
      },
      "outputs": [],
      "source": [
        "# Example 5: Construct, compile and train model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "# Construct model------- ---------------------------------------------------\n",
        "bcwModel = Sequential()\n",
        "bcwModel.add(Input(shape=(bcwX.shape[1],)))  # Input\n",
        "bcwModel.add(Dense(25, activation='relu')) # Hidden 1\n",
        "bcwModel.add(Dense(50, activation='relu')) # Hidden 2\n",
        "bcwModel.add(Dense(bcwY.shape[1],activation='softmax')) # Output\n",
        "\n",
        "# Compile model--------------------------------------------------------------\n",
        "bcwModel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train model----------------------------------------------------------------\n",
        "bcwModel.fit(bcwX,bcwY,verbose=2,epochs=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_abVIYhAbE3i"
      },
      "source": [
        "If your code is correct you should see similiar to the following output. Notice that the loss value started at 20.3770 and gradually decreased to a value of 0.1709 after 100 epochs, in this particular example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrGdG8XYbE3i"
      },
      "source": [
        "~~~text\n",
        "Epoch 1/100\n",
        "18/18 - 1s - 72ms/step - loss: 20.3770\n",
        "Epoch 2/100\n",
        "18/18 - 0s - 4ms/step - loss: 4.5375\n",
        "Epoch 3/100\n",
        "18/18 - 0s - 8ms/step - loss: 0.7118\n",
        "Epoch 4/100\n",
        "18/18 - 0s - 4ms/step - loss: 0.2895\n",
        "Epoch 5/100\n",
        "18/18 - 0s - 9ms/step - loss: 0.2906\n",
        "............................\n",
        "\n",
        "Epoch 95/100\n",
        "18/18 - 0s - 8ms/step - loss: 0.1749\n",
        "Epoch 96/100\n",
        "18/18 - 0s - 8ms/step - loss: 0.1669\n",
        "Epoch 97/100\n",
        "18/18 - 0s - 8ms/step - loss: 0.1609\n",
        "Epoch 98/100\n",
        "18/18 - 0s - 8ms/step - loss: 0.1810\n",
        "Epoch 99/100\n",
        "18/18 - 0s - 7ms/step - loss: 0.2460\n",
        "Epoch 100/100\n",
        "18/18 - 0s - 10ms/step - loss: 0.1798\n",
        "<keras.src.callbacks.history.History at 0x797db258e190>\n",
        "~~~\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ02ecJpbE3i"
      },
      "source": [
        "### **Exercise 5: Construct, Compile and Train _Classification_ Neural Network**\n",
        "\n",
        "In the cell below, construct, compile and train a classification neural network called `hdModel`. Use Example 5 as a template.\n",
        "\n",
        "Make sure to change the input dimensions of your first Hidden layer to `hdX.shape[1]` and the number of neurons in your output layer to `hdY.shape[1]`. If you get an error, it's mostly likely that you forgot to change these values to correctly match your X and Y feature vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shoVd6-dbE3i"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 5 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5WUZacsbE3i"
      },
      "source": [
        "If your code is correct you should see something similar to the output shown below. In this example, the loss function decreased from 1.8839 to 0.0027 after training 100 cycles (epochs).\n",
        "~~~text\n",
        "Epoch 1/100\n",
        "29/29 - 1s - 37ms/step - loss: 1.8839\n",
        "Epoch 2/100\n",
        "29/29 - 0s - 3ms/step - loss: 0.7567\n",
        "Epoch 3/100\n",
        "29/29 - 0s - 5ms/step - loss: 0.6322\n",
        "Epoch 4/100\n",
        "29/29 - 0s - 5ms/step - loss: 0.5892\n",
        "Epoch 5/100\n",
        "29/29 - 0s - 3ms/step - loss: 0.5503\n",
        "29/29 - 0s - loss: 0.6659 - 106ms/epoch - 4ms/step\n",
        "\n",
        "......................................\n",
        "\n",
        "Epoch 95/100\n",
        "29/29 - 0s - 5ms/step - loss: 0.0031\n",
        "Epoch 96/100\n",
        "29/29 - 0s - 5ms/step - loss: 0.0030\n",
        "Epoch 97/100\n",
        "29/29 - 0s - 5ms/step - loss: 0.0028\n",
        "Epoch 98/100\n",
        "29/29 - 0s - 5ms/step - loss: 0.0029\n",
        "Epoch 99/100\n",
        "29/29 - 0s - 5ms/step - loss: 0.0027\n",
        "Epoch 100/100\n",
        "29/29 - 0s - 4ms/step - loss: 0.0027\n",
        "<keras.src.callbacks.history.History at 0x797da9e4b910>\n",
        "\n",
        "~~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SytSo7xnbE3i"
      },
      "source": [
        "## **Generate Feature Vectors for a Regression Neural Network**\n",
        "\n",
        "As mentioned above, the procedure for generating X and Y feature vectors for a regression neural network is somewhat different the procedure used above. Even though these differences are not large, they are important. If your X and Y feature vectors are not generated in the correct format, your neural network will not compile and run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfYNaXbKbE3i"
      },
      "source": [
        "### Example 6: Generate Feature Vectors for Regression Neural Network\n",
        "\n",
        "\n",
        "For regression, we want to predict a variable that has a **_range of values_**. For Example 6, we will generate X and Y feature vectors for a regression neural network designed to predict the `mean_area` of tumor cell nuclei in the Breast Cancer Wisconsin dataset.\n",
        "\n",
        "We begin by creating a new DataFrame from the same CSV file, but this we will call `areaDF`to remind us that is DataFrame is predicting the average (mean) area.  \n",
        "\n",
        "After creating our DataFrame, our next step is to **_pre-process_** the data. There are a variety of data manipulation steps that come under the heading `pre-processing`. Some of these manipulations are optional while other step are required. One required data manipulation is to make sure all of the categorical values (i.e. strings) have been converted to numerical values.\n",
        "\n",
        "For our regression neural network, we definitely want to include the column `diagnosis` as part of our X feature vector. It is certainly reasonable to assume that `mean_area` might be different in tumors that are `Malignant` than tumors that are `Benign`. However, since the column `diagnosis` contains string values (i.e. `M` and `B`) we will first need to convert these strings to numerical values.\n",
        "\n",
        "We saw earlier that we could use One-Hot Encoding to make this conversion. In this example, we will use an alternative method called `mapping`. Mapping has the advantage over One-Hot Encoding, that it doesn't increase the number of columns. It's relative easy to employ, provided the number of different categorical values is relatively small as is it here.  \n",
        "\n",
        "Here is the code chunk that maps the letter `M` to `1` and the letter `B` to `0`:\n",
        "~~~text\n",
        "mapping = {'M': 1, 'B': 0}\n",
        "areaDF['diagnosis'] = areaDF['diagnosis'].map(mapping)\n",
        "~~~~\n",
        "From a purely mathematic perspective, you could assign these two string values to any integer without any effect on the accuracy of the regression neural network. However, the usual convention is to assign `1` to the \"disease\" condition, and `0` to the \"non-diseased\" condition.\n",
        "\n",
        "Next, we need to create the Y feature vector. A very important difference between regression and catagorical networks, is how the Y feature vector is created. With regression, we simply assign the numerical values in the correct DataFrame column to our Numpy array as shown in this code chunk:\n",
        "~~~text\n",
        "areaY = areaDF['mean_area'].values\n",
        "~~~\n",
        "\n",
        "Finally, we print out the first 4 values in the X and Y feature vectors so we can make sure they have the correct format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cOTt8MsZbE3k"
      },
      "outputs": [],
      "source": [
        "# Example 6: Generate X and Y for regression\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read file and create DataFrame-------------------------------------\n",
        "areaDF = pd.read_csv(\n",
        "    \"https://biologicslab.co/BIO1173/data/wcbreast.csv\",\n",
        "    index_col=0,\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Pre-process variables----------------------------------------------\n",
        "# Map categorical values in Quality to integers\n",
        "mapping = {'B': 0, 'M': 1}\n",
        "areaDF['diagnosis'] = areaDF['diagnosis'].map(mapping)\n",
        "\n",
        "# Create X feature vector--------------------------------------------\n",
        "areaX_columns = areaDF.columns.drop('mean_area')\n",
        "areaX = areaDF[areaX_columns].values\n",
        "areaX = np.asarray(areaX).astype('float32')\n",
        "\n",
        "# Create Y feature vector--------------------------------------------\n",
        "areaY = areaDF['mean_area'].values\n",
        "areaY = np.asarray(areaY).astype('float32')\n",
        "\n",
        "# Print out X and Y\n",
        "np.set_printoptions(suppress=True,precision=4)\n",
        "print(\"The first 4 X-values are:\")\n",
        "print(areaX[0:4])\n",
        "print(\"\\nThe corresponding Y-values are:\")\n",
        "print(areaY[0:4])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re9S5Zf4bE3k"
      },
      "source": [
        "If your code is correct you should see the following output:\n",
        "~~~text\n",
        "The first 4 X-values are:\n",
        "[[  842302.            1.           17.99         10.38        122.8\n",
        "         0.1184        0.2776        0.3001        0.1471        0.2419\n",
        "         0.0787        1.095         0.9053        8.589       153.4\n",
        "         0.0064        0.049         0.0537        0.0159        0.03\n",
        "         0.0062       25.38         17.33        184.6        2019.\n",
        "         0.1622        0.6656        0.7119        0.2654        0.4601\n",
        "         0.1189]\n",
        " [  842517.            1.           20.57         17.77        132.9\n",
        "         0.0847        0.0786        0.0869        0.0702        0.1812\n",
        "         0.0567        0.5435        0.7339        3.398        74.08\n",
        "         0.0052        0.0131        0.0186        0.0134        0.0139\n",
        "         0.0035       24.99         23.41        158.8        1956.\n",
        "         0.1238        0.1866        0.2416        0.186         0.275\n",
        "         0.089 ]\n",
        " [84300904.            1.           19.69         21.25        130.\n",
        "         0.1096        0.1599        0.1974        0.1279        0.2069\n",
        "         0.06          0.7456        0.7869        4.585        94.03\n",
        "         0.0061        0.0401        0.0383        0.0206        0.0225\n",
        "         0.0046       23.57         25.53        152.5        1709.\n",
        "         0.1444        0.4245        0.4504        0.243         0.3613\n",
        "         0.0876]\n",
        " [84348304.            1.           11.42         20.38         77.58\n",
        "         0.1425        0.2839        0.2414        0.1052        0.2597\n",
        "         0.0974        0.4956        1.156         3.445        27.23\n",
        "         0.0091        0.0746        0.0566        0.0187        0.0596\n",
        "         0.0092       14.91         26.5          98.87        567.7\n",
        "         0.2098        0.8663        0.6869        0.2575        0.6638\n",
        "         0.173 ]]\n",
        "\n",
        "The corresponding Y-values are:\n",
        "[1001.  1326.  1203.   386.1]\n",
        "~~~\n",
        "\n",
        "The last 4 values, `1001`, `1326`, `1203` and `386.1` are the `mean_area` values for the 4 first subjects in our feature vectors. Our goal is to build and train a regression neural network than accurately predict these `mean_area` numbers, given the values in the X feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gbi4rmvbE3k"
      },
      "source": [
        "### **Exercise 6: Generate Feature Vectors for Regression Neural Network**\n",
        "\n",
        "In the cell below, generate X and Y for a regression neural network that can predict the maximum heart rate,`MaxHR`, for the Heart Disease dataset.\n",
        "\n",
        "Start by reading the `heart_disease.cvs` dataset and making a new DataFrame called `HRateDF`. Don't forget to comment out the line:\n",
        "\n",
        "~~~text\n",
        "#    index_col=0,\n",
        "~~~\n",
        "\n",
        "Then pre-processing the 5 columns with categorical (strings) values using One-Hot Encoding:\n",
        "1. `Sex`\n",
        "2. `ChestPainType`\n",
        "3. `RestingECG`\n",
        "4. `ExerciseAngina`\n",
        "5. `ST_Slope`\n",
        "\n",
        "Here is a code chunk example for One-Hot Encoding the first column `Sex`:\n",
        "~~~text\n",
        "# Sex\n",
        "dummies = pd.get_dummies(HRateDF['Sex'],prefix=\"Sex\", dtype=int)\n",
        "HRateDF = pd.concat([HRateDF,dummies],axis=1)\n",
        "HRateDF.drop('Sex', axis=1, inplace=True)\n",
        "~~~\n",
        "\n",
        "Once you completed One-Hot Encoding all 5 columns, you should ready to generate your X feature vector. Since the goal of your regression neural network is to predict maximum heart rate `MaxHR`, make sure to drop this column when you create your list of X column names, `MaxHRX`. Call your X-feature vector `MaxHRX` and your Y-feature vector `MaxHRY`. Remember, since this regression neural network, you do **NOT** One-Hot Encode the Y-values!\n",
        "\n",
        "When you have generated X and Y, print out the first 4 values in `MaxHRX` and `MaxHRY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "L8jKyO3bbE3k"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 6 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTM8mFaXbE3k"
      },
      "source": [
        "If your code is correct you should see the following output:\n",
        "\n",
        "~~~text\n",
        "The first 4 X-values are:\n",
        "[[ 40.  140.  289.    0.    0.    0.    0.    1.    0.    1.    0.    0.\n",
        "    0.    1.    0.    1.    0.    0.    0.    1. ]\n",
        " [ 49.  160.  180.    0.    1.    1.    1.    0.    0.    0.    1.    0.\n",
        "    0.    1.    0.    1.    0.    0.    1.    0. ]\n",
        " [ 37.  130.  283.    0.    0.    0.    0.    1.    0.    1.    0.    0.\n",
        "    0.    0.    1.    1.    0.    0.    0.    1. ]\n",
        " [ 48.  138.  214.    0.    1.5   1.    1.    0.    1.    0.    0.    0.\n",
        "    0.    1.    0.    0.    1.    0.    1.    0. ]]\n",
        "\n",
        "The corresponding Y-values are:\n",
        "[172. 156.  98. 108.]\n",
        "~~~~\n",
        "\n",
        "The last 4 numbers are the maximum heart rates of the first 4 subjects. When you build your regression neural network, you will try to predict these values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcnrZsUIbE3l"
      },
      "source": [
        "### Example 7: Construct, compile and train a regression neural network\n",
        "\n",
        "The X and Y feature vectors are now ready for training a regression neural network. When building a neural network for regression, there are three points to remember.\n",
        "\n",
        "* **First:** a regression neural network only has a single neuron in its output layer. The \"voltage\" in this single output neuron at the end of each epoch, represents the network's numerical prediction. So in this example, the numerical value in the output neuron would be the `mean_area` value of the tumor cell nucleus.\n",
        "\n",
        "The difference between the `areaModel` model's predicted `mean_area` values, and the actual actual `mean_area` values stored in the Y feature vector, `areaY`, is the loss value. The better the neural network becomes at predicting mean area the smaller the loss value becomes.\n",
        "\n",
        "* **Second:** a regression neural network does **not** use an activation function in the output layer.\n",
        "\n",
        "* **Third:** when you compile a regression neural network, the loss function should be `mean_squared_error`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ygZexM1xbE3l"
      },
      "outputs": [],
      "source": [
        "# Example 7: Construct, compile and train\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "# Construct model------------------------------------------\n",
        "areaModel = Sequential()\n",
        "areaModel.add(Input(shape=(areaX.shape[1],)))  # Input\n",
        "areaModel.add(Dense(10, activation='relu')) # Hidden 1\n",
        "areaModel.add(Dense(20, activation='relu')) # Hidden 2\n",
        "areaModel.add(Dense(1)) # Output: 1 neuron, no activation\n",
        "\n",
        "# Compile model---------------------------------------------\n",
        "areaModel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Train model\n",
        "areaModel.fit(areaX,areaY,verbose=2,epochs=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFFL0u_XbE3l"
      },
      "source": [
        "If your code is correct you should see something similar to the following output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT4fj-r_bE3l"
      },
      "source": [
        "~~~text\n",
        "Epoch 1/100\n",
        "18/18 - 1s - 59ms/step - loss: 85945885917184.0000\n",
        "Epoch 2/100\n",
        "18/18 - 0s - 4ms/step - loss: 11133472735232.0000\n",
        "Epoch 3/100\n",
        "18/18 - 0s - 4ms/step - loss: 464338223104.0000\n",
        "Epoch 4/100\n",
        "18/18 - 0s - 4ms/step - loss: 168510226432.0000\n",
        "Epoch 5/100\n",
        "18/18 - 0s - 6ms/step - loss: 50635878400.0000\n",
        ".................................\n",
        "\n",
        "Epoch 95/100\n",
        "18/18 - 0s - 4ms/step - loss: 225845.4531\n",
        "Epoch 96/100\n",
        "18/18 - 0s - 8ms/step - loss: 224946.9531\n",
        "Epoch 97/100\n",
        "18/18 - 0s - 4ms/step - loss: 230193.8125\n",
        "Epoch 98/100\n",
        "18/18 - 0s - 8ms/step - loss: 238129.4844\n",
        "Epoch 99/100\n",
        "18/18 - 0s - 8ms/step - loss: 226218.7344\n",
        "Epoch 100/100\n",
        "18/18 - 0s - 8ms/step - loss: 225083.6875\n",
        "<keras.src.callbacks.history.History at 0x797da931ad90>\n",
        "\n",
        "~~~\n",
        "In this particular example, the loss function (RMSE) reported a loss of 85945885917184.0000 after the 1st epoch. After 100 epochs, the loss had decrease to 225083.6875. While these might look to be very \"bad\" values, they made not be as bad as they look. We will look more closely how to interpret RSME values in an upcoming lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KPfHR7BbE3l"
      },
      "source": [
        "### **Exercise 7: Construct, Compile, Train Regression Neural Network**\n",
        "\n",
        "In the cell below create a regression neural network for the Heart Disease dataset that can predict the maximum heart rate (`MaxHR`).  Use Example 7 as a template. Call your neural network, `HRateModel`. Train (fit) you model for 100 epochs.\n",
        "\n",
        "Don't forget to set the input dimension of your 1st hidden layer correctly, our you will get an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXyYUtW8bE3l"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 7 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3KlxRfYbE3l"
      },
      "source": [
        "If your code is correct you should see something similar to the following output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9eGjYhQbE3l"
      },
      "source": [
        "~~~text\n",
        "Epoch 1/100\n",
        "29/29 - 1s - 38ms/step - loss: 3065.8098\n",
        "Epoch 2/100\n",
        "29/29 - 0s - 4ms/step - loss: 2209.2034\n",
        "Epoch 3/100\n",
        "29/29 - 0s - 5ms/step - loss: 1715.3960\n",
        "Epoch 4/100\n",
        "29/29 - 0s - 5ms/step - loss: 1325.7843\n",
        "Epoch 5/100\n",
        "29/29 - 0s - 5ms/step - loss: 1114.0975\n",
        "\n",
        ".............\n",
        "\n",
        "Epoch 95/100\n",
        "29/29 - 0s - 3ms/step - loss: 681.4064\n",
        "Epoch 96/100\n",
        "29/29 - 0s - 5ms/step - loss: 664.2032\n",
        "Epoch 97/100\n",
        "29/29 - 0s - 5ms/step - loss: 662.0135\n",
        "Epoch 98/100\n",
        "29/29 - 0s - 5ms/step - loss: 653.0153\n",
        "Epoch 99/100\n",
        "29/29 - 0s - 5ms/step - loss: 655.7418\n",
        "Epoch 100/100\n",
        "29/29 - 0s - 5ms/step - loss: 652.8434\n",
        "<keras.src.callbacks.history.History at 0x797da9ec8d10>\n",
        "~~~\n",
        "\n",
        "In the example above, the RMSE loss went from 3065.8098 after the first epoch, down to  652.8434 after the 100th epoch. Clearly your model improved it's ability to predict maximumm heart rate `MaxHR` with training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MhC_-6ebE3l"
      },
      "source": [
        "## **Lesson Turn-in**\n",
        "\n",
        "When you have completed and run all of the code cells, use the **File --> Print.. --> Save to PDF** to generate a PDF of your Colab notebook. Save your PDF as `Class_04_1.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgxZvma-bE3l"
      },
      "source": [
        "## Appendix\n",
        "\n",
        "The code in the cells use the Pandas method `pd.describe()` to print out a statistical summary of the column `mean_area` in the Wisconsin Breast Cancer dataset and the column `MaxHR` in the Heart Disease dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dkl5Os1bE3l"
      },
      "outputs": [],
      "source": [
        "areaDF['mean_area'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdjo4WFsbE3m"
      },
      "outputs": [],
      "source": [
        "HRateDF['MaxHR'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Poly-A Tail**\n",
        "\n",
        "## **UNIVAC**\n",
        "\n",
        "![___](https://upload.wikimedia.org/wikipedia/commons/2/2f/Univac_I_Census_dedication.jpg)\n",
        "\n",
        "**UNIVAC (Universal Automatic Computer)** was a line of electronic digital stored-program computers starting with the products of the Eckert–Mauchly Computer Corporation. Later the name was applied to a division of the Remington Rand company and successor organizations.\n",
        "\n",
        "The BINAC, built by the Eckert–Mauchly Computer Corporation, was the first general-purpose computer for commercial use, but it was not a success. The last UNIVAC-badged computer was produced in 1986.\n",
        "\n",
        "### **History and structure**\n",
        "\n",
        "**UNIVAC Sperry Rand label**\n",
        "\n",
        "J. Presper Eckert and John Mauchly built the ENIAC (Electronic Numerical Integrator and Computer) at the University of Pennsylvania's Moore School of Electrical Engineering between 1943 and 1946. A 1946 patent rights dispute with the university led Eckert and Mauchly to depart the Moore School to form the Electronic Control Company, later renamed Eckert–Mauchly Computer Corporation (EMCC), based in Philadelphia, Pennsylvania. That company first built a computer called BINAC (BINary Automatic Computer) for Northrop Aviation (which was little used, or perhaps not at all). Afterwards, the development of UNIVAC began in April 1946.[1] UNIVAC was first intended for the Bureau of the Census, which paid for much of the development, and then was put in production.\n",
        "\n",
        "With the death of EMCC's chairman and chief financial backer Henry L. Straus in a plane crash on October 25, 1949, EMCC was sold to typewriter, office machine, electric razor, and gun maker Remington Rand on February 15, 1950. Eckert and Mauchly now reported to Leslie Groves, the retired army general who had previously managed building The Pentagon and led the Manhattan Project.\n",
        "\n",
        "The most famous UNIVAC product was the UNIVAC I mainframe computer of 1951, which became known for predicting the outcome of the U.S. presidential election the following year: this incident is noteworthy because the computer correctly predicted an Eisenhower landslide over Adlai Stevenson, whereas the final Gallup poll had Eisenhower winning the popular vote 51–49 in a close contest.\n",
        "\n",
        "The prediction led CBS's news boss in New York, Siegfried Mickelson, to believe the computer was in error, and he refused to allow the prediction to be read. Instead, the crew showed some staged theatrics that suggested the computer was not responsive, and announced it was predicting 8–7 odds for an Eisenhower win (the actual prediction was 100–1 in his favour).\n",
        "\n",
        "When the predictions proved true—Eisenhower defeated Stevenson in a landslide, with UNIVAC coming within 3.5% of his popular vote total and four votes of his Electoral College total—Charles Collingwood, the on-air announcer, announced that they had failed to believe the earlier prediction.\n",
        "\n",
        "The United States Army requested a UNIVAC computer from Congress in 1951. Colonel Wade Heavey explained to the Senate subcommittee that the national mobilization planning involved multiple industries and agencies: \"This is a tremendous calculating process...there are equations that can not be solved by hand or by electrically operated computing machines because they involve millions of relationships that would take a lifetime to figure out.\" Heavey told the subcommittee it was needed to help with mobilization and other issues similar to the invasion of Normandy that were based on the relationships of various groups.\n",
        "\n",
        "The UNIVAC was manufactured at Remington Rand's former Eckert-Mauchly Division plant on W Allegheny Avenue in Philadelphia, Pennsylvania. Remington Rand also had an engineering research lab in Norwalk, Connecticut, and later bought Engineering Research Associates (ERA) in St. Paul, Minnesota. In 1953 or 1954 Remington Rand merged their Norwalk tabulating machine division, the ERA \"scientific\" computer division, and the UNIVAC \"business\" computer division into a single division under the UNIVAC name. This severely annoyed those who had been with ERA and with the Norwalk laboratory.\n",
        "\n",
        "In 1955 Remington Rand merged with Sperry Corporation to become Sperry Rand. General Douglas MacArthur, then the chairman of the Board of Directors of Remington Rand, was chosen to continue in that role in the new company. Harry Franklin Vickers, then the President of Sperry Corporation, continued as president and CEO of Sperry Rand. The UNIVAC division of Remington Rand was renamed the Remington Rand Univac division of Sperry Rand. William Norris was put in charge as Vice-President and General Manager reporting to the President of the Remington Rand Division (of Sperry Rand)."
      ],
      "metadata": {
        "id": "JjtoU6RQk199"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6Mup7QGl-A8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}