{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNmHhPf21IGhP8BKi2RWpoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO1173_Fall2025/blob/main/AI_Scientist_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ],
      "metadata": {
        "id": "b_7ZtOqzuPlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BIO 1173: Intro Computational Biology**"
      ],
      "metadata": {
        "id": "T1MqPE_puPYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Module 6: Advanced Topics**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Biology, Health and the Environment](https://sciences.utsa.edu/bhe/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "### Module 6 Material\n",
        "\n",
        "* Part 6.1: Reenforcement Learning\n",
        "* **Part 6.2: AI-Scientist**\n",
        "* Part 6.3: Generative AI\n",
        "* Part 6.4: Text to Images with Stable Diffusion\n"
      ],
      "metadata": {
        "id": "KO49Tsxzue8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "You MUST run the following code cell to get credit for this class lesson. By running this code cell, you will map your GDrive to /content/drive and print out your Google GMAIL address. Your Instructor will use your GMAIL address to verify the author of this class lesson."
      ],
      "metadata": {
        "id": "Kod6uWwDu8nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You must run this cell first\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    # from google.colab import auth\n",
        "    # auth.authenticate_user()\n",
        "    COLAB = True\n",
        "    print(\"Note: Using Google CoLab\")\n",
        "    # import requests\n",
        "    # gcloud_token = !gcloud auth print-access-token\n",
        "    # gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    # print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"**WARNING**: Your GMAIL address was **not** printed in the output below.\")\n",
        "    print(\"**WARNING**: You will NOT receive credit for this lesson.\")\n",
        "    COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g7XGhn1ggT_",
        "outputId": "8d954f89-23a9-4dfd-b086-3684717a863a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: Using Google CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your GMAIL address is included as the last line in the output above."
      ],
      "metadata": {
        "id": "KWgr-KEzvFQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI-Scientist YouTube Introduction**\n",
        "\n",
        "If you want to see a YouTube introduction to this lesson, you can run the next 2 code cells. These YouTube videos are optional."
      ],
      "metadata": {
        "id": "s8M_w6vZggie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo(\"BplDEidA6So\", width=800, height=450)  # First video"
      ],
      "metadata": {
        "id": "CffJbeNOragq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo(\"hP-IzCZAZDc\", width=800, height=450)  # Second video"
      ],
      "metadata": {
        "id": "IsxerWAzrioZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI-Scientist Project by SakanaAI**\n",
        "\n",
        "The **AI-Scientist project** by SakanaAI is an ambitious initiative aimed at automating the entire scientific research process. It leverages advanced **Large Language Models (LLMs)** and other AI technologies to independently conduct research, from generating ideas to writing full scientific papers.\n",
        "\n",
        "### **Below are its key features:**\n",
        "\n",
        "**1. Automated Research Lifecycle**  \n",
        "- The AI-Scientist can:\n",
        "  - Brainstorm novel research ideas.\n",
        "  - Write code and execute experiments.\n",
        "  - Analyze results and present findings in a scientific manuscript.\n",
        "\n",
        "**2. Peer Review and Feedback**  \n",
        "- Includes an automated peer-review system to:\n",
        "  - Evaluate the quality of generated papers.\n",
        "  - Provide constructive feedback.\n",
        "  - Iteratively improve research outputs.\n",
        "\n",
        "**3. Applications**\n",
        "- The system has been applied to various machine learning subfields such as:\n",
        "  - Machine vision.\n",
        "  - Diffusion models.\n",
        "  - Transformers.\n",
        "  - Grokking phenomena.\n",
        "\n",
        "**4. Cost-Effectiveness**\n",
        "- Each research paper can be generated at a cost of approximately **\\$15**, making it highly accessible for democratizing scientific research.\n",
        "\n",
        "**5. Open-Ended Discovery**\n",
        "- Mimics the human scientific community by:\n",
        "  - Continuously developing and refining ideas.\n",
        "  - Creating a growing archive of knowledge.\n",
        "\n",
        "**Impact**\n",
        "This project represents a significant step toward fully autonomous scientific discovery, with the potential to accelerate progress across multiple disciplines.\n",
        "\n"
      ],
      "metadata": {
        "id": "LHLlCwFJnq6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **AI-Scientist Template: MobileNetV3**\n",
        "\n",
        "**Description:** The `AI-Scienctist` template `MobileNetV3` investigates transformer-based autoregressive next-token prediction tasks.\n",
        "\n",
        "This description refers to a type of machine learning task where a transformer-based model is used for autoregressive next-token prediction. Here's what the terms mean:\n",
        "\n",
        "* **Transformer-Based:** A transformer is a type of deep learning model architecture, most famously used in natural language processing (NLP). Transformers use attention mechanisms to understand and process sequences of data, such as text or code.\n",
        "\n",
        "* **Autoregressive:** Autoregressive models predict one token (or word) at a time, based on the previous context. In this case, the model generates text by continually predicting the next token, and it uses its own previous predictions as input for subsequent steps.\n",
        "\n",
        "* **Next-Token Prediction:** The task involves predicting the next token (e.g., word or character) in a sequence, given the preceding tokens. For example, if the input is \"The quick brown\", the model might predict \"fox\" as the next token.\n",
        "\n",
        "In summary, this template is investigating how transformer models can be used to predict the next token in a sequence in an autoregressive manner—an approach commonly seen in language models like GPT. Let me know if you want a deeper dive into any of these concepts!"
      ],
      "metadata": {
        "id": "F386d55Mtupz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STEP 1: Prepare the Data**\n",
        "\n",
        "The code in the cell below prepare the `enwik8` dataset for character-level language modeling. Instead of encoding with `GPT-2 BPE tokens`, we just map characters to `ints`. Will save `train.bin`, `val.bin` containing the `ids`, and `meta.pkl` containing the encoder and decoder and some other related info."
      ],
      "metadata": {
        "id": "7DzdZbnTkwnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "__file__ = \"/content/data\"\n",
        "\n",
        "# download the enwik8 dataset\n",
        "input_file_path = os.path.join(os.path.dirname(__file__), 'enwik8')\n",
        "\n",
        "if not os.path.exists(input_file_path):\n",
        "    data_url = 'https://biologicslab.co/BIO1173/data/enwik8.zip'\n",
        "    r = requests.get(data_url)\n",
        "    with open(os.path.join(os.path.dirname(__file__), 'enwik8.zip'), 'wb') as f:\n",
        "        f.write(r.content)\n",
        "\n",
        "    # unzip the enwik8 dataset\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(os.path.join(os.path.dirname(__file__), 'enwik8.zip'), 'r') as zip_ref:\n",
        "        zip_ref.extractall(os.path.dirname(__file__))\n",
        "\n",
        "with open(input_file_path, 'r', encoding='latin-1') as f:\n",
        "    data = f.read()\n",
        "print(f\"length of dataset in characters: {len(data):,}\")\n",
        "\n",
        "# get all the unique characters that occur in this text\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "print(\"all the unique characters:\", ''.join(chars))\n",
        "print(f\"vocab size: {vocab_size:,}\")\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "# Create endcode/decode functions\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# create the train, validation, and test splits\n",
        "n = len(data)\n",
        "num_test_chars = 5000000\n",
        "\n",
        "# Split data\n",
        "train_data = data[: -2 * num_test_chars]\n",
        "val_data = data[-2 * num_test_chars: -num_test_chars]\n",
        "test_data = data[-num_test_chars:]\n",
        "\n",
        "# Encode all splits to integers\n",
        "train_ids = encode(train_data)\n",
        "val_ids = encode(val_data)\n",
        "test_ids = encode(test_data)\n",
        "\n",
        "# Print results\n",
        "print(f\"train has {len(train_ids):,} tokens\")\n",
        "print(f\"val has {len(val_ids):,} tokens\")\n",
        "print(f\"test has {len(test_ids):,} tokens\")\n",
        "\n",
        "# Export to integer arrays\n",
        "train_ids = np.array(train_ids, dtype=np.uint16)\n",
        "val_ids = np.array(val_ids, dtype=np.uint16)\n",
        "test_ids = np.array(test_ids, dtype=np.uint16)\n",
        "\n",
        "# Convert to binary files\n",
        "train_ids.tofile(os.path.join(os.path.dirname(__file__), 'train.bin'))\n",
        "val_ids.tofile(os.path.join(os.path.dirname(__file__), 'val.bin'))\n",
        "test_ids.tofile(os.path.join(os.path.dirname(__file__), 'test.bin'))\n",
        "\n",
        "# save the meta information as dictionary to later encode/decode\n",
        "meta = {\n",
        "    'vocab_size': vocab_size,\n",
        "    'itos': itos,\n",
        "    'stoi': stoi,\n",
        "}\n",
        "\n",
        "# Save data in the meta diction in Pickel format\n",
        "with open(os.path.join(os.path.dirname(__file__), 'meta.pkl'), 'wb') as f:\n",
        "    pickle.dump(meta, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frwx572YkwT7",
        "outputId": "95f2a7e4-8221-4ac6-b4b8-2ca8f2b05581"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 100,000,000\n",
            "all the unique characters: \t\n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÞàáâãäåæçèéêëìíïð\n",
            "vocab size: 205\n",
            "train has 90,000,000 tokens\n",
            "val has 5,000,000 tokens\n",
            "test has 5,000,000 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AI-Scientist/templates/mobilenetV3\n",
        "#!python experiment.py"
      ],
      "metadata": {
        "id": "L-7dTsU9rOY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224412e4-a096-4720-b5c9-311833dabe20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-Scientist/templates/mobilenetV3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Functions**\n",
        "\n",
        "\n",
        "### **1. `_make_divisible` Function**\n",
        "- **Purpose**: Adjusts channel numbers to ensure they are divisible by a specified value (commonly 8).\n",
        "- **Details**:\n",
        "  - Rounds the channel count (`v`) to the nearest multiple of `divisor`.\n",
        "  - Ensures that the new value does not deviate by more than 10% below the original.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `SqueezeExcitation` Block**\n",
        "- **Purpose**: Implements the Squeeze-and-Excitation (SE) mechanism to recalibrate channel-wise feature responses.\n",
        "- **Components**:\n",
        "  - **Adaptive Average Pooling**: Aggregates spatial features into global channel-wise descriptors.\n",
        "  - **Fully Connected Layers (`fc1` and `fc2`)**: Reduce and then expand channel dimensions to learn importance weights.\n",
        "  - **Activation Functions**: Uses `ReLU` for intermediate activation and `Hardsigmoid` for scaling the weights.\n",
        "- **Forward Pass**:\n",
        "  - Computes the importance scale using pooling and fully connected layers.\n",
        "  - Applies this scale to the input tensor, emphasizing relevant features.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `ConvNormActivation` Block**\n",
        "- **Purpose**: Combines convolution, normalization, and activation into a single reusable block.\n",
        "- **Parameters**:\n",
        "  - Supports flexible configurations for kernel size, stride, padding, dilation, groups, etc.\n",
        "  - Uses `BatchNorm2d` for normalization and `ReLU` for activation by default.\n",
        "- **Details**:\n",
        "  - Dynamically computes padding based on kernel size and dilation.\n",
        "  - Adds a sequence of convolution, normalization, and activation layers.\n",
        "- **Utility**:\n",
        "  - Simplifies the construction of deep learning models by encapsulating common operations.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `InvertedResidualConfig` Class**\n",
        "- **Purpose**: Encodes configuration details for an inverted residual block, which is a core component of MobileNet-like architectures.\n",
        "- **Parameters**:\n",
        "  - Includes channel dimensions (`input_channels`, `expanded_channels`, `out_channels`), kernel size, stride, dilation, activation type, and whether to use SE.\n",
        "  - Applies width scaling (`width_mult`) using `_make_divisible` to adjust channel counts.\n",
        "- **Utility**:\n",
        "  - Provides structured data for constructing and initializing inverted residual blocks.\n",
        "\n",
        "---\n",
        "\n",
        "### **Overall Workflow**\n",
        "These components work together to construct building blocks for resource-efficient neural networks:\n",
        "1. **Squeeze-and-Excitation** adds feature recalibration.\n",
        "2. **ConvNormActivation** provides modular convolutional layers with normalization and activation.\n",
        "3. **InvertedResidualConfig** serves as a blueprint for defining configurations for inverted residual blocks.\n",
        "4. `_make_divisible` ensures compatibility with hardware constraints by aligning channel dimensions to multiples of 8.\n"
      ],
      "metadata": {
        "id": "yRCK5Sj3Pve0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Functions\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, List, Optional, Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# _make_divisible function from torchvision\n",
        "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
        "    \"\"\"\n",
        "    This function ensures that all layers have a channel number that is divisible by 8.\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that rounding down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "# Squeeze-and-Excitation block\n",
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_channels: int,\n",
        "            squeeze_channels: int,\n",
        "            activation: Callable[..., nn.Module] = nn.ReLU,\n",
        "            scale_activation: Callable[..., nn.Module] = nn.Hardsigmoid,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(input_channels, squeeze_channels, 1)\n",
        "        self.fc2 = nn.Conv2d(squeeze_channels, input_channels, 1)\n",
        "        self.activation = activation(inplace=True)\n",
        "        self.scale_activation = scale_activation(inplace=True)\n",
        "\n",
        "    def _scale(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        scale = self.avgpool(input)\n",
        "        scale = self.fc1(scale)\n",
        "        scale = self.activation(scale)\n",
        "        scale = self.fc2(scale)\n",
        "        scale = self.scale_activation(scale)\n",
        "        return scale\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        scale = self._scale(input)\n",
        "        return input * scale\n",
        "\n",
        "\n",
        "# ConvNormActivation block\n",
        "class ConvNormActivation(nn.Sequential):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "            out_channels: int,\n",
        "            kernel_size: Union[int, Tuple[int]] = 3,\n",
        "            stride: Union[int, Tuple[int]] = 1,\n",
        "            padding: Optional[Union[int, Tuple[int], str]] = None,\n",
        "            groups: int = 1,\n",
        "            norm_layer: Optional[Callable[..., nn.Module]] = nn.BatchNorm2d,\n",
        "            activation_layer: Optional[Callable[..., nn.Module]] = nn.ReLU,\n",
        "            dilation: Union[int, Tuple[int]] = 1,\n",
        "            bias: Optional[bool] = None,\n",
        "    ) -> None:\n",
        "\n",
        "        if padding is None:\n",
        "            if isinstance(kernel_size, int):\n",
        "                padding = (kernel_size - 1) // 2 * dilation\n",
        "            else:\n",
        "                padding = tuple((k - 1) // 2 * d for k, d in zip(kernel_size, dilation))\n",
        "        if bias is None:\n",
        "            bias = norm_layer is None\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size,\n",
        "                stride,\n",
        "                padding,\n",
        "                dilation=dilation,\n",
        "                groups=groups,\n",
        "                bias=bias,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if norm_layer is not None:\n",
        "            layers.append(norm_layer(out_channels))\n",
        "        if activation_layer is not None:\n",
        "            layers.append(activation_layer(inplace=True))\n",
        "        super().__init__(*layers)\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "\n",
        "# InvertedResidualConfig class\n",
        "class InvertedResidualConfig:\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_channels: int,\n",
        "            kernel: int,\n",
        "            expanded_channels: int,\n",
        "            out_channels: int,\n",
        "            use_se: bool,\n",
        "            activation: str,\n",
        "            stride: int,\n",
        "            dilation: int,\n",
        "            width_mult: float,\n",
        "    ):\n",
        "        self.input_channels = self.adjust_channels(input_channels, width_mult)\n",
        "        self.kernel = kernel\n",
        "        self.expanded_channels = self.adjust_channels(expanded_channels, width_mult)\n",
        "        self.out_channels = self.adjust_channels(out_channels, width_mult)\n",
        "        self.use_se = use_se\n",
        "        self.activation = activation\n",
        "        self.stride = stride\n",
        "        self.dilation = dilation\n",
        "\n",
        "    @staticmethod\n",
        "    def adjust_channels(channels: int, width_mult: float):\n",
        "        return _make_divisible(channels * width_mult, 8)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I1wDAOQ6QTrb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **InvertedResidual block**\n",
        "\n",
        "### **Overview of the InvertedResidual Block**\n",
        "- The InvertedResidual block is a **lightweight module** that balances computational efficiency and model performance.\n",
        "- It features **expansion**, **depthwise convolution**, and **projection** operations, along with optional **squeeze-and-excitation (SE)** mechanisms to improve representational power.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Components of the Code**\n",
        "\n",
        "#### **1. Initialization (`__init__`)**\n",
        "- **Parameters**:\n",
        "  - `cnf` (InvertedResidualConfig): Specifies configuration details like input/output channels, stride, kernel size, activation type, etc.\n",
        "  - `norm_layer`: Callable defining the normalization layer (e.g., BatchNorm2D).\n",
        "  - `se_layer`: Callable defining the squeeze-and-excitation layer (default uses `SqueezeExcitation` with `Hardsigmoid` activation).\n",
        "- **Steps**:\n",
        "  1. **Residual Connection**:\n",
        "     - Enabled when stride is `1` **and** input/output channels match.\n",
        "  2. **Expand Phase**:\n",
        "     - Expands input channels using a 1x1 pointwise convolution if `expanded_channels` differs from `input_channels`.\n",
        "  3. **Depthwise Convolution**:\n",
        "     - Applies depthwise separable convolution (lightweight operation).\n",
        "     - Convolution groups are equal to the number of input channels, reducing complexity.\n",
        "  4. **Squeeze-and-Excitation (Optional)**:\n",
        "     - Enhances important features while suppressing irrelevant ones.\n",
        "  5. **Projection Phase**:\n",
        "     - Reduces expanded channels back to the required `out_channels` using another 1x1 pointwise convolution.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Residual Connection**\n",
        "- **Purpose**: Combines the input and output of the block (shortcut connection) when:\n",
        "  - The stride is `1`.\n",
        "  - The input and output channels match (`use_res_connect` is `True`).\n",
        "- This aids in learning identity mappings and improves gradient flow.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Forward Pass (`forward`)**\n",
        "- **Steps**:\n",
        "  1. Passes the input through the `self.block` sequence of layers.\n",
        "  2. If `use_res_connect` is `True`, adds the input tensor to the block's output.\n",
        "  3. Returns the result.\n",
        "\n",
        "---\n",
        "\n",
        "### **Detailed Breakdown of Operations**\n",
        "1. **Expand Phase**:\n",
        "   - Uses a 1x1 convolution to increase feature dimensions.\n",
        "   - Followed by a normalization layer and activation (ReLU or Hardswish based on `cnf.activation`).\n",
        "\n",
        "2. **Depthwise Convolution**:\n",
        "   - Performs channel-wise convolution using a kernel size defined in `cnf`.\n",
        "   - Supports dilation for extended receptive fields.\n",
        "\n",
        "3. **Squeeze-and-Excitation (Optional)**:\n",
        "   - Applies the SE mechanism to learn channel-wise importance.\n",
        "   - The number of squeeze channels is a fraction (1/4) of `expanded_channels`, adjusted to be divisible by 8.\n",
        "\n",
        "4. **Projection Phase**:\n",
        "   - Reduces feature dimensions back to `out_channels`.\n",
        "   - Final 1x1 convolution without an activation function.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Advantages**\n",
        "- **Efficiency**: Combines depthwise convolution and pointwise convolution for fewer parameters and computations.\n",
        "- **Flexibility**: The SE mechanism improves performance on a wide range of tasks.\n",
        "- **Residual Connections**: Simplifies optimization by propagating gradients through shortcut paths.\n",
        "\n",
        "---\n",
        "\n",
        "This block is foundational for resource-efficient neural networks like MobileNetV2 and MobileNetV3. Let me know if you'd like to dive deeper into any specific part!\n"
      ],
      "metadata": {
        "id": "mtgiMpx5d5Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, List, Optional, Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# InvertedResidual block\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            cnf: InvertedResidualConfig,\n",
        "            norm_layer: Callable[..., nn.Module],\n",
        "            se_layer: Callable[..., nn.Module] = partial(SqueezeExcitation, scale_activation=nn.Hardsigmoid),\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if not (1 <= cnf.stride <= 2):\n",
        "            raise ValueError(\"Illegal stride value\")\n",
        "\n",
        "        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n",
        "\n",
        "        layers: List[nn.Module] = []\n",
        "        activation_layer = nn.Hardswish if cnf.activation == \"HS\" else nn.ReLU\n",
        "\n",
        "        # Expand phase\n",
        "        if cnf.expanded_channels != cnf.input_channels:\n",
        "            layers.append(\n",
        "                ConvNormActivation(\n",
        "                    cnf.input_channels,\n",
        "                    cnf.expanded_channels,\n",
        "                    kernel_size=1,\n",
        "                    norm_layer=norm_layer,\n",
        "                    activation_layer=activation_layer,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Depthwise convolution\n",
        "        layers.append(\n",
        "            ConvNormActivation(\n",
        "                cnf.expanded_channels,\n",
        "                cnf.expanded_channels,\n",
        "                kernel_size=cnf.kernel,\n",
        "                stride=cnf.stride,\n",
        "                groups=cnf.expanded_channels,\n",
        "                norm_layer=norm_layer,\n",
        "                activation_layer=activation_layer,\n",
        "                dilation=cnf.dilation,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Squeeze-and-Excitation\n",
        "        if cnf.use_se:\n",
        "            squeeze_channels = _make_divisible(cnf.expanded_channels // 4, 8)\n",
        "            layers.append(\n",
        "                se_layer(\n",
        "                    cnf.expanded_channels,\n",
        "                    squeeze_channels,\n",
        "                    activation=nn.ReLU,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Project phase\n",
        "        layers.append(\n",
        "            ConvNormActivation(\n",
        "                cnf.expanded_channels,\n",
        "                cnf.out_channels,\n",
        "                kernel_size=1,\n",
        "                norm_layer=norm_layer,\n",
        "                activation_layer=None,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.block = nn.Sequential(*layers)\n",
        "        self.out_channels = cnf.out_channels\n",
        "        self.is_strided = cnf.stride > 1\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        result = self.block(input)\n",
        "        if self.use_res_connect:\n",
        "            return input + result\n",
        "        else:\n",
        "            return result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uo84G33zd4iN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MobileNetV3 Small model**\n",
        "\n",
        "### **Overview of the Code**\n",
        "This code defines the `MobileNetV3Small` model, a variant of the MobileNetV3 architecture used for lightweight and efficient deep learning applications, particularly for mobile and embedded devices.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Components and Steps**\n",
        "\n",
        "#### **1. Initialization (`__init__`)**\n",
        "- **Purpose**: Sets up the model architecture, consisting of feature extraction, pooling, and classification components.\n",
        "- **Parameters**:\n",
        "  - `num_classes`: Number of output classes for the classification task (default is 1000).\n",
        "  - `width_mult`: Multiplier for scaling the network width, useful for adjusting model size.\n",
        "  - `dropout`: Dropout rate to prevent overfitting (default is 0.2).\n",
        "  - `reduced_tail`: Reduces the number of filters in later layers if set to `True`.\n",
        "  - `dilated`: Uses dilated convolutions for larger receptive fields if set to `True`.\n",
        "  - `norm_layer`: Defines the normalization layer (default is `BatchNorm2d`).\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Inverted Residual Blocks**\n",
        "- **Purpose**: Implements the core building blocks of MobileNetV3, known as *Inverted Residuals*.\n",
        "- **Details**:\n",
        "  - Uses a series of configurations (`InvertedResidualConfig`) to define the input/output channels, kernel sizes, and other properties for each block.\n",
        "  - Layers include depthwise convolutions and pointwise convolutions with optional squeeze-and-excitation (SE) mechanisms and activation functions like ReLU (`RE`) or Hardswish (`HS`).\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Feature Extraction**\n",
        "- The backbone of the network is built with:\n",
        "  - An initial convolutional layer followed by normalization and activation (`ConvNormActivation`).\n",
        "  - A sequence of **inverted residual blocks**, defined by the `inverted_residual_setting`.\n",
        "  - Final layers to extract features with a pointwise convolution.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Pooling and Classification**\n",
        "- **Adaptive Average Pooling**:\n",
        "  - Pools the extracted features into a fixed size.\n",
        "- **Fully Connected Classifier**:\n",
        "  - A sequential classifier that includes:\n",
        "    - A linear layer to reduce dimensions.\n",
        "    - Hardswish activation for non-linearity.\n",
        "    - Dropout for regularization.\n",
        "    - A final linear layer for output predictions (`num_classes`).\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Weight Initialization (`_initialize_weights`)**\n",
        "- **Purpose**: Initializes weights and biases for different types of layers:\n",
        "  - Convolution layers: Initialized with Kaiming normalization.\n",
        "  - BatchNorm layers: Initialized with ones for weights and zeros for biases.\n",
        "  - Linear layers: Initialized with Gaussian distribution.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Forward Pass (`forward`)**\n",
        "- **Input**: A tensor `x` (e.g., an image batch).\n",
        "- **Steps**:\n",
        "  1. Passes the input through the feature extraction layers (`self.features`).\n",
        "  2. Applies average pooling (`self.avgpool`).\n",
        "  3. Flattens the tensor into a 1D vector.\n",
        "  4. Feeds the vector into the classifier for predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Overall Architecture**\n",
        "- The `MobileNetV3Small` model is highly efficient and lightweight, making it suitable for devices with limited computational resources.\n",
        "- It uses innovations like inverted residual blocks, squeeze-and-excitation, and Hardswish activations to achieve a good balance of performance and efficiency.\n",
        "\n",
        "---\n",
        "\n",
        "Let me know if you'd like more details about any part of the code or the theory behind MobileNetV3!\n"
      ],
      "metadata": {
        "id": "qKFl5aZudhju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, List, Optional, Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "# MobileNetV3 Small model\n",
        "class MobileNetV3Small(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_classes: int = 1000,\n",
        "            width_mult: float = 1.0,\n",
        "            dropout: float = 0.2,\n",
        "            reduced_tail: bool = False,\n",
        "            dilated: bool = False,\n",
        "            norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)\n",
        "\n",
        "        layers: List[nn.Module] = []\n",
        "\n",
        "        bneck_conf = partial(InvertedResidualConfig, width_mult=width_mult)\n",
        "\n",
        "        # Build inverted residual setting\n",
        "        reduce_divider = 2 if reduced_tail else 1\n",
        "        dilation = 2 if dilated else 1\n",
        "\n",
        "        inverted_residual_setting = [\n",
        "            # input_c, kernel, exp_c, out_c, se, nl, s, d\n",
        "            bneck_conf(16, 3, 16, 16, True, \"RE\", 2, 1),\n",
        "            bneck_conf(16, 3, 72, 24, False, \"RE\", 2, 1),\n",
        "            bneck_conf(24, 3, 88, 24, False, \"RE\", 1, 1),\n",
        "            bneck_conf(24, 5, 96, 40, True, \"HS\", 2, 1),\n",
        "            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n",
        "            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n",
        "            bneck_conf(40, 5, 120, 48, True, \"HS\", 1, 1),\n",
        "            bneck_conf(48, 5, 144, 48, True, \"HS\", 1, 1),\n",
        "            bneck_conf(48, 5, 288 // reduce_divider, 96 // reduce_divider, True, \"HS\", 2, dilation),\n",
        "            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1, dilation),\n",
        "            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1, dilation),\n",
        "        ]\n",
        "\n",
        "        last_channel = _make_divisible(1024 // reduce_divider * width_mult, 8)\n",
        "\n",
        "        # First layer\n",
        "        firstconv_output_channels = inverted_residual_setting[0].input_channels\n",
        "        layers.append(\n",
        "            ConvNormActivation(\n",
        "                3,\n",
        "                firstconv_output_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2,\n",
        "                norm_layer=norm_layer,\n",
        "                activation_layer=nn.Hardswish,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Building inverted residual blocks\n",
        "        for cnf in inverted_residual_setting:\n",
        "            layers.append(InvertedResidual(cnf, norm_layer))\n",
        "\n",
        "        # Building last several layers\n",
        "        lastconv_input_channels = inverted_residual_setting[-1].out_channels\n",
        "        lastconv_output_channels = _make_divisible(576 * width_mult, 8)\n",
        "        layers.append(\n",
        "            ConvNormActivation(\n",
        "                lastconv_input_channels,\n",
        "                lastconv_output_channels,\n",
        "                kernel_size=1,\n",
        "                norm_layer=norm_layer,\n",
        "                activation_layer=nn.Hardswish,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lastconv_output_channels, last_channel),\n",
        "            nn.Hardswish(inplace=True),\n",
        "            nn.Dropout(p=dropout, inplace=True),\n",
        "            nn.Linear(last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm, nn.SyncBatchNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "zOVcpeOGdhWW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function to create the model and load pretrained weights**\n",
        "\n",
        "### **Overview of the Code**\n",
        "This code provides a full pipeline to create, configure, and initialize a `MobileNetV3 Small` deep learning model, alongside data loading and preprocessing for training and testing.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. `mobilenet_v3_small` Function**\n",
        "- **Purpose**: Builds a `MobileNetV3 Small` model and optionally loads pretrained weights.\n",
        "- **Details**:\n",
        "  - If `pretrained=True`, it downloads weights for the model from TorchVision's pretrained models.\n",
        "  - Handles scenarios where the number of classes in the pretrained weights (`1000`) doesn't match the number of output classes defined in the model (`num_classes`).\n",
        "  - If the classes differ, it discards classifier weights from the pretrained state and updates the current model's state dictionary with the appropriate layers.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `Config` Data Class**\n",
        "- **Purpose**: Encapsulates all configurable parameters for the training process.\n",
        "- **Parameters**:\n",
        "  - **Data settings**: Includes dataset name (`cifar10` or `cifar100`), path, and the number of output classes (`num_classes`).\n",
        "  - **Model settings**: Specifies the model architecture (e.g., `mobilenet_v3_small`).\n",
        "  - **Training settings**: Contains hyperparameters like batch size, learning rate, weight decay, and the number of epochs.\n",
        "  - **System settings**: Specifies the compute device (e.g., `cuda` for GPU or `cpu`) and number of data loading workers.\n",
        "  - **Logging and output**: Includes intervals for logging and evaluation, and output directories for saving results.\n",
        "  - **Miscellaneous**: Includes options like random seed for reproducibility and model compilation for faster training.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `get_data_loaders` Function**\n",
        "- **Purpose**: Prepares DataLoader objects to feed training and testing data to the model.\n",
        "- **Steps**:\n",
        "  1. Checks the dataset specified in the `config` (currently supports `cifar10` and `cifar100`).\n",
        "  2. Applies data augmentation and normalization:\n",
        "     - **Data augmentation**: Random cropping and horizontal flipping are applied during training for better generalization.\n",
        "     - **Normalization**: Adjusts data pixel values to have zero mean and unit variance.\n",
        "  3. Downloads the datasets (CIFAR-10 or CIFAR-100) and applies the transformations.\n",
        "  4. Creates `DataLoader` objects to load batches of data during training and testing.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Overall Workflow**\n",
        "1. **Model Creation**:\n",
        "   - A `MobileNetV3 Small` model is built using the `mobilenet_v3_small` function.\n",
        "   - Pretrained weights can optionally be loaded and adjusted for specific tasks.\n",
        "2. **Configuration**:\n",
        "   - Training and system settings (e.g., device type, batch size) are initialized using the `Config` class.\n",
        "3. **Data Loading**:\n",
        "   - Training and testing datasets (e.g., CIFAR-10) are loaded, preprocessed, and batched using the `get_data_loaders` function.\n",
        "\n",
        "---\n",
        "\n",
        "This code is modular, enabling easy customization and scalability for training `MobileNetV3 Small` on different datasets. Let me know if you'd like more details on any specific part or need help extending this code!\n"
      ],
      "metadata": {
        "id": "8pD1hg9zdT2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create the model and load pretrained weights\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, List, Optional, Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def mobilenet_v3_small(pretrained=False, progress=True, **kwargs):\n",
        "    model = MobileNetV3Small(**kwargs)\n",
        "\n",
        "    if pretrained:\n",
        "        # Load the torchvision model with pretrained weights\n",
        "        from torchvision.models import mobilenet_v3_small as tv_mobilenet_v3_small\n",
        "        from torchvision.models import MobileNet_V3_Small_Weights\n",
        "\n",
        "        # Check for number of classes\n",
        "        if kwargs.get('num_classes', 1000) != 1000:\n",
        "            # We cannot load the classifier weights (different classes)\n",
        "            pretrained_model = tv_mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT, progress=progress)\n",
        "            pretrained_state_dict = pretrained_model.state_dict()\n",
        "            # Remove classifier weights\n",
        "            pretrained_state_dict = {k: v for k, v in pretrained_state_dict.items() if not k.startswith('classifier')}\n",
        "            model_dict = model.state_dict()\n",
        "            print(model_dict.keys())\n",
        "            # Update the model dict\n",
        "            model_dict.update(pretrained_state_dict)\n",
        "            model.load_state_dict(model_dict)\n",
        "        else:\n",
        "            # Load all weights\n",
        "            pretrained_model = tv_mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT, progress=progress)\n",
        "            model.load_state_dict(pretrained_model.state_dict())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    # data\n",
        "    data_path: str = './data'\n",
        "    dataset: str = 'cifar10'\n",
        "    num_classes: int = 10\n",
        "    # model\n",
        "    model: str = 'mobilenet_v3_small'\n",
        "    # training\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 0.01\n",
        "    weight_decay: float = 1e-4\n",
        "    epochs: int = 2\n",
        "    # system\n",
        "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    num_workers: int = 2\n",
        "    # logging\n",
        "    log_interval: int = 100\n",
        "    eval_interval: int = 1000\n",
        "    # output\n",
        "    out_dir: str = 'run_0'\n",
        "    seed: int = 0\n",
        "    # compile for SPEED!\n",
        "    compile_model: bool = False\n",
        "\n",
        "\n",
        "def get_data_loaders(config):\n",
        "    if config.dataset == 'cifar10':\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ])\n",
        "\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ])\n",
        "\n",
        "        train_dataset = datasets.CIFAR10(root=config.data_path, train=True, download=True, transform=transform_train)\n",
        "        test_dataset = datasets.CIFAR10(root=config.data_path, train=False, download=True, transform=transform_test)\n",
        "    elif config.dataset == 'cifar100':\n",
        "        # Placeholder for CIFAR-100 (for future use)\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                                 (0.2675, 0.2565, 0.2761)),\n",
        "        ])\n",
        "\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                                 (0.2675, 0.2565, 0.2761)),\n",
        "        ])\n",
        "\n",
        "        train_dataset = datasets.CIFAR100(root=config.data_path, train=True, download=True, transform=transform_train)\n",
        "        test_dataset = datasets.CIFAR100(root=config.data_path, train=False, download=True, transform=transform_test)\n",
        "        config.num_classes = 100  # Update number of classes for CIFAR-100\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset: {config.dataset}\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "fq2jkiDCdTdK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model**\n",
        "\n",
        "### **Overview of the Code**\n",
        "\n",
        "This Python code defines a training pipeline for a deep learning model using PyTorch.\n",
        "\n",
        "### **Key Components of the Code**\n",
        "\n",
        "1. **Configuration Input**:\n",
        "   - The `config` parameter contains settings like random seed, device type (e.g., `cpu` or `cuda`), learning rate, batch size, number of epochs, etc.\n",
        "   - It ensures reproducibility of results by setting random seeds for `torch`, `numpy`, and Python's `random`.\n",
        "\n",
        "2. **Model Initialization**:\n",
        "   - A `MobileNetV3 Small` model is created and moved to the appropriate device (CPU or GPU).\n",
        "   - If the `config.compile_model` flag is set, it compiles the model for improved performance.\n",
        "\n",
        "3. **Loss Function and Optimization**:\n",
        "   - The loss function is `CrossEntropyLoss`, commonly used for classification tasks.\n",
        "   - The optimizer is `SGD` with momentum and weight decay, combined with a cosine annealing learning rate scheduler for dynamic learning rate adjustment over epochs.\n",
        "\n",
        "4. **Data Loaders**:\n",
        "   - The function `get_data_loaders(config)` is invoked to prepare the training and testing datasets. It loads data in batches for efficiency.\n",
        "\n",
        "5. **Training Loop**:\n",
        "   - For each epoch:\n",
        "     - Sets the model to training mode (`model.train()`).\n",
        "     - Iterates over the training dataset, calculates predictions, computes the loss, and updates model weights using backpropagation (`loss.backward()` and `optimizer.step()`).\n",
        "     - Logs training loss, accuracy, and learning rate at intervals defined by `config.log_interval`.\n",
        "\n",
        "6. **Validation**:\n",
        "   - After training in each epoch, the `evaluate()` function computes loss and accuracy on the validation set.\n",
        "   - If the validation accuracy improves, the model's state is saved to a file (`best_model.pth`).\n",
        "\n",
        "7. **Learning Rate Scheduler**:\n",
        "   - The learning rate scheduler (`CosineAnnealingLR`) adjusts the optimizer's learning rate after each epoch for better convergence.\n",
        "\n",
        "8. **Return Values**:\n",
        "   - The function returns:\n",
        "     - `train_log_info`: A log of training statistics (loss, accuracy, learning rate).\n",
        "     - `val_log_info`: A log of validation statistics (loss, accuracy).\n",
        "     - `best_acc`: The best validation accuracy achieved during training.\n",
        "\n",
        "---\n",
        "\n",
        "This code is structured for training a deep learning model on image classification tasks. Let me know if you'd like to explore any part of it further!\n"
      ],
      "metadata": {
        "id": "J7AzGHF9c8V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, List, Optional, Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def train(config):\n",
        "    # Set random seeds\n",
        "    torch.manual_seed(config.seed)\n",
        "    np.random.seed(config.seed)\n",
        "    random.seed(config.seed)\n",
        "    if config.device == 'cuda':\n",
        "        torch.cuda.manual_seed_all(config.seed)\n",
        "\n",
        "    model = mobilenet_v3_small(pretrained=False, progress=True, num_classes=config.num_classes).to(config.device)\n",
        "\n",
        "    if config.compile_model:\n",
        "        print(\"Compiling the model...\")\n",
        "        model = torch.compile(model)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=0.9, weight_decay=config.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
        "\n",
        "    train_loader, test_loader = get_data_loaders(config)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    train_log_info = []\n",
        "    val_log_info = []\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += targets.size(0)\n",
        "            train_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % config.log_interval == 0:\n",
        "                train_log_info.append({\n",
        "                    'epoch': epoch,\n",
        "                    'batch': batch_idx,\n",
        "                    'loss': train_loss / (batch_idx + 1),\n",
        "                    'acc': 100. * train_correct / train_total,\n",
        "                    'lr': optimizer.param_groups[0]['lr']\n",
        "                })\n",
        "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {train_loss / (batch_idx + 1):.3f}, '\n",
        "                      f'Acc: {100. * train_correct / train_total:.3f}%, '\n",
        "                      f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "        val_loss, val_acc = evaluate(model, test_loader, criterion, config)\n",
        "        val_log_info.append({\n",
        "            'epoch': epoch,\n",
        "            'loss': val_loss,\n",
        "            'acc': val_acc\n",
        "        })\n",
        "        print(f'Validation - Loss: {val_loss:.3f}, Acc: {val_acc:.3f}%')\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), os.path.join(config.out_dir, 'best_model.pth'))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return train_log_info, val_log_info, best_acc"
      ],
      "metadata": {
        "id": "-V2GPyatc8Fi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate and Test Model Functions**"
      ],
      "metadata": {
        "id": "4mOltAGgcgAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and Test Model Functions\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, List, Optional, Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def evaluate(model, dataloader, criterion, config):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(config.device), targets.to(config.device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += targets.size(0)\n",
        "            val_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(dataloader)\n",
        "    val_acc = 100. * val_correct / val_total\n",
        "\n",
        "    return val_loss, val_acc\n",
        "\n",
        "\n",
        "def test(config):\n",
        "    model = MobileNetV3Small(num_classes=config.num_classes).to(config.device)\n",
        "    if config.compile_model:\n",
        "        print(\"Compiling the model for testing...\")\n",
        "        model = torch.compile(model)\n",
        "    model.load_state_dict(torch.load(os.path.join(config.out_dir, 'best_model.pth')))\n",
        "    _, test_loader = get_data_loaders(config)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, config)\n",
        "    print(f'Test - Loss: {test_loss:.3f}, Acc: {test_acc:.3f}%')\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "5xNA1_oqcfub"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model**"
      ],
      "metadata": {
        "id": "tKDckeQ4Z0gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, List, Optional, Union, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Train MobileNetV3 for Image Classification\")\n",
        "    parser.add_argument(\"--data_path\", type=str, default=\"./data\", help=\"Path to save/load the dataset\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128, help=\"Batch size\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=0.01, help=\"Initial learning rate\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=30, help=\"Number of epochs to train\")\n",
        "    parser.add_argument(\"--out_dir\", type=str, default=\"run_0\", help=\"Output directory\")\n",
        "\n",
        "    # Parse arguments and ignore unrecognized ones\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    os.makedirs(args.out_dir, exist_ok=True)\n",
        "    print(f\"Outputs will be saved to {args.out_dir}\")\n",
        "\n",
        "    # Define datasets and number of seeds per dataset\n",
        "    datasets = ['cifar10']  # For now, only CIFAR-10; can add 'cifar100' in the future\n",
        "    num_seeds = {\n",
        "        'cifar10': 1  # Change the number of seeds as desired\n",
        "    }\n",
        "\n",
        "    all_results = {}\n",
        "    final_infos = {}\n",
        "\n",
        "    for dataset in datasets:\n",
        "        final_info_list = []\n",
        "        for seed_offset in range(num_seeds[dataset]):\n",
        "            # Update the config for each run\n",
        "            config = Config(\n",
        "                data_path=args.data_path,\n",
        "                dataset=dataset,\n",
        "                batch_size=args.batch_size,\n",
        "                learning_rate=args.learning_rate,\n",
        "                epochs=args.epochs,\n",
        "                out_dir=args.out_dir,\n",
        "                seed=seed_offset  # Set the seed\n",
        "            )\n",
        "            os.makedirs(config.out_dir, exist_ok=True)\n",
        "            print(f\"Starting training for {dataset} with seed {seed_offset}\")\n",
        "            start_time = time.time()\n",
        "            train_log_info, val_log_info, best_acc = train(config)\n",
        "            total_time = time.time() - start_time\n",
        "\n",
        "            # Run test after training\n",
        "            test_loss, test_acc = test(config)\n",
        "\n",
        "            # Prepare final_info dictionary\n",
        "            final_info = {\n",
        "                \"best_val_acc\": best_acc,\n",
        "                \"test_acc\": test_acc,\n",
        "                \"total_train_time\": total_time,\n",
        "                \"config\": vars(config)\n",
        "            }\n",
        "            final_info_list.append(final_info)\n",
        "\n",
        "            # Store results in all_results\n",
        "            key_prefix = f\"{dataset}_{seed_offset}\"\n",
        "            all_results[f\"{key_prefix}_final_info\"] = final_info\n",
        "            all_results[f\"{key_prefix}_train_log_info\"] = train_log_info\n",
        "            all_results[f\"{key_prefix}_val_log_info\"] = val_log_info\n",
        "\n",
        "            print(f\"Training completed for {dataset} seed {seed_offset}. Best validation accuracy: {best_acc:.2f}%, Test accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "        # Aggregate results over seeds\n",
        "        final_info_dict = {k: [d[k] for d in final_info_list if k in d] for k in final_info_list[0].keys()}\n",
        "        means = {f\"{k}_mean\": np.mean(v) for k, v in final_info_dict.items() if isinstance(v[0], (int, float, float))}\n",
        "        stderrs = {f\"{k}_stderr\": np.std(v) / np.sqrt(len(v)) for k, v in final_info_dict.items() if isinstance(v[0], (int, float, float))}\n",
        "        final_infos[dataset] = {\n",
        "            \"means\": means,\n",
        "            \"stderrs\": stderrs,\n",
        "            \"final_info_dict\": final_info_dict\n",
        "        }\n",
        "\n",
        "    # Save final_infos to final_info.json\n",
        "    with open(os.path.join(args.out_dir, \"final_info.json\"), \"w\") as f:\n",
        "        json.dump(final_infos, f, indent=2)\n",
        "\n",
        "    # Save all_results to all_results.npy\n",
        "    with open(os.path.join(args.out_dir, \"all_results.npy\"), \"wb\") as f:\n",
        "        np.save(f, all_results)\n",
        "\n",
        "    print(f\"All results saved to {args.out_dir}\")\n",
        "\n",
        "# Run program\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_qrr6nAYAUr",
        "outputId": "40f30d27-4c30-40d7-c6a1-71ca30f83ba9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs will be saved to run_0\n",
            "Starting training for cifar10 with seed 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 73.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 2.305, Acc: 10.156%, LR: 0.010000\n",
            "Epoch: 0, Batch: 100, Loss: 2.220, Acc: 15.873%, LR: 0.010000\n",
            "Epoch: 0, Batch: 200, Loss: 2.071, Acc: 20.180%, LR: 0.010000\n",
            "Epoch: 0, Batch: 300, Loss: 1.974, Acc: 23.915%, LR: 0.010000\n",
            "Validation - Loss: 2.308, Acc: 10.000%\n",
            "Epoch: 1, Batch: 0, Loss: 1.691, Acc: 37.500%, LR: 0.009973\n",
            "Epoch: 1, Batch: 100, Loss: 1.647, Acc: 37.686%, LR: 0.009973\n",
            "Epoch: 1, Batch: 200, Loss: 1.622, Acc: 38.891%, LR: 0.009973\n",
            "Epoch: 1, Batch: 300, Loss: 1.598, Acc: 39.942%, LR: 0.009973\n",
            "Validation - Loss: 1.486, Acc: 45.470%\n",
            "Epoch: 2, Batch: 0, Loss: 1.549, Acc: 48.438%, LR: 0.009891\n",
            "Epoch: 2, Batch: 100, Loss: 1.488, Acc: 45.189%, LR: 0.009891\n",
            "Epoch: 2, Batch: 200, Loss: 1.484, Acc: 45.445%, LR: 0.009891\n",
            "Epoch: 2, Batch: 300, Loss: 1.478, Acc: 45.824%, LR: 0.009891\n",
            "Validation - Loss: 1.370, Acc: 50.100%\n",
            "Epoch: 3, Batch: 0, Loss: 1.435, Acc: 47.656%, LR: 0.009755\n",
            "Epoch: 3, Batch: 100, Loss: 1.428, Acc: 47.602%, LR: 0.009755\n",
            "Epoch: 3, Batch: 200, Loss: 1.413, Acc: 48.216%, LR: 0.009755\n",
            "Epoch: 3, Batch: 300, Loss: 1.408, Acc: 48.482%, LR: 0.009755\n",
            "Validation - Loss: 1.319, Acc: 52.670%\n",
            "Epoch: 4, Batch: 0, Loss: 1.438, Acc: 50.000%, LR: 0.009568\n",
            "Epoch: 4, Batch: 100, Loss: 1.373, Acc: 49.961%, LR: 0.009568\n",
            "Epoch: 4, Batch: 200, Loss: 1.358, Acc: 50.653%, LR: 0.009568\n",
            "Epoch: 4, Batch: 300, Loss: 1.351, Acc: 50.784%, LR: 0.009568\n",
            "Validation - Loss: 1.298, Acc: 53.090%\n",
            "Epoch: 5, Batch: 0, Loss: 1.209, Acc: 54.688%, LR: 0.009330\n",
            "Epoch: 5, Batch: 100, Loss: 1.298, Acc: 53.226%, LR: 0.009330\n",
            "Epoch: 5, Batch: 200, Loss: 1.311, Acc: 52.429%, LR: 0.009330\n",
            "Epoch: 5, Batch: 300, Loss: 1.304, Acc: 52.728%, LR: 0.009330\n",
            "Validation - Loss: 1.253, Acc: 55.860%\n",
            "Epoch: 6, Batch: 0, Loss: 1.201, Acc: 60.156%, LR: 0.009045\n",
            "Epoch: 6, Batch: 100, Loss: 1.268, Acc: 53.844%, LR: 0.009045\n",
            "Epoch: 6, Batch: 200, Loss: 1.272, Acc: 53.712%, LR: 0.009045\n",
            "Epoch: 6, Batch: 300, Loss: 1.269, Acc: 53.945%, LR: 0.009045\n",
            "Validation - Loss: 1.234, Acc: 55.280%\n",
            "Epoch: 7, Batch: 0, Loss: 1.362, Acc: 56.250%, LR: 0.008716\n",
            "Epoch: 7, Batch: 100, Loss: 1.252, Acc: 54.626%, LR: 0.008716\n",
            "Epoch: 7, Batch: 200, Loss: 1.229, Acc: 55.667%, LR: 0.008716\n",
            "Epoch: 7, Batch: 300, Loss: 1.233, Acc: 55.458%, LR: 0.008716\n",
            "Validation - Loss: 1.184, Acc: 57.820%\n",
            "Epoch: 8, Batch: 0, Loss: 1.159, Acc: 57.031%, LR: 0.008346\n",
            "Epoch: 8, Batch: 100, Loss: 1.218, Acc: 56.103%, LR: 0.008346\n",
            "Epoch: 8, Batch: 200, Loss: 1.212, Acc: 56.133%, LR: 0.008346\n",
            "Epoch: 8, Batch: 300, Loss: 1.207, Acc: 56.369%, LR: 0.008346\n",
            "Validation - Loss: 1.162, Acc: 58.730%\n",
            "Epoch: 9, Batch: 0, Loss: 1.256, Acc: 56.250%, LR: 0.007939\n",
            "Epoch: 9, Batch: 100, Loss: 1.174, Acc: 57.820%, LR: 0.007939\n",
            "Epoch: 9, Batch: 200, Loss: 1.185, Acc: 57.377%, LR: 0.007939\n",
            "Epoch: 9, Batch: 300, Loss: 1.180, Acc: 57.527%, LR: 0.007939\n",
            "Validation - Loss: 1.129, Acc: 59.800%\n",
            "Epoch: 10, Batch: 0, Loss: 1.158, Acc: 57.031%, LR: 0.007500\n",
            "Epoch: 10, Batch: 100, Loss: 1.153, Acc: 58.601%, LR: 0.007500\n",
            "Epoch: 10, Batch: 200, Loss: 1.159, Acc: 58.411%, LR: 0.007500\n",
            "Epoch: 10, Batch: 300, Loss: 1.153, Acc: 58.583%, LR: 0.007500\n",
            "Validation - Loss: 1.199, Acc: 57.610%\n",
            "Epoch: 11, Batch: 0, Loss: 1.154, Acc: 60.156%, LR: 0.007034\n",
            "Epoch: 11, Batch: 100, Loss: 1.119, Acc: 59.808%, LR: 0.007034\n",
            "Epoch: 11, Batch: 200, Loss: 1.127, Acc: 59.406%, LR: 0.007034\n",
            "Epoch: 11, Batch: 300, Loss: 1.129, Acc: 59.323%, LR: 0.007034\n",
            "Validation - Loss: 1.164, Acc: 58.350%\n",
            "Epoch: 12, Batch: 0, Loss: 1.118, Acc: 60.938%, LR: 0.006545\n",
            "Epoch: 12, Batch: 100, Loss: 1.125, Acc: 59.731%, LR: 0.006545\n",
            "Epoch: 12, Batch: 200, Loss: 1.113, Acc: 60.016%, LR: 0.006545\n",
            "Epoch: 12, Batch: 300, Loss: 1.107, Acc: 60.221%, LR: 0.006545\n",
            "Validation - Loss: 1.074, Acc: 61.650%\n",
            "Epoch: 13, Batch: 0, Loss: 1.049, Acc: 63.281%, LR: 0.006040\n",
            "Epoch: 13, Batch: 100, Loss: 1.081, Acc: 60.938%, LR: 0.006040\n",
            "Epoch: 13, Batch: 200, Loss: 1.090, Acc: 61.015%, LR: 0.006040\n",
            "Epoch: 13, Batch: 300, Loss: 1.087, Acc: 61.119%, LR: 0.006040\n",
            "Validation - Loss: 1.085, Acc: 61.850%\n",
            "Epoch: 14, Batch: 0, Loss: 1.096, Acc: 61.719%, LR: 0.005523\n",
            "Epoch: 14, Batch: 100, Loss: 1.072, Acc: 61.688%, LR: 0.005523\n",
            "Epoch: 14, Batch: 200, Loss: 1.066, Acc: 61.758%, LR: 0.005523\n",
            "Epoch: 14, Batch: 300, Loss: 1.067, Acc: 61.716%, LR: 0.005523\n",
            "Validation - Loss: 1.092, Acc: 61.720%\n",
            "Epoch: 15, Batch: 0, Loss: 1.005, Acc: 61.719%, LR: 0.005000\n",
            "Epoch: 15, Batch: 100, Loss: 1.043, Acc: 62.709%, LR: 0.005000\n",
            "Epoch: 15, Batch: 200, Loss: 1.042, Acc: 62.632%, LR: 0.005000\n",
            "Epoch: 15, Batch: 300, Loss: 1.043, Acc: 62.692%, LR: 0.005000\n",
            "Validation - Loss: 1.019, Acc: 63.790%\n",
            "Epoch: 16, Batch: 0, Loss: 1.040, Acc: 64.844%, LR: 0.004477\n",
            "Epoch: 16, Batch: 100, Loss: 1.011, Acc: 63.753%, LR: 0.004477\n",
            "Epoch: 16, Batch: 200, Loss: 1.021, Acc: 63.231%, LR: 0.004477\n",
            "Epoch: 16, Batch: 300, Loss: 1.023, Acc: 63.362%, LR: 0.004477\n",
            "Validation - Loss: 0.998, Acc: 64.840%\n",
            "Epoch: 17, Batch: 0, Loss: 1.079, Acc: 60.938%, LR: 0.003960\n",
            "Epoch: 17, Batch: 100, Loss: 1.009, Acc: 63.637%, LR: 0.003960\n",
            "Epoch: 17, Batch: 200, Loss: 1.014, Acc: 63.596%, LR: 0.003960\n",
            "Epoch: 17, Batch: 300, Loss: 1.006, Acc: 63.886%, LR: 0.003960\n",
            "Validation - Loss: 0.995, Acc: 64.360%\n",
            "Epoch: 18, Batch: 0, Loss: 1.058, Acc: 64.062%, LR: 0.003455\n",
            "Epoch: 18, Batch: 100, Loss: 0.990, Acc: 64.666%, LR: 0.003455\n",
            "Epoch: 18, Batch: 200, Loss: 0.986, Acc: 64.883%, LR: 0.003455\n",
            "Epoch: 18, Batch: 300, Loss: 0.984, Acc: 64.974%, LR: 0.003455\n",
            "Validation - Loss: 0.963, Acc: 65.550%\n",
            "Epoch: 19, Batch: 0, Loss: 0.881, Acc: 67.188%, LR: 0.002966\n",
            "Epoch: 19, Batch: 100, Loss: 0.964, Acc: 65.849%, LR: 0.002966\n",
            "Epoch: 19, Batch: 200, Loss: 0.978, Acc: 65.030%, LR: 0.002966\n",
            "Epoch: 19, Batch: 300, Loss: 0.978, Acc: 65.031%, LR: 0.002966\n",
            "Validation - Loss: 0.968, Acc: 65.880%\n",
            "Epoch: 20, Batch: 0, Loss: 0.934, Acc: 63.281%, LR: 0.002500\n",
            "Epoch: 20, Batch: 100, Loss: 0.957, Acc: 65.540%, LR: 0.002500\n",
            "Epoch: 20, Batch: 200, Loss: 0.955, Acc: 65.917%, LR: 0.002500\n",
            "Epoch: 20, Batch: 300, Loss: 0.961, Acc: 65.635%, LR: 0.002500\n",
            "Validation - Loss: 0.941, Acc: 66.790%\n",
            "Epoch: 21, Batch: 0, Loss: 1.139, Acc: 60.156%, LR: 0.002061\n",
            "Epoch: 21, Batch: 100, Loss: 0.940, Acc: 65.849%, LR: 0.002061\n",
            "Epoch: 21, Batch: 200, Loss: 0.954, Acc: 65.707%, LR: 0.002061\n",
            "Epoch: 21, Batch: 300, Loss: 0.955, Acc: 65.742%, LR: 0.002061\n",
            "Validation - Loss: 0.939, Acc: 67.050%\n",
            "Epoch: 22, Batch: 0, Loss: 0.974, Acc: 65.625%, LR: 0.001654\n",
            "Epoch: 22, Batch: 100, Loss: 0.946, Acc: 66.352%, LR: 0.001654\n",
            "Epoch: 22, Batch: 200, Loss: 0.944, Acc: 66.402%, LR: 0.001654\n",
            "Epoch: 22, Batch: 300, Loss: 0.941, Acc: 66.360%, LR: 0.001654\n",
            "Validation - Loss: 0.929, Acc: 67.030%\n",
            "Epoch: 23, Batch: 0, Loss: 0.978, Acc: 64.062%, LR: 0.001284\n",
            "Epoch: 23, Batch: 100, Loss: 0.932, Acc: 67.242%, LR: 0.001284\n",
            "Epoch: 23, Batch: 200, Loss: 0.930, Acc: 67.137%, LR: 0.001284\n",
            "Epoch: 23, Batch: 300, Loss: 0.928, Acc: 66.969%, LR: 0.001284\n",
            "Validation - Loss: 0.922, Acc: 67.640%\n",
            "Epoch: 24, Batch: 0, Loss: 0.979, Acc: 60.938%, LR: 0.000955\n",
            "Epoch: 24, Batch: 100, Loss: 0.927, Acc: 66.863%, LR: 0.000955\n",
            "Epoch: 24, Batch: 200, Loss: 0.924, Acc: 66.915%, LR: 0.000955\n",
            "Epoch: 24, Batch: 300, Loss: 0.924, Acc: 67.104%, LR: 0.000955\n",
            "Validation - Loss: 0.917, Acc: 67.390%\n",
            "Epoch: 25, Batch: 0, Loss: 0.803, Acc: 71.094%, LR: 0.000670\n",
            "Epoch: 25, Batch: 100, Loss: 0.922, Acc: 67.079%, LR: 0.000670\n",
            "Epoch: 25, Batch: 200, Loss: 0.917, Acc: 67.428%, LR: 0.000670\n",
            "Epoch: 25, Batch: 300, Loss: 0.922, Acc: 67.232%, LR: 0.000670\n",
            "Validation - Loss: 0.913, Acc: 67.650%\n",
            "Epoch: 26, Batch: 0, Loss: 1.015, Acc: 63.281%, LR: 0.000432\n",
            "Epoch: 26, Batch: 100, Loss: 0.920, Acc: 67.389%, LR: 0.000432\n",
            "Epoch: 26, Batch: 200, Loss: 0.920, Acc: 67.580%, LR: 0.000432\n",
            "Epoch: 26, Batch: 300, Loss: 0.918, Acc: 67.546%, LR: 0.000432\n",
            "Validation - Loss: 0.914, Acc: 67.960%\n",
            "Epoch: 27, Batch: 0, Loss: 0.897, Acc: 69.531%, LR: 0.000245\n",
            "Epoch: 27, Batch: 100, Loss: 0.906, Acc: 67.938%, LR: 0.000245\n",
            "Epoch: 27, Batch: 200, Loss: 0.906, Acc: 67.872%, LR: 0.000245\n",
            "Epoch: 27, Batch: 300, Loss: 0.911, Acc: 67.590%, LR: 0.000245\n",
            "Validation - Loss: 0.911, Acc: 68.050%\n",
            "Epoch: 28, Batch: 0, Loss: 0.866, Acc: 69.531%, LR: 0.000109\n",
            "Epoch: 28, Batch: 100, Loss: 0.929, Acc: 66.963%, LR: 0.000109\n",
            "Epoch: 28, Batch: 200, Loss: 0.915, Acc: 67.623%, LR: 0.000109\n",
            "Epoch: 28, Batch: 300, Loss: 0.908, Acc: 67.818%, LR: 0.000109\n",
            "Validation - Loss: 0.909, Acc: 68.160%\n",
            "Epoch: 29, Batch: 0, Loss: 0.975, Acc: 63.281%, LR: 0.000027\n",
            "Epoch: 29, Batch: 100, Loss: 0.903, Acc: 67.899%, LR: 0.000027\n",
            "Epoch: 29, Batch: 200, Loss: 0.912, Acc: 67.720%, LR: 0.000027\n",
            "Epoch: 29, Batch: 300, Loss: 0.910, Acc: 67.759%, LR: 0.000027\n",
            "Validation - Loss: 0.910, Acc: 68.070%\n",
            "Test - Loss: 0.909, Acc: 68.160%\n",
            "Training completed for cifar10 seed 0. Best validation accuracy: 68.16%, Test accuracy: 68.16%\n",
            "All results saved to run_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9NZXtcy7YAET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NanoGPT**\n",
        "\n",
        "**Description:** This template investigates transformer-based autoregressive next-token prediction tasks."
      ],
      "metadata": {
        "id": "1w87MoAKPwIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prepare the data"
      ],
      "metadata": {
        "id": "_Ui8bNsVPwIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Prepare the data\n",
        "\n",
        "!python data/enwik8/prepare.py\n",
        "!python data/shakespeare_char/prepare.py\n",
        "!python data/text8/prepare.py"
      ],
      "metadata": {
        "id": "tl8KeiygPwIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create baseline runs (machine dependent)"
      ],
      "metadata": {
        "id": "gfbzNk6zPwIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AI-Scientist/templates/nanoGPT\n",
        "!python experiment.py"
      ],
      "metadata": {
        "id": "ybfGkwvSPwIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d5b23c-6a0d-403c-87a8-003ad5b25e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-Scientist/templates/nanoGPT\n",
            "tokens per iteration will be: 16,384\n",
            "found vocab_size = 65 (inside ../../data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 10.65M\n",
            "/content/AI-Scientist/templates/nanoGPT/experiment.py:463: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == \"float16\"))\n",
            "num decayed parameter tensors: 26, with 10,740,096 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 4.2874, val loss 4.2823\n",
            "iter 0: loss 4.2654, time 33093.79ms\n",
            "iter 10: loss 3.2457, time 10.59ms\n",
            "iter 20: loss 2.7914, time 10.98ms\n",
            "iter 30: loss 2.6356, time 10.61ms\n",
            "iter 40: loss 2.5776, time 10.62ms\n",
            "iter 50: loss 2.5276, time 10.68ms\n",
            "iter 60: loss 2.5195, time 10.78ms\n",
            "iter 70: loss 2.4966, time 10.57ms\n",
            "iter 80: loss 2.4972, time 10.53ms\n",
            "iter 90: loss 2.4686, time 10.68ms\n",
            "iter 100: loss 2.4580, time 10.47ms\n",
            "iter 110: loss 2.4629, time 10.80ms\n",
            "iter 120: loss 2.4277, time 10.49ms\n",
            "iter 130: loss 2.4116, time 10.58ms\n",
            "iter 140: loss 2.4119, time 10.50ms\n",
            "iter 150: loss 2.4150, time 10.45ms\n",
            "iter 160: loss 2.3684, time 10.52ms\n",
            "iter 170: loss 2.3523, time 10.60ms\n",
            "iter 180: loss 2.3182, time 10.57ms\n",
            "iter 190: loss 2.2537, time 10.54ms\n",
            "iter 200: loss 2.2186, time 10.51ms\n",
            "iter 210: loss 2.1413, time 10.51ms\n",
            "iter 220: loss 2.1461, time 10.49ms\n",
            "iter 230: loss 2.0719, time 10.61ms\n",
            "iter 240: loss 2.0792, time 11.69ms\n",
            "step 250: train loss 1.9641, val loss 2.0632\n",
            "iter 250: loss 2.0279, time 2678.82ms\n",
            "iter 260: loss 1.9735, time 10.45ms\n",
            "iter 270: loss 1.9803, time 12.97ms\n",
            "iter 280: loss 1.9785, time 10.57ms\n",
            "iter 290: loss 1.9186, time 10.47ms\n",
            "iter 300: loss 1.9040, time 10.56ms\n",
            "iter 310: loss 1.8652, time 10.79ms\n",
            "iter 320: loss 1.8524, time 10.54ms\n",
            "iter 330: loss 1.8213, time 10.49ms\n",
            "iter 340: loss 1.7886, time 10.47ms\n",
            "iter 350: loss 1.8234, time 10.46ms\n",
            "iter 360: loss 1.7719, time 10.64ms\n",
            "iter 370: loss 1.7396, time 10.51ms\n",
            "iter 380: loss 1.7266, time 10.74ms\n",
            "iter 390: loss 1.7320, time 10.50ms\n",
            "iter 400: loss 1.7673, time 10.47ms\n",
            "iter 410: loss 1.6974, time 10.60ms\n",
            "iter 420: loss 1.7167, time 10.74ms\n",
            "iter 430: loss 1.6884, time 10.71ms\n",
            "iter 440: loss 1.6439, time 10.92ms\n",
            "iter 450: loss 1.6556, time 10.51ms\n",
            "iter 460: loss 1.5966, time 10.39ms\n",
            "iter 470: loss 1.6514, time 10.42ms\n",
            "iter 480: loss 1.6197, time 10.48ms\n",
            "iter 490: loss 1.6031, time 10.40ms\n",
            "step 500: train loss 1.5243, val loss 1.7222\n",
            "iter 500: loss 1.5976, time 2670.16ms\n",
            "iter 510: loss 1.6111, time 10.59ms\n",
            "iter 520: loss 1.5889, time 12.91ms\n",
            "iter 530: loss 1.5503, time 10.51ms\n",
            "iter 540: loss 1.6179, time 10.55ms\n",
            "iter 550: loss 1.5565, time 10.48ms\n",
            "iter 560: loss 1.5600, time 10.48ms\n",
            "iter 570: loss 1.5675, time 10.40ms\n",
            "iter 580: loss 1.5297, time 10.90ms\n",
            "iter 590: loss 1.4906, time 10.48ms\n",
            "iter 600: loss 1.5153, time 10.48ms\n",
            "iter 610: loss 1.5458, time 10.59ms\n",
            "iter 620: loss 1.5321, time 10.52ms\n",
            "iter 630: loss 1.5015, time 10.69ms\n",
            "iter 640: loss 1.4646, time 10.42ms\n",
            "iter 650: loss 1.4968, time 10.44ms\n",
            "iter 660: loss 1.5055, time 10.45ms\n",
            "iter 670: loss 1.4399, time 10.51ms\n",
            "iter 680: loss 1.5102, time 10.51ms\n",
            "iter 690: loss 1.4704, time 10.48ms\n",
            "iter 700: loss 1.4847, time 10.62ms\n",
            "iter 710: loss 1.4583, time 10.49ms\n",
            "iter 720: loss 1.4467, time 10.55ms\n",
            "iter 730: loss 1.4251, time 10.50ms\n",
            "iter 740: loss 1.4246, time 10.61ms\n",
            "step 750: train loss 1.3612, val loss 1.5910\n",
            "iter 750: loss 1.4209, time 2689.87ms\n",
            "iter 760: loss 1.4474, time 11.21ms\n",
            "iter 770: loss 1.4299, time 11.42ms\n",
            "iter 780: loss 1.4138, time 10.71ms\n",
            "iter 790: loss 1.4219, time 10.63ms\n",
            "iter 800: loss 1.4356, time 10.69ms\n",
            "iter 810: loss 1.4060, time 11.00ms\n",
            "iter 820: loss 1.4101, time 10.96ms\n",
            "iter 830: loss 1.3989, time 10.67ms\n",
            "iter 840: loss 1.3959, time 10.55ms\n",
            "iter 850: loss 1.3884, time 10.47ms\n",
            "iter 860: loss 1.4024, time 10.43ms\n",
            "iter 870: loss 1.3998, time 10.56ms\n",
            "iter 880: loss 1.3719, time 10.45ms\n",
            "iter 890: loss 1.3890, time 10.46ms\n",
            "iter 900: loss 1.3747, time 10.41ms\n",
            "iter 910: loss 1.3203, time 10.43ms\n",
            "iter 920: loss 1.3675, time 10.40ms\n",
            "iter 930: loss 1.3522, time 10.41ms\n",
            "iter 940: loss 1.3462, time 10.40ms\n",
            "iter 950: loss 1.3509, time 10.47ms\n",
            "iter 960: loss 1.3605, time 10.52ms\n",
            "iter 970: loss 1.3571, time 11.65ms\n",
            "iter 980: loss 1.3541, time 10.46ms\n",
            "iter 990: loss 1.3395, time 10.53ms\n",
            "step 1000: train loss 1.2763, val loss 1.5281\n",
            "iter 1000: loss 1.3331, time 2665.31ms\n",
            "iter 1010: loss 1.3392, time 10.54ms\n",
            "iter 1020: loss 1.3077, time 10.69ms\n",
            "iter 1030: loss 1.3370, time 10.44ms\n",
            "iter 1040: loss 1.3564, time 10.55ms\n",
            "iter 1050: loss 1.2958, time 10.49ms\n",
            "iter 1060: loss 1.3416, time 10.46ms\n",
            "iter 1070: loss 1.3349, time 10.42ms\n",
            "iter 1080: loss 1.3402, time 10.58ms\n",
            "iter 1090: loss 1.3618, time 10.43ms\n",
            "iter 1100: loss 1.3224, time 11.57ms\n",
            "iter 1110: loss 1.3027, time 10.89ms\n",
            "iter 1120: loss 1.2983, time 10.45ms\n",
            "iter 1130: loss 1.2940, time 10.62ms\n",
            "iter 1140: loss 1.2989, time 10.86ms\n",
            "iter 1150: loss 1.3130, time 10.43ms\n",
            "iter 1160: loss 1.3279, time 10.46ms\n",
            "iter 1170: loss 1.3050, time 10.45ms\n",
            "iter 1180: loss 1.3223, time 10.42ms\n",
            "iter 1190: loss 1.2664, time 10.64ms\n",
            "iter 1200: loss 1.2847, time 10.46ms\n",
            "iter 1210: loss 1.2647, time 10.67ms\n",
            "iter 1220: loss 1.3059, time 10.49ms\n",
            "iter 1230: loss 1.3017, time 10.84ms\n",
            "iter 1240: loss 1.3035, time 10.59ms\n",
            "step 1250: train loss 1.2060, val loss 1.4971\n",
            "iter 1250: loss 1.2733, time 2665.20ms\n",
            "iter 1260: loss 1.2830, time 10.58ms\n",
            "iter 1270: loss 1.2683, time 10.60ms\n",
            "iter 1280: loss 1.2568, time 10.44ms\n",
            "iter 1290: loss 1.2864, time 10.74ms\n",
            "iter 1300: loss 1.3067, time 12.54ms\n",
            "iter 1310: loss 1.2344, time 10.70ms\n",
            "iter 1320: loss 1.3013, time 10.72ms\n",
            "iter 1330: loss 1.2705, time 10.86ms\n",
            "iter 1340: loss 1.2982, time 10.73ms\n",
            "iter 1350: loss 1.2561, time 10.72ms\n",
            "iter 1360: loss 1.2719, time 10.74ms\n",
            "iter 1370: loss 1.2566, time 10.94ms\n",
            "iter 1380: loss 1.2728, time 11.01ms\n",
            "iter 1390: loss 1.2486, time 10.71ms\n",
            "iter 1400: loss 1.2597, time 10.70ms\n",
            "iter 1410: loss 1.2486, time 10.68ms\n",
            "iter 1420: loss 1.2698, time 10.54ms\n",
            "iter 1430: loss 1.2389, time 10.54ms\n",
            "iter 1440: loss 1.2519, time 10.48ms\n",
            "iter 1450: loss 1.2277, time 10.54ms\n",
            "iter 1460: loss 1.2428, time 12.00ms\n",
            "iter 1470: loss 1.2206, time 10.42ms\n",
            "iter 1480: loss 1.2123, time 10.66ms\n",
            "iter 1490: loss 1.2357, time 10.53ms\n",
            "step 1500: train loss 1.1551, val loss 1.4723\n",
            "iter 1500: loss 1.1842, time 2663.22ms\n",
            "iter 1510: loss 1.2348, time 10.76ms\n",
            "iter 1520: loss 1.2258, time 10.68ms\n",
            "iter 1530: loss 1.2585, time 10.58ms\n",
            "iter 1540: loss 1.1956, time 10.46ms\n",
            "iter 1550: loss 1.2332, time 10.73ms\n",
            "iter 1560: loss 1.2038, time 12.89ms\n",
            "iter 1570: loss 1.2326, time 10.55ms\n",
            "iter 1580: loss 1.2038, time 10.46ms\n",
            "iter 1590: loss 1.1912, time 10.52ms\n",
            "iter 1600: loss 1.1935, time 10.44ms\n",
            "iter 1610: loss 1.2338, time 10.43ms\n",
            "iter 1620: loss 1.1759, time 10.46ms\n",
            "iter 1630: loss 1.2059, time 10.42ms\n",
            "iter 1640: loss 1.1967, time 10.42ms\n",
            "iter 1650: loss 1.1831, time 11.84ms\n",
            "iter 1660: loss 1.2212, time 10.52ms\n",
            "iter 1670: loss 1.1927, time 10.42ms\n",
            "iter 1680: loss 1.1987, time 11.07ms\n",
            "iter 1690: loss 1.2059, time 10.46ms\n",
            "iter 1700: loss 1.1812, time 10.47ms\n",
            "iter 1710: loss 1.1756, time 10.45ms\n",
            "iter 1720: loss 1.1839, time 10.47ms\n",
            "iter 1730: loss 1.1966, time 12.88ms\n",
            "iter 1740: loss 1.1681, time 10.62ms\n",
            "step 1750: train loss 1.1057, val loss 1.4647\n",
            "iter 1750: loss 1.1855, time 2704.01ms\n",
            "iter 1760: loss 1.1884, time 10.41ms\n",
            "iter 1770: loss 1.1936, time 10.45ms\n",
            "iter 1780: loss 1.1968, time 10.96ms\n",
            "iter 1790: loss 1.2005, time 10.67ms\n",
            "iter 1800: loss 1.1819, time 10.77ms\n",
            "iter 1810: loss 1.1558, time 10.60ms\n",
            "iter 1820: loss 1.1643, time 10.60ms\n",
            "iter 1830: loss 1.1685, time 10.69ms\n",
            "iter 1840: loss 1.1621, time 11.75ms\n",
            "iter 1850: loss 1.1566, time 11.08ms\n",
            "iter 1860: loss 1.1769, time 10.68ms\n",
            "iter 1870: loss 1.1399, time 12.88ms\n",
            "iter 1880: loss 1.1776, time 12.57ms\n",
            "iter 1890: loss 1.1771, time 11.51ms\n",
            "iter 1900: loss 1.1302, time 10.70ms\n",
            "iter 1910: loss 1.1723, time 10.75ms\n",
            "iter 1920: loss 1.1748, time 10.96ms\n",
            "iter 1930: loss 1.1496, time 10.83ms\n",
            "iter 1940: loss 1.1317, time 10.71ms\n",
            "iter 1950: loss 1.1442, time 10.89ms\n",
            "iter 1960: loss 1.1472, time 10.70ms\n",
            "iter 1970: loss 1.1429, time 10.74ms\n",
            "iter 1980: loss 1.1574, time 10.65ms\n",
            "iter 1990: loss 1.1536, time 10.79ms\n",
            "step 2000: train loss 1.0601, val loss 1.4684\n",
            "iter 2000: loss 1.1283, time 2674.10ms\n",
            "iter 2010: loss 1.1199, time 10.57ms\n",
            "iter 2020: loss 1.1201, time 10.73ms\n",
            "iter 2030: loss 1.1564, time 10.91ms\n",
            "iter 2040: loss 1.1453, time 10.91ms\n",
            "iter 2050: loss 1.1133, time 11.16ms\n",
            "iter 2060: loss 1.0987, time 10.63ms\n",
            "iter 2070: loss 1.1292, time 10.81ms\n",
            "iter 2080: loss 1.1195, time 10.47ms\n",
            "iter 2090: loss 1.1356, time 10.48ms\n",
            "iter 2100: loss 1.1383, time 10.85ms\n",
            "iter 2110: loss 1.1323, time 11.10ms\n",
            "iter 2120: loss 1.1271, time 10.57ms\n",
            "iter 2130: loss 1.1391, time 10.54ms\n",
            "iter 2140: loss 1.1368, time 10.54ms\n",
            "iter 2150: loss 1.1311, time 10.61ms\n",
            "iter 2160: loss 1.1465, time 12.92ms\n",
            "iter 2170: loss 1.1315, time 10.56ms\n",
            "iter 2180: loss 1.1171, time 10.53ms\n",
            "iter 2190: loss 1.1120, time 10.63ms\n",
            "iter 2200: loss 1.1225, time 10.63ms\n",
            "iter 2210: loss 1.1137, time 10.58ms\n",
            "iter 2220: loss 1.1223, time 10.51ms\n",
            "iter 2230: loss 1.1227, time 10.69ms\n",
            "iter 2240: loss 1.1176, time 10.58ms\n",
            "step 2250: train loss 1.0120, val loss 1.4795\n",
            "iter 2250: loss 1.1093, time 2692.77ms\n",
            "iter 2260: loss 1.1066, time 10.71ms\n",
            "iter 2270: loss 1.1337, time 10.53ms\n",
            "iter 2280: loss 1.1019, time 11.01ms\n",
            "iter 2290: loss 1.1460, time 10.56ms\n",
            "iter 2300: loss 1.1183, time 10.48ms\n",
            "iter 2310: loss 1.0919, time 10.89ms\n",
            "iter 2320: loss 1.0957, time 10.57ms\n",
            "iter 2330: loss 1.0951, time 10.52ms\n",
            "iter 2340: loss 1.1177, time 13.07ms\n",
            "iter 2350: loss 1.1019, time 10.73ms\n",
            "iter 2360: loss 1.1155, time 10.76ms\n",
            "iter 2370: loss 1.0853, time 10.53ms\n",
            "iter 2380: loss 1.0784, time 10.49ms\n",
            "iter 2390: loss 1.0802, time 12.94ms\n",
            "iter 2400: loss 1.0804, time 12.93ms\n",
            "iter 2410: loss 1.0660, time 10.49ms\n",
            "iter 2420: loss 1.0789, time 10.65ms\n",
            "iter 2430: loss 1.0491, time 10.99ms\n",
            "iter 2440: loss 1.0645, time 10.69ms\n",
            "iter 2450: loss 1.0744, time 10.63ms\n",
            "iter 2460: loss 1.0899, time 11.00ms\n",
            "iter 2470: loss 1.0835, time 10.84ms\n",
            "iter 2480: loss 1.0865, time 10.89ms\n",
            "iter 2490: loss 1.0604, time 10.65ms\n",
            "step 2500: train loss 0.9601, val loss 1.4849\n",
            "iter 2500: loss 1.0853, time 2653.57ms\n",
            "iter 2510: loss 1.0707, time 10.51ms\n",
            "iter 2520: loss 1.0445, time 10.44ms\n",
            "iter 2530: loss 1.0504, time 10.43ms\n",
            "iter 2540: loss 1.0516, time 10.47ms\n",
            "iter 2550: loss 1.0658, time 10.43ms\n",
            "iter 2560: loss 1.0559, time 10.34ms\n",
            "iter 2570: loss 1.0689, time 11.54ms\n",
            "iter 2580: loss 1.0736, time 10.46ms\n",
            "iter 2590: loss 1.0615, time 10.48ms\n",
            "iter 2600: loss 1.0609, time 10.40ms\n",
            "iter 2610: loss 1.0557, time 10.35ms\n",
            "iter 2620: loss 1.0392, time 10.39ms\n",
            "iter 2630: loss 1.0240, time 10.46ms\n",
            "iter 2640: loss 1.0448, time 10.44ms\n",
            "iter 2650: loss 1.0637, time 10.45ms\n",
            "iter 2660: loss 1.0463, time 10.40ms\n",
            "iter 2670: loss 1.0141, time 10.47ms\n",
            "iter 2680: loss 1.0502, time 10.52ms\n",
            "iter 2690: loss 1.0579, time 10.37ms\n",
            "iter 2700: loss 1.0285, time 10.35ms\n",
            "iter 2710: loss 1.0514, time 10.38ms\n",
            "iter 2720: loss 1.0449, time 10.35ms\n",
            "iter 2730: loss 1.0559, time 10.48ms\n",
            "iter 2740: loss 1.0163, time 10.41ms\n",
            "step 2750: train loss 0.9145, val loss 1.5124\n",
            "iter 2750: loss 1.0361, time 2686.02ms\n",
            "iter 2760: loss 1.0283, time 10.55ms\n",
            "iter 2770: loss 1.0193, time 10.49ms\n",
            "iter 2780: loss 1.0201, time 10.57ms\n",
            "iter 2790: loss 1.0401, time 10.45ms\n",
            "iter 2800: loss 1.0134, time 10.57ms\n",
            "iter 2810: loss 1.0420, time 10.44ms\n",
            "iter 2820: loss 1.0256, time 10.65ms\n",
            "iter 2830: loss 1.0337, time 10.46ms\n",
            "iter 2840: loss 0.9960, time 10.49ms\n",
            "iter 2850: loss 1.0240, time 10.42ms\n",
            "iter 2860: loss 1.0228, time 10.56ms\n",
            "iter 2870: loss 1.0009, time 12.92ms\n",
            "iter 2880: loss 1.0332, time 10.49ms\n",
            "iter 2890: loss 1.0104, time 10.84ms\n",
            "iter 2900: loss 0.9883, time 10.79ms\n",
            "iter 2910: loss 1.0435, time 10.76ms\n",
            "iter 2920: loss 1.0086, time 10.98ms\n",
            "iter 2930: loss 0.9948, time 10.60ms\n",
            "iter 2940: loss 0.9905, time 10.56ms\n",
            "iter 2950: loss 1.0265, time 10.57ms\n",
            "iter 2960: loss 0.9955, time 10.46ms\n",
            "iter 2970: loss 0.9911, time 10.39ms\n",
            "iter 2980: loss 0.9934, time 10.86ms\n",
            "iter 2990: loss 0.9815, time 10.47ms\n",
            "step 3000: train loss 0.8686, val loss 1.5248\n",
            "iter 3000: loss 0.9811, time 2687.68ms\n",
            "iter 3010: loss 0.9919, time 10.56ms\n",
            "iter 3020: loss 0.9962, time 10.54ms\n",
            "iter 3030: loss 1.0053, time 10.53ms\n",
            "iter 3040: loss 1.0151, time 10.48ms\n",
            "iter 3050: loss 0.9844, time 11.65ms\n",
            "iter 3060: loss 0.9969, time 11.32ms\n",
            "iter 3070: loss 1.0237, time 10.52ms\n",
            "iter 3080: loss 0.9866, time 10.43ms\n",
            "iter 3090: loss 0.9878, time 10.41ms\n",
            "iter 3100: loss 0.9887, time 10.48ms\n",
            "iter 3110: loss 0.9759, time 10.42ms\n",
            "iter 3120: loss 0.9968, time 10.53ms\n",
            "iter 3130: loss 0.9764, time 10.50ms\n",
            "iter 3140: loss 0.9763, time 10.51ms\n",
            "iter 3150: loss 0.9934, time 10.49ms\n",
            "iter 3160: loss 1.0098, time 10.44ms\n",
            "iter 3170: loss 0.9640, time 10.52ms\n",
            "iter 3180: loss 0.9695, time 10.51ms\n",
            "iter 3190: loss 0.9914, time 10.52ms\n",
            "iter 3200: loss 0.9646, time 10.64ms\n",
            "iter 3210: loss 0.9619, time 10.55ms\n",
            "iter 3220: loss 0.9620, time 10.71ms\n",
            "iter 3230: loss 0.9501, time 10.61ms\n",
            "iter 3240: loss 0.9554, time 10.63ms\n",
            "step 3250: train loss 0.8268, val loss 1.5605\n",
            "iter 3250: loss 0.9673, time 2689.80ms\n",
            "iter 3260: loss 0.9630, time 10.48ms\n",
            "iter 3270: loss 0.9752, time 10.43ms\n",
            "iter 3280: loss 0.9498, time 10.44ms\n",
            "iter 3290: loss 0.9477, time 10.42ms\n",
            "iter 3300: loss 0.9400, time 10.69ms\n",
            "iter 3310: loss 0.9569, time 11.48ms\n",
            "iter 3320: loss 0.9621, time 11.26ms\n",
            "iter 3330: loss 0.9643, time 10.60ms\n",
            "iter 3340: loss 0.9526, time 10.50ms\n",
            "iter 3350: loss 0.9567, time 10.40ms\n",
            "iter 3360: loss 0.9231, time 10.84ms\n",
            "iter 3370: loss 0.9583, time 10.39ms\n",
            "iter 3380: loss 0.9539, time 10.47ms\n",
            "iter 3390: loss 0.9562, time 10.45ms\n",
            "iter 3400: loss 0.9517, time 10.45ms\n",
            "iter 3410: loss 0.9397, time 10.56ms\n",
            "iter 3420: loss 0.9427, time 10.49ms\n",
            "iter 3430: loss 0.9489, time 10.46ms\n",
            "iter 3440: loss 0.9820, time 10.43ms\n",
            "iter 3450: loss 0.9521, time 10.74ms\n",
            "iter 3460: loss 0.9447, time 10.40ms\n",
            "iter 3470: loss 0.9384, time 10.39ms\n",
            "iter 3480: loss 0.9481, time 10.77ms\n",
            "iter 3490: loss 0.9199, time 10.71ms\n",
            "step 3500: train loss 0.7830, val loss 1.5696\n",
            "iter 3500: loss 0.9044, time 2659.11ms\n",
            "iter 3510: loss 0.9258, time 10.46ms\n",
            "iter 3520: loss 0.9196, time 10.43ms\n",
            "iter 3530: loss 0.9518, time 10.48ms\n",
            "iter 3540: loss 0.9307, time 10.59ms\n",
            "iter 3550: loss 0.9186, time 10.65ms\n",
            "iter 3560: loss 0.9558, time 10.43ms\n",
            "iter 3570: loss 0.9307, time 10.56ms\n",
            "iter 3580: loss 0.9326, time 10.42ms\n",
            "iter 3590: loss 0.9248, time 10.55ms\n",
            "iter 3600: loss 0.9248, time 10.43ms\n",
            "iter 3610: loss 0.9145, time 10.47ms\n",
            "iter 3620: loss 0.9091, time 10.45ms\n",
            "iter 3630: loss 0.9264, time 10.44ms\n",
            "iter 3640: loss 0.9135, time 10.70ms\n",
            "iter 3650: loss 0.9111, time 10.48ms\n",
            "iter 3660: loss 0.9361, time 10.41ms\n",
            "iter 3670: loss 0.9393, time 10.39ms\n",
            "iter 3680: loss 0.9040, time 10.68ms\n",
            "iter 3690: loss 0.9338, time 10.46ms\n",
            "iter 3700: loss 0.8665, time 10.41ms\n",
            "iter 3710: loss 0.8877, time 10.41ms\n",
            "iter 3720: loss 0.9020, time 10.55ms\n",
            "iter 3730: loss 0.9024, time 10.42ms\n",
            "iter 3740: loss 0.9030, time 10.51ms\n",
            "step 3750: train loss 0.7438, val loss 1.5998\n",
            "iter 3750: loss 0.9039, time 2660.47ms\n",
            "iter 3760: loss 0.9412, time 12.80ms\n",
            "iter 3770: loss 0.9330, time 10.85ms\n",
            "iter 3780: loss 0.9242, time 10.43ms\n",
            "iter 3790: loss 0.9052, time 10.38ms\n",
            "iter 3800: loss 0.9183, time 10.37ms\n",
            "iter 3810: loss 0.9240, time 10.58ms\n",
            "iter 3820: loss 0.8865, time 10.43ms\n",
            "iter 3830: loss 0.9009, time 10.35ms\n",
            "iter 3840: loss 0.8901, time 10.83ms\n",
            "iter 3850: loss 0.8810, time 10.43ms\n",
            "iter 3860: loss 0.8763, time 10.50ms\n",
            "iter 3870: loss 0.8959, time 10.44ms\n",
            "iter 3880: loss 0.8846, time 10.44ms\n",
            "iter 3890: loss 0.8942, time 10.39ms\n",
            "iter 3900: loss 0.8867, time 10.38ms\n",
            "iter 3910: loss 0.8841, time 10.46ms\n",
            "iter 3920: loss 0.8749, time 10.37ms\n",
            "iter 3930: loss 0.8962, time 10.58ms\n",
            "iter 3940: loss 0.8727, time 11.53ms\n",
            "iter 3950: loss 0.8798, time 10.42ms\n",
            "iter 3960: loss 0.9131, time 10.50ms\n",
            "iter 3970: loss 0.8916, time 10.45ms\n",
            "iter 3980: loss 0.8973, time 10.40ms\n",
            "iter 3990: loss 0.8744, time 10.38ms\n",
            "step 4000: train loss 0.7114, val loss 1.6250\n",
            "iter 4000: loss 0.8640, time 2682.99ms\n",
            "iter 4010: loss 0.8748, time 12.82ms\n",
            "iter 4020: loss 0.8886, time 10.48ms\n",
            "iter 4030: loss 0.8761, time 10.61ms\n",
            "iter 4040: loss 0.8781, time 10.69ms\n",
            "iter 4050: loss 0.8728, time 11.72ms\n",
            "iter 4060: loss 0.8690, time 10.98ms\n",
            "iter 4070: loss 0.8596, time 10.68ms\n",
            "iter 4080: loss 0.8902, time 10.64ms\n",
            "iter 4090: loss 0.8465, time 10.66ms\n",
            "iter 4100: loss 0.9007, time 10.60ms\n",
            "iter 4110: loss 0.8743, time 10.67ms\n",
            "iter 4120: loss 0.8775, time 10.47ms\n",
            "iter 4130: loss 0.8595, time 10.57ms\n",
            "iter 4140: loss 0.8823, time 10.72ms\n",
            "iter 4150: loss 0.8723, time 10.54ms\n",
            "iter 4160: loss 0.8497, time 10.98ms\n",
            "iter 4170: loss 0.8657, time 10.88ms\n",
            "iter 4180: loss 0.8705, time 10.52ms\n",
            "iter 4190: loss 0.8685, time 10.47ms\n",
            "iter 4200: loss 0.8462, time 10.53ms\n",
            "iter 4210: loss 0.8608, time 10.78ms\n",
            "iter 4220: loss 0.8535, time 10.64ms\n",
            "iter 4230: loss 0.8825, time 10.50ms\n",
            "iter 4240: loss 0.8744, time 10.49ms\n",
            "step 4250: train loss 0.6813, val loss 1.6459\n",
            "iter 4250: loss 0.8720, time 2637.41ms\n",
            "iter 4260: loss 0.8589, time 10.60ms\n",
            "iter 4270: loss 0.8603, time 11.17ms\n",
            "iter 4280: loss 0.8651, time 10.91ms\n",
            "iter 4290: loss 0.8312, time 10.63ms\n",
            "iter 4300: loss 0.8265, time 10.80ms\n",
            "iter 4310: loss 0.8545, time 11.06ms\n",
            "iter 4320: loss 0.8394, time 10.57ms\n",
            "iter 4330: loss 0.8615, time 10.88ms\n",
            "iter 4340: loss 0.8282, time 11.97ms\n",
            "iter 4350: loss 0.8406, time 10.55ms\n",
            "iter 4360: loss 0.8591, time 10.72ms\n",
            "iter 4370: loss 0.8521, time 10.55ms\n",
            "iter 4380: loss 0.8256, time 10.48ms\n",
            "iter 4390: loss 0.8680, time 10.60ms\n",
            "iter 4400: loss 0.8510, time 10.52ms\n",
            "iter 4410: loss 0.8685, time 10.54ms\n",
            "iter 4420: loss 0.8620, time 10.85ms\n",
            "iter 4430: loss 0.8449, time 12.84ms\n",
            "iter 4440: loss 0.8549, time 10.56ms\n",
            "iter 4450: loss 0.8494, time 10.66ms\n",
            "iter 4460: loss 0.8413, time 10.63ms\n",
            "iter 4470: loss 0.8494, time 10.58ms\n",
            "iter 4480: loss 0.8298, time 10.58ms\n",
            "iter 4490: loss 0.8491, time 10.61ms\n",
            "step 4500: train loss 0.6555, val loss 1.6641\n",
            "iter 4500: loss 0.8609, time 2673.63ms\n",
            "iter 4510: loss 0.8451, time 10.71ms\n",
            "iter 4520: loss 0.8394, time 10.72ms\n",
            "iter 4530: loss 0.8499, time 11.70ms\n",
            "iter 4540: loss 0.8389, time 11.72ms\n",
            "iter 4550: loss 0.8783, time 10.65ms\n",
            "iter 4560: loss 0.8502, time 12.20ms\n",
            "iter 4570: loss 0.8402, time 13.03ms\n",
            "iter 4580: loss 0.8545, time 10.92ms\n",
            "iter 4590: loss 0.8597, time 10.58ms\n",
            "iter 4600: loss 0.8267, time 10.48ms\n",
            "iter 4610: loss 0.8775, time 10.54ms\n",
            "iter 4620: loss 0.8325, time 10.60ms\n",
            "iter 4630: loss 0.8261, time 10.54ms\n",
            "iter 4640: loss 0.8440, time 10.60ms\n",
            "iter 4650: loss 0.8620, time 10.53ms\n",
            "iter 4660: loss 0.8498, time 10.57ms\n",
            "iter 4670: loss 0.8343, time 10.51ms\n",
            "iter 4680: loss 0.8512, time 10.54ms\n",
            "iter 4690: loss 0.8402, time 10.51ms\n",
            "iter 4700: loss 0.8299, time 10.60ms\n",
            "iter 4710: loss 0.7883, time 10.55ms\n",
            "iter 4720: loss 0.8418, time 10.67ms\n",
            "iter 4730: loss 0.8179, time 10.58ms\n",
            "iter 4740: loss 0.8348, time 10.61ms\n",
            "step 4750: train loss 0.6380, val loss 1.6853\n",
            "iter 4750: loss 0.8048, time 2669.72ms\n",
            "iter 4760: loss 0.8134, time 10.49ms\n",
            "iter 4770: loss 0.8014, time 10.80ms\n",
            "iter 4780: loss 0.8131, time 10.49ms\n",
            "iter 4790: loss 0.8343, time 10.47ms\n",
            "iter 4800: loss 0.8219, time 10.54ms\n",
            "iter 4810: loss 0.8405, time 12.65ms\n",
            "iter 4820: loss 0.8207, time 11.84ms\n",
            "iter 4830: loss 0.8259, time 10.47ms\n",
            "iter 4840: loss 0.8332, time 10.77ms\n",
            "iter 4850: loss 0.8191, time 10.45ms\n",
            "iter 4860: loss 0.8273, time 10.75ms\n",
            "iter 4870: loss 0.8020, time 10.48ms\n",
            "iter 4880: loss 0.8280, time 10.39ms\n",
            "iter 4890: loss 0.8125, time 11.08ms\n",
            "iter 4900: loss 0.8071, time 10.44ms\n",
            "iter 4910: loss 0.8235, time 10.47ms\n",
            "iter 4920: loss 0.8139, time 10.40ms\n",
            "iter 4930: loss 0.8120, time 10.39ms\n",
            "iter 4940: loss 0.8096, time 10.63ms\n",
            "iter 4950: loss 0.8281, time 10.49ms\n",
            "iter 4960: loss 0.8338, time 10.35ms\n",
            "iter 4970: loss 0.7821, time 10.34ms\n",
            "iter 4980: loss 0.7948, time 10.41ms\n",
            "iter 4990: loss 0.8247, time 11.83ms\n",
            "step 5000: train loss 0.6246, val loss 1.6969\n",
            "iter 5000: loss 0.8162, time 2638.49ms\n",
            "training done\n",
            "Best validation loss: 1.4646967649459839\n",
            "Total train time: 2.45 mins\n",
            "Loading meta from ../../data/shakespeare_char/meta.pkl...\n",
            "Sample 1:\n",
            " beauty;\n",
            "And yet, to raise upon the world to get.\n",
            "\n",
            "Lord:\n",
            "How fares our grace? is he not with her?\n",
            "\n",
            "Lord:\n",
            "Ay, sirrah, and in a chale for twenty speaks,\n",
            "And do with such a substance from the fire?\n",
            "Darest thou suggest the gallant? and these babes\n",
            "That thou proclaim'st the walls to the abuse.\n",
            "\n",
            "LEONTES:\n",
            "We have we here deserved it.\n",
            "\n",
            "HERMIONE:\n",
            "Though that be so, hast still thy unbruised\n",
            "In thy fruit-desire should here to lose her\n",
            "That's content; though for thence they should not not\n",
            "Be content to be ta\n",
            "Inference time: 2.61 seconds\n",
            "Tokens per second: 191.90\n",
            "---------------\n",
            "Sample 2:\n",
            " such every credits:\n",
            "That they have ever heard of sorrow joy\n",
            "Shall have their feebled with habit,\n",
            "And their virtue substance in their banishments\n",
            "Which proud happily to sear their suffrages,\n",
            "Or else the souls would spring a paraged to the earth,\n",
            "When they will bear them as a shepherd's day,\n",
            "Which are all fright as lies like a cave.\n",
            "The sights are dead, and heavily in the chiefest shop,\n",
            "Provokes thee to as a sweeter fellow's eye,\n",
            "And then is not fished as the glorious earth.\n",
            "\n",
            "Second Gentleman:\n",
            "I t\n",
            "Inference time: 1.81 seconds\n",
            "Tokens per second: 276.24\n",
            "---------------\n",
            "Sample 3:\n",
            " bastard be the king: she when you should not\n",
            "do it take it off.\n",
            "\n",
            "Provost:\n",
            "It is a point of her most wish: he hath been time to\n",
            "complain with him, but I will compare him. If I will\n",
            "hence am your strange thief.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "You have not some speech well: but your cannot awake\n",
            "your acknowledge and sellence; since it against\n",
            "your deputy; and I have it would say another.\n",
            "\n",
            "LUCIO:\n",
            "There was the duke was the husband and for his life off.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What, how now! what, what?\n",
            "\n",
            "ISABELLA:\n",
            "How now\n",
            "Inference time: 1.80 seconds\n",
            "Tokens per second: 278.52\n",
            "---------------\n",
            "Sample 4:\n",
            " let us alone;\n",
            "And therefore it be disturb'd for a death.\n",
            "\n",
            "KING RICHARD III:\n",
            "Then, en it your majesty and your royal self.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "To think his majesty to reign his chair:\n",
            "And for what is this, my lord?\n",
            "\n",
            "KING RICHARD III:\n",
            "Well, belike a sail, thou hast said is afe.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "What should she do fear? art thou mean to shriek?\n",
            "\n",
            "KING RICHARD III:\n",
            "Thou detest me; and I am not for thee,\n",
            "Thou wilt be safe for my holy life.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Nay, then if the world is for hell she speak \n",
            "Inference time: 1.80 seconds\n",
            "Tokens per second: 277.13\n",
            "---------------\n",
            "Sample 5:\n",
            " will you be taught me, and entreat your grace.\n",
            "\n",
            "GLOUCESTER:\n",
            "Be pitiful, like a dangerous corse,\n",
            "Like to a corse, when I saw this day of course,\n",
            "Who now but to tutor in the sadness,\n",
            "When mine own living steel'd strokes, not flatter'd with grief,\n",
            "To fail in the bounds of encounters' bosoms,\n",
            "Scars your friends and quietness of business:\n",
            "For I have done a sleeper-house,\n",
            "My colours will well have seem'd, if they be thrown,\n",
            "As like me on your loving for her eyes.\n",
            "\n",
            "CORIOLANUS:\n",
            "Let's soldiers, prove me \n",
            "Inference time: 1.80 seconds\n",
            "Tokens per second: 278.53\n",
            "---------------\n",
            "Sample 6:\n",
            " my father's son,\n",
            "She would be her come to the block of the farther:\n",
            "Your highness shall have many sons hold you:\n",
            "I am bound with him, sanctuary, man.\n",
            "\n",
            "CLEOMENES:\n",
            "How! am fair befal to have an hour?\n",
            "\n",
            "HERMIONE:\n",
            "I mean, the great corn of this moveable day,\n",
            "That may suffer us his to the Capitol?\n",
            "\n",
            "MARCIUS:\n",
            "Well, well, sir.\n",
            "\n",
            "COMINIUS:\n",
            "I know you well enough.\n",
            "\n",
            "MARCIUS:\n",
            "Well, well, well, well.\n",
            "\n",
            "MARCIUS:\n",
            "I'll bring you them--\n",
            "\n",
            "All:\n",
            "Ay, and those shall be their tears, that we may claim hither.\n",
            "\n",
            "CORIOLANUS\n",
            "Inference time: 1.79 seconds\n",
            "Tokens per second: 279.82\n",
            "---------------\n",
            "Sample 7:\n",
            " will I make a lustful earth and me.\n",
            "\n",
            "ROMEO:\n",
            "Kind sinve your highness shall be so discover'd.\n",
            "\n",
            "JULIET:\n",
            "Art thou swear to me?\n",
            "\n",
            "ROMEO:\n",
            "Die and mother's hope.\n",
            "\n",
            "ROMEO:\n",
            "How now! what noise? where is this speech?\n",
            "\n",
            "Nurse:\n",
            "How? what is become of love?\n",
            "\n",
            "Nurse:\n",
            "It is it your ghostly son will take it on you;\n",
            "For it is coming to you there, you shall be gone.\n",
            "\n",
            "ROMEO:\n",
            "I have no time to her.\n",
            "\n",
            "Nurse:\n",
            "What, what news?\n",
            "\n",
            "ROMEO:\n",
            "The more will strike and bring me to this basilisk;\n",
            "This is not thirty.\n",
            "\n",
            "JULIET:\n",
            "No, not\n",
            "Inference time: 1.81 seconds\n",
            "Tokens per second: 276.02\n",
            "---------------\n",
            "Sample 8:\n",
            " do it before the ensuing,\n",
            "And for the end of the prisoners of their death.\n",
            "\n",
            "RICHMOND:\n",
            "Cry mercy, my lord; I pray you, my lord:\n",
            "I'll to die with this, and fetch more of mine.\n",
            "\n",
            "KING RICHARD II:\n",
            "I think there be a man--\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "The noble duke that I set at allow.\n",
            "\n",
            "KING RICHARD II:\n",
            "Saw'st thou thy hands with his sight?\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "My lord, I come to my service hither;\n",
            "And to-morrow morning to thee thus ancient may.\n",
            "\n",
            "CLIFFORD:\n",
            "Convenient is born to the field; who hast soldiers\n",
            "Shall be \n",
            "Inference time: 1.83 seconds\n",
            "Tokens per second: 273.64\n",
            "---------------\n",
            "Sample 9:\n",
            " slanderous death,\n",
            "The manner of the tables of his face,\n",
            "The deadly chairs and full of water souls,\n",
            "Through much bloody with the kingly soldiers\n",
            "Ere I lived the truth of it as green\n",
            "As the night day sets on earth from my faults,\n",
            "And so in pure to the dust and sound so province\n",
            "Lest in the uncle the subject he is dear;\n",
            "And so it is my father's life to be so.\n",
            "\n",
            "KING RICHARD II:\n",
            "He is in his reason, that stopp'd his friends.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "So would he do him in his policy\n",
            "That he hath help to say,\n",
            "Inference time: 1.81 seconds\n",
            "Tokens per second: 276.65\n",
            "---------------\n",
            "Sample 10:\n",
            " minded actions, whereon-songs are conceived,\n",
            "That I found it on the design.\n",
            "\n",
            "BENVOLIO:\n",
            "And that is some speech, such a kinsman's hope,\n",
            "To say you will encounter with a kind of blood,\n",
            "To see if I must be so good up to horse.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "In God's name, sir, let me know her alone.\n",
            "\n",
            "PARIS:\n",
            "How fares your husband! how now, Canst thou will!\n",
            "\n",
            "CAMILLO:\n",
            "Sir, I know not what he doth now; for we are two now.\n",
            "\n",
            "POLIXENES:\n",
            "I know the sacrament he hath promised me to\n",
            "some audience with a life bear, which \n",
            "Inference time: 1.83 seconds\n",
            "Tokens per second: 273.21\n",
            "---------------\n",
            "Average tokens per second: 268.17\n",
            "tokens per iteration will be: 16,384\n",
            "found vocab_size = 65 (inside ../../data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 10.65M\n",
            "/content/AI-Scientist/templates/nanoGPT/experiment.py:463: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == \"float16\"))\n",
            "num decayed parameter tensors: 26, with 10,740,096 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 4.2372, val loss 4.2295\n",
            "iter 0: loss 4.2337, time 2670.66ms\n",
            "iter 10: loss 3.2253, time 10.67ms\n",
            "iter 20: loss 2.7688, time 10.60ms\n",
            "iter 30: loss 2.6201, time 10.53ms\n",
            "iter 40: loss 2.5385, time 10.46ms\n",
            "iter 50: loss 2.5372, time 10.59ms\n",
            "iter 60: loss 2.4993, time 10.56ms\n",
            "iter 70: loss 2.4939, time 13.19ms\n",
            "iter 80: loss 2.4949, time 12.96ms\n",
            "iter 90: loss 2.4797, time 10.56ms\n",
            "iter 100: loss 2.4708, time 10.57ms\n",
            "iter 110: loss 2.4355, time 10.67ms\n",
            "iter 120: loss 2.4508, time 10.58ms\n",
            "iter 130: loss 2.4279, time 11.01ms\n",
            "iter 140: loss 2.4240, time 10.56ms\n",
            "iter 150: loss 2.3578, time 10.56ms\n",
            "iter 160: loss 2.3841, time 10.85ms\n",
            "iter 170: loss 2.3390, time 10.80ms\n",
            "iter 180: loss 2.3151, time 10.55ms\n",
            "iter 190: loss 2.2795, time 11.23ms\n",
            "iter 200: loss 2.2414, time 10.70ms\n",
            "iter 210: loss 2.1618, time 11.58ms\n",
            "iter 220: loss 2.1225, time 10.54ms\n",
            "iter 230: loss 2.0827, time 10.73ms\n",
            "iter 240: loss 2.0628, time 10.63ms\n",
            "step 250: train loss 1.9850, val loss 2.0815\n",
            "iter 250: loss 2.0316, time 2730.93ms\n",
            "iter 260: loss 2.0134, time 10.58ms\n",
            "iter 270: loss 1.9550, time 10.59ms\n",
            "iter 280: loss 1.9412, time 11.31ms\n",
            "iter 290: loss 1.9147, time 10.59ms\n",
            "iter 300: loss 1.9025, time 10.53ms\n",
            "iter 310: loss 1.9052, time 10.62ms\n",
            "iter 320: loss 1.8538, time 10.93ms\n",
            "iter 330: loss 1.8664, time 10.64ms\n",
            "iter 340: loss 1.8000, time 10.51ms\n",
            "iter 350: loss 1.7867, time 10.54ms\n",
            "iter 360: loss 1.7904, time 10.61ms\n",
            "iter 370: loss 1.7805, time 10.63ms\n",
            "iter 380: loss 1.7452, time 10.62ms\n",
            "iter 390: loss 1.7353, time 10.61ms\n",
            "iter 400: loss 1.7102, time 10.58ms\n",
            "iter 410: loss 1.7129, time 10.70ms\n",
            "iter 420: loss 1.7140, time 10.57ms\n",
            "iter 430: loss 1.6924, time 10.56ms\n",
            "iter 440: loss 1.6666, time 10.50ms\n",
            "iter 450: loss 1.6412, time 10.75ms\n",
            "iter 460: loss 1.6809, time 10.62ms\n",
            "iter 470: loss 1.6502, time 10.45ms\n",
            "iter 480: loss 1.6588, time 10.63ms\n",
            "iter 490: loss 1.6104, time 10.58ms\n",
            "step 500: train loss 1.5430, val loss 1.7426\n",
            "iter 500: loss 1.6102, time 2646.89ms\n",
            "iter 510: loss 1.6057, time 10.59ms\n",
            "iter 520: loss 1.5732, time 10.59ms\n",
            "iter 530: loss 1.6002, time 10.50ms\n",
            "iter 540: loss 1.5565, time 10.59ms\n",
            "iter 550: loss 1.5522, time 10.54ms\n",
            "iter 560: loss 1.5612, time 10.58ms\n",
            "iter 570: loss 1.5738, time 10.78ms\n",
            "iter 580: loss 1.5173, time 10.63ms\n",
            "iter 590: loss 1.5385, time 10.59ms\n",
            "iter 600: loss 1.5043, time 10.64ms\n",
            "iter 610: loss 1.5396, time 10.56ms\n",
            "iter 620: loss 1.4903, time 10.82ms\n",
            "iter 630: loss 1.5487, time 10.64ms\n",
            "iter 640: loss 1.4707, time 10.47ms\n",
            "iter 650: loss 1.4948, time 10.56ms\n",
            "iter 660: loss 1.4926, time 10.81ms\n",
            "iter 670: loss 1.4841, time 11.93ms\n",
            "iter 680: loss 1.4530, time 11.00ms\n",
            "iter 690: loss 1.4613, time 10.59ms\n",
            "iter 700: loss 1.4621, time 11.71ms\n",
            "iter 710: loss 1.4844, time 10.63ms\n",
            "iter 720: loss 1.4470, time 10.55ms\n",
            "iter 730: loss 1.4518, time 10.58ms\n",
            "iter 740: loss 1.4367, time 11.10ms\n",
            "step 750: train loss 1.3660, val loss 1.5965\n",
            "iter 750: loss 1.4433, time 2682.35ms\n",
            "iter 760: loss 1.4017, time 10.57ms\n",
            "iter 770: loss 1.4229, time 10.67ms\n",
            "iter 780: loss 1.4258, time 10.53ms\n",
            "iter 790: loss 1.3884, time 10.55ms\n",
            "iter 800: loss 1.4198, time 10.69ms\n",
            "iter 810: loss 1.4344, time 10.59ms\n",
            "iter 820: loss 1.4107, time 10.98ms\n",
            "iter 830: loss 1.4070, time 10.60ms\n",
            "iter 840: loss 1.3989, time 10.56ms\n",
            "iter 850: loss 1.4238, time 10.68ms\n",
            "iter 860: loss 1.3764, time 10.62ms\n",
            "iter 870: loss 1.4006, time 10.64ms\n",
            "iter 880: loss 1.3661, time 10.65ms\n",
            "iter 890: loss 1.3791, time 10.66ms\n",
            "iter 900: loss 1.3620, time 10.68ms\n",
            "iter 910: loss 1.4004, time 10.67ms\n",
            "iter 920: loss 1.3729, time 10.58ms\n",
            "iter 930: loss 1.3609, time 10.60ms\n",
            "iter 940: loss 1.3690, time 10.94ms\n",
            "iter 950: loss 1.3495, time 10.56ms\n",
            "iter 960: loss 1.3899, time 10.52ms\n",
            "iter 970: loss 1.3753, time 10.49ms\n",
            "iter 980: loss 1.3684, time 10.47ms\n",
            "iter 990: loss 1.3041, time 10.56ms\n",
            "step 1000: train loss 1.2769, val loss 1.5190\n",
            "iter 1000: loss 1.3432, time 2683.03ms\n",
            "iter 1010: loss 1.3613, time 10.55ms\n",
            "iter 1020: loss 1.3557, time 10.60ms\n",
            "iter 1030: loss 1.3277, time 10.73ms\n",
            "iter 1040: loss 1.3027, time 10.78ms\n",
            "iter 1050: loss 1.3042, time 10.54ms\n",
            "iter 1060: loss 1.3063, time 10.72ms\n",
            "iter 1070: loss 1.3268, time 10.57ms\n",
            "iter 1080: loss 1.3254, time 10.62ms\n",
            "iter 1090: loss 1.3586, time 10.55ms\n",
            "iter 1100: loss 1.2933, time 10.56ms\n",
            "iter 1110: loss 1.3068, time 11.08ms\n",
            "iter 1120: loss 1.2915, time 10.66ms\n",
            "iter 1130: loss 1.3105, time 10.63ms\n",
            "iter 1140: loss 1.3023, time 10.59ms\n",
            "iter 1150: loss 1.2856, time 10.96ms\n",
            "iter 1160: loss 1.2841, time 10.63ms\n",
            "iter 1170: loss 1.2762, time 10.64ms\n",
            "iter 1180: loss 1.2744, time 10.58ms\n",
            "iter 1190: loss 1.3288, time 10.57ms\n",
            "iter 1200: loss 1.2964, time 10.63ms\n",
            "iter 1210: loss 1.2963, time 10.68ms\n",
            "iter 1220: loss 1.2928, time 10.72ms\n",
            "iter 1230: loss 1.2504, time 10.71ms\n",
            "iter 1240: loss 1.2687, time 10.66ms\n",
            "step 1250: train loss 1.2099, val loss 1.4993\n",
            "iter 1250: loss 1.3044, time 2658.94ms\n",
            "iter 1260: loss 1.2957, time 10.71ms\n",
            "iter 1270: loss 1.3005, time 10.71ms\n",
            "iter 1280: loss 1.2706, time 10.58ms\n",
            "iter 1290: loss 1.2988, time 10.58ms\n",
            "iter 1300: loss 1.2939, time 10.57ms\n",
            "iter 1310: loss 1.2487, time 10.57ms\n",
            "iter 1320: loss 1.2846, time 10.60ms\n",
            "iter 1330: loss 1.2675, time 10.64ms\n",
            "iter 1340: loss 1.2554, time 10.63ms\n",
            "iter 1350: loss 1.2462, time 10.57ms\n",
            "iter 1360: loss 1.2974, time 10.54ms\n",
            "iter 1370: loss 1.2703, time 10.48ms\n",
            "iter 1380: loss 1.2531, time 10.64ms\n",
            "iter 1390: loss 1.2677, time 10.58ms\n",
            "iter 1400: loss 1.2628, time 10.63ms\n",
            "iter 1410: loss 1.2641, time 10.58ms\n",
            "iter 1420: loss 1.2491, time 11.80ms\n",
            "iter 1430: loss 1.2277, time 10.54ms\n",
            "iter 1440: loss 1.2166, time 10.63ms\n",
            "iter 1450: loss 1.2765, time 10.59ms\n",
            "iter 1460: loss 1.2448, time 10.46ms\n",
            "iter 1470: loss 1.2219, time 10.57ms\n",
            "iter 1480: loss 1.2245, time 10.47ms\n",
            "iter 1490: loss 1.2507, time 10.51ms\n",
            "step 1500: train loss 1.1536, val loss 1.4783\n",
            "iter 1500: loss 1.2461, time 2657.10ms\n",
            "iter 1510: loss 1.2273, time 10.54ms\n",
            "iter 1520: loss 1.2414, time 10.59ms\n",
            "iter 1530: loss 1.2212, time 10.59ms\n",
            "iter 1540: loss 1.2472, time 10.58ms\n",
            "iter 1550: loss 1.2235, time 10.67ms\n",
            "iter 1560: loss 1.2624, time 10.61ms\n",
            "iter 1570: loss 1.2088, time 10.59ms\n",
            "iter 1580: loss 1.1988, time 10.79ms\n",
            "iter 1590: loss 1.1965, time 10.55ms\n",
            "iter 1600: loss 1.2172, time 10.91ms\n",
            "iter 1610: loss 1.1893, time 10.50ms\n",
            "iter 1620: loss 1.2231, time 10.54ms\n",
            "iter 1630: loss 1.2385, time 10.48ms\n",
            "iter 1640: loss 1.2259, time 10.51ms\n",
            "iter 1650: loss 1.1996, time 10.49ms\n",
            "iter 1660: loss 1.1971, time 10.48ms\n",
            "iter 1670: loss 1.2242, time 10.49ms\n",
            "iter 1680: loss 1.1805, time 11.55ms\n",
            "iter 1690: loss 1.1915, time 12.82ms\n",
            "iter 1700: loss 1.1849, time 11.40ms\n",
            "iter 1710: loss 1.1536, time 10.49ms\n",
            "iter 1720: loss 1.1785, time 10.48ms\n",
            "iter 1730: loss 1.1907, time 10.58ms\n",
            "iter 1740: loss 1.1953, time 10.50ms\n",
            "step 1750: train loss 1.1073, val loss 1.4789\n",
            "iter 1750: loss 1.1905, time 2655.22ms\n",
            "iter 1760: loss 1.1963, time 10.78ms\n",
            "iter 1770: loss 1.1906, time 10.62ms\n",
            "iter 1780: loss 1.1432, time 10.69ms\n",
            "iter 1790: loss 1.1835, time 11.06ms\n",
            "iter 1800: loss 1.1533, time 11.45ms\n",
            "iter 1810: loss 1.1783, time 12.59ms\n",
            "iter 1820: loss 1.1780, time 10.73ms\n",
            "iter 1830: loss 1.1855, time 10.85ms\n",
            "iter 1840: loss 1.1648, time 11.83ms\n",
            "iter 1850: loss 1.1828, time 10.48ms\n",
            "iter 1860: loss 1.2237, time 10.50ms\n",
            "iter 1870: loss 1.1847, time 10.45ms\n",
            "iter 1880: loss 1.1643, time 10.51ms\n",
            "iter 1890: loss 1.1570, time 10.49ms\n",
            "iter 1900: loss 1.1576, time 11.89ms\n",
            "iter 1910: loss 1.1642, time 10.63ms\n",
            "iter 1920: loss 1.1537, time 10.56ms\n",
            "iter 1930: loss 1.1809, time 10.63ms\n",
            "iter 1940: loss 1.1480, time 10.64ms\n",
            "iter 1950: loss 1.1334, time 10.54ms\n",
            "iter 1960: loss 1.1611, time 10.56ms\n",
            "iter 1970: loss 1.1397, time 10.59ms\n",
            "iter 1980: loss 1.1979, time 10.72ms\n",
            "iter 1990: loss 1.1417, time 10.51ms\n",
            "step 2000: train loss 1.0605, val loss 1.4697\n",
            "iter 2000: loss 1.1289, time 2645.13ms\n",
            "iter 2010: loss 1.1446, time 10.55ms\n",
            "iter 2020: loss 1.1254, time 10.49ms\n",
            "iter 2030: loss 1.1486, time 10.46ms\n",
            "iter 2040: loss 1.1450, time 10.43ms\n",
            "iter 2050: loss 1.1233, time 10.46ms\n",
            "iter 2060: loss 1.1190, time 10.70ms\n",
            "iter 2070: loss 1.1374, time 10.52ms\n",
            "iter 2080: loss 1.1161, time 10.60ms\n",
            "iter 2090: loss 1.1294, time 10.51ms\n",
            "iter 2100: loss 1.1319, time 10.73ms\n",
            "iter 2110: loss 1.1451, time 10.62ms\n",
            "iter 2120: loss 1.1427, time 10.52ms\n",
            "iter 2130: loss 1.1381, time 10.76ms\n",
            "iter 2140: loss 1.1090, time 10.50ms\n",
            "iter 2150: loss 1.1086, time 10.69ms\n",
            "iter 2160: loss 1.1012, time 10.48ms\n",
            "iter 2170: loss 1.1141, time 11.28ms\n",
            "iter 2180: loss 1.1245, time 10.66ms\n",
            "iter 2190: loss 1.1502, time 10.59ms\n",
            "iter 2200: loss 1.1449, time 10.60ms\n",
            "iter 2210: loss 1.1280, time 10.93ms\n",
            "iter 2220: loss 1.1205, time 10.53ms\n",
            "iter 2230: loss 1.0991, time 10.56ms\n",
            "iter 2240: loss 1.1193, time 12.97ms\n",
            "step 2250: train loss 1.0111, val loss 1.4914\n",
            "iter 2250: loss 1.1250, time 2697.74ms\n",
            "iter 2260: loss 1.1154, time 10.89ms\n",
            "iter 2270: loss 1.0972, time 10.71ms\n",
            "iter 2280: loss 1.0872, time 10.83ms\n",
            "iter 2290: loss 1.0873, time 10.73ms\n",
            "iter 2300: loss 1.1222, time 10.75ms\n",
            "iter 2310: loss 1.0945, time 10.93ms\n",
            "iter 2320: loss 1.0903, time 10.76ms\n",
            "iter 2330: loss 1.0934, time 10.82ms\n",
            "iter 2340: loss 1.0921, time 10.80ms\n",
            "iter 2350: loss 1.0791, time 11.35ms\n",
            "iter 2360: loss 1.0914, time 11.45ms\n",
            "iter 2370: loss 1.0957, time 11.14ms\n",
            "iter 2380: loss 1.0940, time 10.81ms\n",
            "iter 2390: loss 1.0877, time 11.11ms\n",
            "iter 2400: loss 1.0488, time 11.63ms\n",
            "iter 2410: loss 1.0974, time 11.77ms\n",
            "iter 2420: loss 1.0686, time 10.62ms\n",
            "iter 2430: loss 1.0558, time 10.60ms\n",
            "iter 2440: loss 1.0499, time 11.92ms\n",
            "iter 2450: loss 1.0757, time 10.88ms\n",
            "iter 2460: loss 1.0919, time 10.68ms\n",
            "iter 2470: loss 1.0800, time 10.65ms\n",
            "iter 2480: loss 1.0681, time 10.66ms\n",
            "iter 2490: loss 1.0652, time 10.62ms\n",
            "step 2500: train loss 0.9594, val loss 1.4971\n",
            "iter 2500: loss 1.0777, time 2696.81ms\n",
            "iter 2510: loss 1.0504, time 10.65ms\n",
            "iter 2520: loss 1.0678, time 10.67ms\n",
            "iter 2530: loss 1.0801, time 10.77ms\n",
            "iter 2540: loss 1.0475, time 10.58ms\n",
            "iter 2550: loss 1.0666, time 10.64ms\n",
            "iter 2560: loss 1.0534, time 11.25ms\n",
            "iter 2570: loss 1.0545, time 10.55ms\n",
            "iter 2580: loss 1.0547, time 10.56ms\n",
            "iter 2590: loss 1.0647, time 10.46ms\n",
            "iter 2600: loss 1.0664, time 10.50ms\n",
            "iter 2610: loss 1.0358, time 12.89ms\n",
            "iter 2620: loss 1.0628, time 10.57ms\n",
            "iter 2630: loss 1.0706, time 11.53ms\n",
            "iter 2640: loss 1.0218, time 10.63ms\n",
            "iter 2650: loss 1.0403, time 10.58ms\n",
            "iter 2660: loss 1.0525, time 10.60ms\n",
            "iter 2670: loss 1.0525, time 10.87ms\n",
            "iter 2680: loss 1.0385, time 10.65ms\n",
            "iter 2690: loss 1.0517, time 10.67ms\n",
            "iter 2700: loss 1.0141, time 10.80ms\n",
            "iter 2710: loss 1.0375, time 10.58ms\n",
            "iter 2720: loss 0.9941, time 10.57ms\n",
            "iter 2730: loss 1.0438, time 10.51ms\n",
            "iter 2740: loss 1.0341, time 10.62ms\n",
            "step 2750: train loss 0.9142, val loss 1.5180\n",
            "iter 2750: loss 1.0515, time 2660.71ms\n",
            "iter 2760: loss 1.0211, time 13.02ms\n",
            "iter 2770: loss 1.0443, time 10.50ms\n",
            "iter 2780: loss 1.0341, time 10.54ms\n",
            "iter 2790: loss 1.0219, time 10.68ms\n",
            "iter 2800: loss 1.0110, time 10.61ms\n",
            "iter 2810: loss 1.0189, time 10.87ms\n",
            "iter 2820: loss 1.0352, time 10.85ms\n",
            "iter 2830: loss 0.9925, time 11.91ms\n",
            "iter 2840: loss 1.0136, time 10.76ms\n",
            "iter 2850: loss 1.0129, time 10.83ms\n",
            "iter 2860: loss 1.0027, time 10.74ms\n",
            "iter 2870: loss 1.0291, time 10.67ms\n",
            "iter 2880: loss 1.0305, time 10.72ms\n",
            "iter 2890: loss 1.0190, time 10.69ms\n",
            "iter 2900: loss 1.0380, time 10.70ms\n",
            "iter 2910: loss 1.0098, time 11.01ms\n",
            "iter 2920: loss 0.9808, time 11.10ms\n",
            "iter 2930: loss 1.0010, time 10.88ms\n",
            "iter 2940: loss 1.0045, time 10.90ms\n",
            "iter 2950: loss 0.9989, time 11.62ms\n",
            "iter 2960: loss 1.0007, time 11.20ms\n",
            "iter 2970: loss 0.9968, time 10.67ms\n",
            "iter 2980: loss 1.0152, time 10.64ms\n",
            "iter 2990: loss 0.9956, time 10.64ms\n",
            "step 3000: train loss 0.8649, val loss 1.5476\n",
            "iter 3000: loss 0.9948, time 2684.99ms\n",
            "iter 3010: loss 1.0163, time 10.48ms\n",
            "iter 3020: loss 1.0055, time 10.53ms\n",
            "iter 3030: loss 1.0056, time 11.77ms\n",
            "iter 3040: loss 0.9830, time 10.54ms\n",
            "iter 3050: loss 0.9917, time 10.63ms\n",
            "iter 3060: loss 0.9992, time 10.66ms\n",
            "iter 3070: loss 0.9907, time 10.57ms\n",
            "iter 3080: loss 0.9963, time 10.73ms\n",
            "iter 3090: loss 0.9991, time 10.41ms\n",
            "iter 3100: loss 0.9803, time 13.46ms\n",
            "iter 3110: loss 0.9976, time 10.42ms\n",
            "iter 3120: loss 0.9899, time 10.41ms\n",
            "iter 3130: loss 0.9846, time 10.55ms\n",
            "iter 3140: loss 0.9960, time 10.48ms\n",
            "iter 3150: loss 0.9671, time 10.43ms\n",
            "iter 3160: loss 0.9733, time 10.48ms\n",
            "iter 3170: loss 0.9542, time 10.48ms\n",
            "iter 3180: loss 0.9552, time 13.01ms\n",
            "iter 3190: loss 0.9864, time 10.71ms\n",
            "iter 3200: loss 0.9886, time 10.65ms\n",
            "iter 3210: loss 0.9914, time 10.59ms\n",
            "iter 3220: loss 0.9893, time 10.69ms\n",
            "iter 3230: loss 0.9911, time 10.51ms\n",
            "iter 3240: loss 0.9526, time 10.49ms\n",
            "step 3250: train loss 0.8200, val loss 1.5692\n",
            "iter 3250: loss 0.9927, time 2651.20ms\n",
            "iter 3260: loss 0.9847, time 10.45ms\n",
            "iter 3270: loss 0.9697, time 10.45ms\n",
            "iter 3280: loss 0.9575, time 10.48ms\n",
            "iter 3290: loss 0.9550, time 10.48ms\n",
            "iter 3300: loss 0.9565, time 10.51ms\n",
            "iter 3310: loss 0.9626, time 10.54ms\n",
            "iter 3320: loss 0.9446, time 10.45ms\n",
            "iter 3330: loss 0.9447, time 10.47ms\n",
            "iter 3340: loss 0.9761, time 10.48ms\n",
            "iter 3350: loss 0.9817, time 10.47ms\n",
            "iter 3360: loss 0.9428, time 10.50ms\n",
            "iter 3370: loss 0.9351, time 10.91ms\n",
            "iter 3380: loss 0.9471, time 10.61ms\n",
            "iter 3390: loss 0.9397, time 10.82ms\n",
            "iter 3400: loss 0.9415, time 10.97ms\n",
            "iter 3410: loss 0.9517, time 11.18ms\n",
            "iter 3420: loss 0.9353, time 10.66ms\n",
            "iter 3430: loss 0.9371, time 10.68ms\n",
            "iter 3440: loss 0.9375, time 10.62ms\n",
            "iter 3450: loss 0.9204, time 10.51ms\n",
            "iter 3460: loss 0.9772, time 10.78ms\n",
            "iter 3470: loss 0.9235, time 10.62ms\n",
            "iter 3480: loss 0.9381, time 10.69ms\n",
            "iter 3490: loss 0.9422, time 10.78ms\n",
            "step 3500: train loss 0.7782, val loss 1.5904\n",
            "iter 3500: loss 0.9322, time 2639.94ms\n",
            "iter 3510: loss 0.9528, time 10.65ms\n",
            "iter 3520: loss 0.9124, time 10.64ms\n",
            "iter 3530: loss 0.9247, time 10.58ms\n",
            "iter 3540: loss 0.9393, time 10.95ms\n",
            "iter 3550: loss 0.9175, time 10.63ms\n",
            "iter 3560: loss 0.9513, time 10.58ms\n",
            "iter 3570: loss 0.9355, time 10.64ms\n",
            "iter 3580: loss 0.9356, time 10.61ms\n",
            "iter 3590: loss 0.9416, time 10.54ms\n",
            "iter 3600: loss 0.9059, time 10.53ms\n",
            "iter 3610: loss 0.9302, time 11.11ms\n",
            "iter 3620: loss 0.9411, time 10.77ms\n",
            "iter 3630: loss 0.9176, time 10.60ms\n",
            "iter 3640: loss 0.9316, time 10.67ms\n",
            "iter 3650: loss 0.9378, time 10.51ms\n",
            "iter 3660: loss 0.9051, time 10.83ms\n",
            "iter 3670: loss 0.9122, time 10.56ms\n",
            "iter 3680: loss 0.8924, time 10.83ms\n",
            "iter 3690: loss 0.9066, time 10.61ms\n",
            "iter 3700: loss 0.9054, time 10.50ms\n",
            "iter 3710: loss 0.8803, time 12.83ms\n",
            "iter 3720: loss 0.9070, time 10.78ms\n",
            "iter 3730: loss 0.9092, time 11.89ms\n",
            "iter 3740: loss 0.8832, time 12.24ms\n",
            "step 3750: train loss 0.7355, val loss 1.6268\n",
            "iter 3750: loss 0.9176, time 2657.53ms\n",
            "iter 3760: loss 0.8860, time 10.65ms\n",
            "iter 3770: loss 0.9037, time 10.57ms\n",
            "iter 3780: loss 0.9119, time 10.53ms\n",
            "iter 3790: loss 0.8755, time 10.59ms\n",
            "iter 3800: loss 0.8938, time 10.61ms\n",
            "iter 3810: loss 0.9201, time 10.73ms\n",
            "iter 3820: loss 0.9104, time 10.60ms\n",
            "iter 3830: loss 0.9073, time 10.57ms\n",
            "iter 3840: loss 0.8941, time 10.51ms\n",
            "iter 3850: loss 0.9075, time 10.52ms\n",
            "iter 3860: loss 0.8765, time 11.40ms\n",
            "iter 3870: loss 0.8692, time 10.61ms\n",
            "iter 3880: loss 0.8844, time 10.90ms\n",
            "iter 3890: loss 0.9002, time 10.55ms\n",
            "iter 3900: loss 0.9202, time 10.52ms\n",
            "iter 3910: loss 0.8877, time 10.71ms\n",
            "iter 3920: loss 0.8983, time 12.16ms\n",
            "iter 3930: loss 0.8900, time 10.56ms\n",
            "iter 3940: loss 0.8983, time 11.65ms\n",
            "iter 3950: loss 0.8800, time 11.13ms\n",
            "iter 3960: loss 0.8782, time 11.08ms\n",
            "iter 3970: loss 0.8556, time 10.45ms\n",
            "iter 3980: loss 0.8991, time 10.65ms\n",
            "iter 3990: loss 0.8851, time 10.54ms\n",
            "step 4000: train loss 0.7030, val loss 1.6462\n",
            "iter 4000: loss 0.8806, time 2716.56ms\n",
            "iter 4010: loss 0.8820, time 10.96ms\n",
            "iter 4020: loss 0.8509, time 10.64ms\n",
            "iter 4030: loss 0.8836, time 10.71ms\n",
            "iter 4040: loss 0.8712, time 10.78ms\n",
            "iter 4050: loss 0.8456, time 12.09ms\n",
            "iter 4060: loss 0.8775, time 10.63ms\n",
            "iter 4070: loss 0.8916, time 10.51ms\n",
            "iter 4080: loss 0.8887, time 10.72ms\n",
            "iter 4090: loss 0.8515, time 10.60ms\n",
            "iter 4100: loss 0.8714, time 10.55ms\n",
            "iter 4110: loss 0.8908, time 10.57ms\n",
            "iter 4120: loss 0.8486, time 10.59ms\n",
            "iter 4130: loss 0.8564, time 10.78ms\n",
            "iter 4140: loss 0.8601, time 10.55ms\n",
            "iter 4150: loss 0.8525, time 10.59ms\n",
            "iter 4160: loss 0.8513, time 10.49ms\n",
            "iter 4170: loss 0.8652, time 10.47ms\n",
            "iter 4180: loss 0.8651, time 10.45ms\n",
            "iter 4190: loss 0.8587, time 10.68ms\n",
            "iter 4200: loss 0.8526, time 10.54ms\n",
            "iter 4210: loss 0.8852, time 10.47ms\n",
            "iter 4220: loss 0.8576, time 10.50ms\n",
            "iter 4230: loss 0.8707, time 10.49ms\n",
            "iter 4240: loss 0.8665, time 10.42ms\n",
            "step 4250: train loss 0.6751, val loss 1.6626\n",
            "iter 4250: loss 0.8630, time 2748.73ms\n",
            "iter 4260: loss 0.8731, time 10.62ms\n",
            "iter 4270: loss 0.8351, time 10.54ms\n",
            "iter 4280: loss 0.8784, time 10.80ms\n",
            "iter 4290: loss 0.8398, time 10.57ms\n",
            "iter 4300: loss 0.8542, time 10.43ms\n",
            "iter 4310: loss 0.8507, time 10.44ms\n",
            "iter 4320: loss 0.8564, time 10.61ms\n",
            "iter 4330: loss 0.8743, time 10.44ms\n",
            "iter 4340: loss 0.8814, time 10.47ms\n",
            "iter 4350: loss 0.8586, time 10.45ms\n",
            "iter 4360: loss 0.8438, time 10.59ms\n",
            "iter 4370: loss 0.8242, time 10.50ms\n",
            "iter 4380: loss 0.8595, time 10.74ms\n",
            "iter 4390: loss 0.8306, time 10.54ms\n",
            "iter 4400: loss 0.8299, time 10.57ms\n",
            "iter 4410: loss 0.8498, time 10.55ms\n",
            "iter 4420: loss 0.8285, time 10.52ms\n",
            "iter 4430: loss 0.8431, time 11.07ms\n",
            "iter 4440: loss 0.8321, time 10.60ms\n",
            "iter 4450: loss 0.8514, time 10.46ms\n",
            "iter 4460: loss 0.8340, time 10.46ms\n",
            "iter 4470: loss 0.8601, time 10.50ms\n",
            "iter 4480: loss 0.8416, time 11.57ms\n",
            "iter 4490: loss 0.8176, time 10.60ms\n",
            "step 4500: train loss 0.6482, val loss 1.6839\n",
            "iter 4500: loss 0.8549, time 2694.96ms\n",
            "iter 4510: loss 0.8546, time 10.81ms\n",
            "iter 4520: loss 0.8413, time 10.52ms\n",
            "iter 4530: loss 0.8370, time 10.53ms\n",
            "iter 4540: loss 0.8176, time 10.68ms\n",
            "iter 4550: loss 0.8249, time 10.59ms\n",
            "iter 4560: loss 0.8335, time 10.80ms\n",
            "iter 4570: loss 0.8284, time 10.64ms\n",
            "iter 4580: loss 0.8208, time 11.18ms\n",
            "iter 4590: loss 0.8257, time 10.56ms\n",
            "iter 4600: loss 0.8344, time 10.65ms\n",
            "iter 4610: loss 0.8269, time 10.68ms\n",
            "iter 4620: loss 0.8144, time 10.68ms\n",
            "iter 4630: loss 0.8320, time 10.85ms\n",
            "iter 4640: loss 0.8410, time 10.53ms\n",
            "iter 4650: loss 0.8336, time 10.78ms\n",
            "iter 4660: loss 0.8508, time 10.59ms\n",
            "iter 4670: loss 0.8535, time 10.59ms\n",
            "iter 4680: loss 0.8635, time 11.94ms\n",
            "iter 4690: loss 0.8312, time 10.63ms\n",
            "iter 4700: loss 0.8293, time 10.59ms\n",
            "iter 4710: loss 0.8340, time 10.84ms\n",
            "iter 4720: loss 0.8259, time 10.61ms\n",
            "iter 4730: loss 0.8286, time 10.74ms\n",
            "iter 4740: loss 0.8218, time 10.62ms\n",
            "step 4750: train loss 0.6310, val loss 1.6990\n",
            "iter 4750: loss 0.8315, time 2659.11ms\n",
            "iter 4760: loss 0.8319, time 10.60ms\n",
            "iter 4770: loss 0.8437, time 10.58ms\n",
            "iter 4780: loss 0.8159, time 10.58ms\n",
            "iter 4790: loss 0.8196, time 11.02ms\n",
            "iter 4800: loss 0.7971, time 10.55ms\n",
            "iter 4810: loss 0.8314, time 10.89ms\n",
            "iter 4820: loss 0.8537, time 10.86ms\n",
            "iter 4830: loss 0.8261, time 10.69ms\n",
            "iter 4840: loss 0.8120, time 10.78ms\n",
            "iter 4850: loss 0.8043, time 10.63ms\n",
            "iter 4860: loss 0.8066, time 10.64ms\n",
            "iter 4870: loss 0.8088, time 10.82ms\n",
            "iter 4880: loss 0.8061, time 10.54ms\n",
            "iter 4890: loss 0.8139, time 10.76ms\n",
            "iter 4900: loss 0.8061, time 10.80ms\n",
            "iter 4910: loss 0.8209, time 10.65ms\n",
            "iter 4920: loss 0.8174, time 10.68ms\n",
            "iter 4930: loss 0.8345, time 10.61ms\n",
            "iter 4940: loss 0.8385, time 10.61ms\n",
            "iter 4950: loss 0.8335, time 11.43ms\n",
            "iter 4960: loss 0.8451, time 12.98ms\n",
            "iter 4970: loss 0.8146, time 10.60ms\n",
            "iter 4980: loss 0.7887, time 10.70ms\n",
            "iter 4990: loss 0.7937, time 10.56ms\n",
            "step 5000: train loss 0.6122, val loss 1.7180\n",
            "iter 5000: loss 0.7948, time 2713.68ms\n",
            "training done\n",
            "Best validation loss: 1.4697067737579346\n",
            "Total train time: 1.94 mins\n",
            "Loading meta from ../../data/shakespeare_char/meta.pkl...\n",
            "Sample 1:\n",
            " and thought of his name reason\n",
            "Are they were not inconstantly attend\n",
            "Their brother and only have been in their depart.\n",
            "\n",
            "KING RICHARD II:\n",
            "The Earl of Wiltshire will rise unto thy counsel:\n",
            "And this is his loath, that will grow for weeping each,\n",
            "By any other hour bids me battle scalled now;\n",
            "And here lives in parliament lives in pain\n",
            "And the dangerous fires: so we charged thee all\n",
            "From summers that thou seest them as thou art.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "My heart is but half\n",
            "For my poor brother doth have touch\n",
            "Inference time: 1.85 seconds\n",
            "Tokens per second: 269.70\n",
            "---------------\n",
            "Sample 2:\n",
            " but most sheep--\n",
            "Is not four and she need all nature,\n",
            "She's not fourteen.\n",
            "\n",
            "LUCIO:\n",
            "O thy devils!\n",
            "\n",
            "ISABELLA:\n",
            "I'll tell you what I am.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Thou wilt not do't.\n",
            "\n",
            "ISABELLA:\n",
            "I should discharge you to her hence,\n",
            "If she were time then let him deserve\n",
            "Such neighbours to be a punk, that a bloody sire\n",
            "Of countenance and in the world to hurt\n",
            "The king is dear enough to chase the gentle:\n",
            "In happy virtue could not thrive in a warrant\n",
            "That make misfortunes have such a heavy soul.\n",
            "I thank your brothe\n",
            "Inference time: 1.83 seconds\n",
            "Tokens per second: 273.92\n",
            "---------------\n",
            "Sample 3:\n",
            " his eye,\n",
            "Quit it off that triumphant love with words.\n",
            "Draw near, or England's queen? why should thou slay\n",
            "That Edward shall be proclaim'd with some honesty?\n",
            "\n",
            "EDWARD:\n",
            "I will leave forth with mine eyes, and look on thee.\n",
            "\n",
            "KING HENRY VI:\n",
            "Come, let us along with the tear;\n",
            "And we will put the seas, I'll swear to them.\n",
            "\n",
            "YORK:\n",
            "He is my gage, the charge of Warwick,\n",
            "And would choose devise me father's gaod!\n",
            "\n",
            "EDWARD:\n",
            "I would protect him from the Fourth, but by the first,\n",
            "And I lay the truth of Henry the F\n",
            "Inference time: 1.81 seconds\n",
            "Tokens per second: 276.72\n",
            "---------------\n",
            "Sample 4:\n",
            " gentleman what with you worthy now?--\n",
            "For this absence that speaks the consulship,\n",
            "Lend made a party to prove a second cait\n",
            "And leaden other with injuries. I think\n",
            "What with these other words will I be so made\n",
            "As that are the consul.\n",
            "\n",
            "CORIOLANUS:\n",
            "Though many about to take the world\n",
            "And the instruments of my country, which else\n",
            "'Twere farther off against me, I'ld find this purpose\n",
            "To undertake the like of the other: which thou\n",
            "Shalt reply the court? If I do not, my sweet's\n",
            "Wife and children of ge\n",
            "Inference time: 1.82 seconds\n",
            "Tokens per second: 275.13\n",
            "---------------\n",
            "Sample 5:\n",
            " and tell the way\n",
            "That you shall bear the cheapes that hangs\n",
            "Which the downfall of war forfeit of thine eyes,\n",
            "Which sorrow can do this harm be our intent,\n",
            "But owe to assist thy tongue despair:\n",
            "Then pardon me, by the holy of the house,\n",
            "That I'll prove mourn and dance from part of dim:\n",
            "Mercy for the cause, call the sun sea\n",
            "For delay the deputy in a house;\n",
            "The revenge which 'twere all the groaning earth.\n",
            "\n",
            "KING EDWARD IV:\n",
            "The world affords are my father, Clarence;\n",
            "And these war I will be obstinate.\n",
            "\n",
            "\n",
            "Inference time: 1.82 seconds\n",
            "Tokens per second: 275.12\n",
            "---------------\n",
            "Sample 6:\n",
            " death, to his business do speak,\n",
            "With that this neighbour's love and grave\n",
            "The tongue of this another's pardon,\n",
            "Gives not the triumphant of the grief;\n",
            "And this worthy part doth live forth that perish.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "And thou shalt not stay to the Tower, but that thou trouble\n",
            "What he hath been to fair Juliet: she was fought\n",
            "To be the worst of men: let her speak again,\n",
            "And there is no soon so fister; let him be so;\n",
            "That she hath resisted: who is a letter for\n",
            "the fairiest from the law carters and\n",
            "Inference time: 1.80 seconds\n",
            "Tokens per second: 277.17\n",
            "---------------\n",
            "Sample 7:\n",
            " desire.\n",
            "\n",
            "Second Lady:\n",
            "Stand all all at once, and fetch him breathed\n",
            "To his bed presence under the state of death:\n",
            "If he be advised, sly in the hope hath done,\n",
            "Thou for his love wash'd against the grave;\n",
            "And say 'pardon' the burial king.'\n",
            "\n",
            "LEONTES:\n",
            "Please you, that your beauties speak like a bonne.\n",
            "\n",
            "HERMIONE:\n",
            "I see it, sir,\n",
            "You are come to make you as a word of you.\n",
            "\n",
            "LEONTES:\n",
            "Thou art poor: out, out!\n",
            "\n",
            "HERMIONE:\n",
            "You will, my lord: I will not please you to increase;\n",
            "If thou be ready to look upon't.\n",
            "Inference time: 1.85 seconds\n",
            "Tokens per second: 270.81\n",
            "---------------\n",
            "Sample 8:\n",
            " chamber-maids and hearted looks\n",
            "Proved in blood to like the war down of blood,\n",
            "Resides me that from his father, who pass'd\n",
            "Successively to peck his charge, then to beg\n",
            "What is his doing, and children of that prayer\n",
            "May she be able to endure the world,\n",
            "By whose body hath his dowry of pernicious\n",
            "And made a power and with a vineyard home\n",
            "To see her breathers o' the royal report.\n",
            "Farewell, good night: if we were a shower for the\n",
            "tide of our tribunes, we see it them come to the poor\n",
            "deeds from the sl\n",
            "Inference time: 1.80 seconds\n",
            "Tokens per second: 278.41\n",
            "---------------\n",
            "Sample 9:\n",
            " Catesby, you are all at once.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Then might have been so many thousand men\n",
            "That they spake of; but I will free,\n",
            "And leave the bosom of your grace and yours,\n",
            "And hear me yet speak.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "God forbid! a word with scrept I should bear my tent!\n",
            "Go, get thee to thy heart; back, play thy holy book!\n",
            "Dispatch; a bawd, and a handking toad!\n",
            "O no! O coward! O day! O woful day!\n",
            "O Clifford, O coward! doth here wrapp'd!\n",
            "O woful day! O flattering glass, God!\n",
            "\n",
            "BENVOLIO:\n",
            "O Clifford! how now!\n",
            "Inference time: 1.83 seconds\n",
            "Tokens per second: 273.45\n",
            "---------------\n",
            "Sample 10:\n",
            " the wear;\n",
            "And let the waving toward him from him;\n",
            "And he bears himself and honourable\n",
            "That he could follow him, which was so sent to death,\n",
            "Too cause his daughter. First, how now, you must speak!\n",
            "\n",
            "First Citizen:\n",
            "We know not, our name; for we shall push our woes,\n",
            "And crave the happy bones of the bones\n",
            "Of us of encounter, scorn, as he shall scarce that\n",
            "Which he does like the basilisk: whence are they\n",
            "They should bring and hair together, they say:\n",
            "So it is the happy day, by some honest measure\n",
            "Of w\n",
            "Inference time: 1.81 seconds\n",
            "Tokens per second: 276.81\n",
            "---------------\n",
            "Average tokens per second: 274.72\n",
            "tokens per iteration will be: 16,384\n",
            "found vocab_size = 65 (inside ../../data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 10.65M\n",
            "num decayed parameter tensors: 26, with 10,740,096 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 4.2468, val loss 4.2417\n",
            "iter 0: loss 4.2478, time 2742.23ms\n",
            "iter 10: loss 3.2118, time 10.67ms\n",
            "iter 20: loss 2.7846, time 10.62ms\n",
            "iter 30: loss 2.6130, time 10.56ms\n",
            "iter 40: loss 2.5605, time 11.76ms\n",
            "iter 50: loss 2.5317, time 11.20ms\n",
            "iter 60: loss 2.4922, time 10.79ms\n",
            "iter 70: loss 2.4931, time 10.90ms\n",
            "iter 80: loss 2.5012, time 10.72ms\n",
            "iter 90: loss 2.4810, time 11.01ms\n",
            "iter 100: loss 2.4771, time 13.36ms\n",
            "iter 110: loss 2.4380, time 10.55ms\n",
            "iter 120: loss 2.4328, time 10.51ms\n",
            "iter 130: loss 2.4332, time 10.70ms\n",
            "iter 140: loss 2.3972, time 10.58ms\n",
            "iter 150: loss 2.3975, time 10.59ms\n",
            "iter 160: loss 2.3551, time 10.54ms\n",
            "iter 170: loss 2.3529, time 10.72ms\n",
            "iter 180: loss 2.2967, time 10.64ms\n",
            "iter 190: loss 2.3093, time 10.56ms\n",
            "iter 200: loss 2.2236, time 13.09ms\n",
            "iter 210: loss 2.1663, time 11.73ms\n",
            "iter 220: loss 2.1386, time 10.63ms\n",
            "iter 230: loss 2.0983, time 10.83ms\n",
            "iter 240: loss 2.0481, time 10.84ms\n",
            "step 250: train loss 1.9709, val loss 2.0748\n",
            "iter 250: loss 2.0408, time 2681.53ms\n",
            "iter 260: loss 2.0001, time 10.54ms\n",
            "iter 270: loss 1.9513, time 10.53ms\n",
            "iter 280: loss 1.9464, time 10.54ms\n",
            "iter 290: loss 1.9120, time 10.50ms\n",
            "iter 300: loss 1.9161, time 10.47ms\n",
            "iter 310: loss 1.8686, time 11.63ms\n",
            "iter 320: loss 1.8637, time 10.71ms\n",
            "iter 330: loss 1.8087, time 10.51ms\n",
            "iter 340: loss 1.8257, time 11.32ms\n",
            "iter 350: loss 1.8037, time 10.96ms\n",
            "iter 360: loss 1.7853, time 10.68ms\n",
            "iter 370: loss 1.7578, time 10.64ms\n",
            "iter 380: loss 1.7525, time 10.72ms\n",
            "iter 390: loss 1.7268, time 10.50ms\n",
            "iter 400: loss 1.7247, time 10.50ms\n",
            "iter 410: loss 1.7565, time 10.54ms\n",
            "iter 420: loss 1.6877, time 10.56ms\n",
            "iter 430: loss 1.6481, time 11.37ms\n",
            "iter 440: loss 1.7034, time 10.65ms\n",
            "iter 450: loss 1.6391, time 10.67ms\n",
            "iter 460: loss 1.6550, time 10.50ms\n",
            "iter 470: loss 1.6397, time 10.51ms\n",
            "iter 480: loss 1.6413, time 10.62ms\n",
            "iter 490: loss 1.6109, time 10.52ms\n",
            "step 500: train loss 1.5313, val loss 1.7180\n",
            "iter 500: loss 1.5521, time 2658.68ms\n",
            "iter 510: loss 1.6142, time 10.73ms\n",
            "iter 520: loss 1.5693, time 12.18ms\n",
            "iter 530: loss 1.5740, time 10.52ms\n",
            "iter 540: loss 1.5892, time 10.55ms\n",
            "iter 550: loss 1.5484, time 10.60ms\n",
            "iter 560: loss 1.5529, time 10.60ms\n",
            "iter 570: loss 1.5537, time 10.57ms\n",
            "iter 580: loss 1.5321, time 10.54ms\n",
            "iter 590: loss 1.5187, time 10.51ms\n",
            "iter 600: loss 1.5154, time 10.58ms\n",
            "iter 610: loss 1.5110, time 10.77ms\n",
            "iter 620: loss 1.5204, time 10.64ms\n",
            "iter 630: loss 1.5174, time 10.57ms\n",
            "iter 640: loss 1.4931, time 10.56ms\n",
            "iter 650: loss 1.5039, time 10.59ms\n",
            "iter 660: loss 1.4810, time 12.71ms\n",
            "iter 670: loss 1.4789, time 10.89ms\n",
            "iter 680: loss 1.4579, time 10.69ms\n",
            "iter 690: loss 1.4629, time 10.70ms\n",
            "iter 700: loss 1.4727, time 10.82ms\n",
            "iter 710: loss 1.4866, time 10.70ms\n",
            "iter 720: loss 1.4654, time 10.70ms\n",
            "iter 730: loss 1.4568, time 10.72ms\n",
            "iter 740: loss 1.4263, time 14.26ms\n",
            "step 750: train loss 1.3589, val loss 1.5808\n",
            "iter 750: loss 1.4378, time 2702.14ms\n",
            "iter 760: loss 1.4442, time 10.65ms\n",
            "iter 770: loss 1.4475, time 11.20ms\n",
            "iter 780: loss 1.4382, time 10.66ms\n",
            "iter 790: loss 1.4261, time 10.54ms\n",
            "iter 800: loss 1.4212, time 10.62ms\n",
            "iter 810: loss 1.4313, time 10.77ms\n",
            "iter 820: loss 1.3857, time 10.66ms\n",
            "iter 830: loss 1.3772, time 10.72ms\n",
            "iter 840: loss 1.4046, time 10.62ms\n",
            "iter 850: loss 1.3759, time 10.69ms\n",
            "iter 860: loss 1.3893, time 10.65ms\n",
            "iter 870: loss 1.3867, time 10.94ms\n",
            "iter 880: loss 1.3599, time 10.57ms\n",
            "iter 890: loss 1.3734, time 10.63ms\n",
            "iter 900: loss 1.3439, time 10.65ms\n",
            "iter 910: loss 1.3973, time 10.52ms\n",
            "iter 920: loss 1.3694, time 10.52ms\n",
            "iter 930: loss 1.3700, time 10.68ms\n",
            "iter 940: loss 1.3438, time 11.89ms\n",
            "iter 950: loss 1.3553, time 10.99ms\n",
            "iter 960: loss 1.3796, time 10.72ms\n",
            "iter 970: loss 1.3711, time 10.61ms\n",
            "iter 980: loss 1.3672, time 10.72ms\n",
            "iter 990: loss 1.3462, time 10.55ms\n",
            "step 1000: train loss 1.2699, val loss 1.5276\n",
            "iter 1000: loss 1.3249, time 2717.56ms\n",
            "iter 1010: loss 1.3411, time 10.58ms\n",
            "iter 1020: loss 1.3218, time 10.55ms\n",
            "iter 1030: loss 1.3525, time 13.06ms\n",
            "iter 1040: loss 1.3239, time 10.54ms\n",
            "iter 1050: loss 1.3370, time 11.50ms\n",
            "iter 1060: loss 1.3408, time 10.65ms\n",
            "iter 1070: loss 1.3535, time 10.49ms\n",
            "iter 1080: loss 1.3195, time 10.59ms\n",
            "iter 1090: loss 1.2722, time 10.59ms\n",
            "iter 1100: loss 1.3177, time 10.83ms\n",
            "iter 1110: loss 1.3167, time 10.50ms\n",
            "iter 1120: loss 1.3017, time 10.59ms\n",
            "iter 1130: loss 1.2993, time 10.75ms\n",
            "iter 1140: loss 1.3336, time 10.58ms\n",
            "iter 1150: loss 1.2724, time 10.60ms\n",
            "iter 1160: loss 1.3096, time 10.61ms\n",
            "iter 1170: loss 1.2844, time 10.59ms\n",
            "iter 1180: loss 1.2711, time 10.53ms\n",
            "iter 1190: loss 1.3147, time 10.48ms\n",
            "iter 1200: loss 1.2945, time 10.78ms\n",
            "iter 1210: loss 1.2857, time 10.52ms\n",
            "iter 1220: loss 1.3007, time 11.92ms\n",
            "iter 1230: loss 1.2989, time 14.11ms\n",
            "iter 1240: loss 1.3085, time 10.48ms\n",
            "step 1250: train loss 1.2046, val loss 1.4949\n",
            "iter 1250: loss 1.3017, time 2676.35ms\n",
            "iter 1260: loss 1.2930, time 10.58ms\n",
            "iter 1270: loss 1.2939, time 10.57ms\n",
            "iter 1280: loss 1.2719, time 10.57ms\n",
            "iter 1290: loss 1.2661, time 10.58ms\n",
            "iter 1300: loss 1.3009, time 10.62ms\n",
            "iter 1310: loss 1.2615, time 10.62ms\n",
            "iter 1320: loss 1.2602, time 10.64ms\n",
            "iter 1330: loss 1.2516, time 10.69ms\n",
            "iter 1340: loss 1.2703, time 10.60ms\n",
            "iter 1350: loss 1.2470, time 10.72ms\n",
            "iter 1360: loss 1.2383, time 10.62ms\n",
            "iter 1370: loss 1.2693, time 10.65ms\n",
            "iter 1380: loss 1.2351, time 10.55ms\n",
            "iter 1390: loss 1.2459, time 10.56ms\n",
            "iter 1400: loss 1.2296, time 10.57ms\n",
            "iter 1410: loss 1.2106, time 10.81ms\n",
            "iter 1420: loss 1.2658, time 10.60ms\n",
            "iter 1430: loss 1.2639, time 10.58ms\n",
            "iter 1440: loss 1.2079, time 10.57ms\n",
            "iter 1450: loss 1.2626, time 10.86ms\n",
            "iter 1460: loss 1.2454, time 10.66ms\n",
            "iter 1470: loss 1.2194, time 10.65ms\n",
            "iter 1480: loss 1.2194, time 10.61ms\n",
            "iter 1490: loss 1.2409, time 10.70ms\n",
            "step 1500: train loss 1.1504, val loss 1.4685\n",
            "iter 1500: loss 1.2058, time 2654.21ms\n",
            "iter 1510: loss 1.2392, time 10.53ms\n",
            "iter 1520: loss 1.2112, time 11.33ms\n",
            "iter 1530: loss 1.2470, time 13.12ms\n",
            "iter 1540: loss 1.2187, time 10.53ms\n",
            "iter 1550: loss 1.1744, time 10.55ms\n",
            "iter 1560: loss 1.2214, time 11.34ms\n",
            "iter 1570: loss 1.1988, time 10.56ms\n",
            "iter 1580: loss 1.2013, time 10.86ms\n",
            "iter 1590: loss 1.2425, time 11.79ms\n",
            "iter 1600: loss 1.2144, time 10.58ms\n",
            "iter 1610: loss 1.2049, time 10.64ms\n",
            "iter 1620: loss 1.2061, time 10.60ms\n",
            "iter 1630: loss 1.1967, time 10.52ms\n",
            "iter 1640: loss 1.2174, time 10.63ms\n",
            "iter 1650: loss 1.1904, time 10.56ms\n",
            "iter 1660: loss 1.2130, time 10.59ms\n",
            "iter 1670: loss 1.2217, time 10.58ms\n",
            "iter 1680: loss 1.2223, time 10.54ms\n",
            "iter 1690: loss 1.2226, time 11.03ms\n",
            "iter 1700: loss 1.2207, time 10.53ms\n",
            "iter 1710: loss 1.1929, time 11.01ms\n",
            "iter 1720: loss 1.2009, time 10.95ms\n",
            "iter 1730: loss 1.1923, time 10.57ms\n",
            "iter 1740: loss 1.1850, time 10.51ms\n",
            "step 1750: train loss 1.1007, val loss 1.4823\n",
            "iter 1750: loss 1.1864, time 2700.33ms\n",
            "iter 1760: loss 1.1674, time 10.48ms\n",
            "iter 1770: loss 1.1636, time 10.54ms\n",
            "iter 1780: loss 1.1584, time 11.40ms\n",
            "iter 1790: loss 1.1829, time 10.54ms\n",
            "iter 1800: loss 1.1686, time 10.88ms\n",
            "iter 1810: loss 1.1773, time 10.55ms\n",
            "iter 1820: loss 1.1666, time 10.85ms\n",
            "iter 1830: loss 1.1256, time 10.84ms\n",
            "iter 1840: loss 1.1759, time 10.73ms\n",
            "iter 1850: loss 1.1872, time 10.66ms\n",
            "iter 1860: loss 1.1919, time 10.64ms\n",
            "iter 1870: loss 1.1503, time 10.64ms\n",
            "iter 1880: loss 1.2058, time 10.65ms\n",
            "iter 1890: loss 1.1375, time 10.65ms\n",
            "iter 1900: loss 1.1810, time 10.52ms\n",
            "iter 1910: loss 1.1340, time 10.67ms\n",
            "iter 1920: loss 1.1391, time 10.66ms\n",
            "iter 1930: loss 1.1455, time 10.59ms\n",
            "iter 1940: loss 1.1440, time 10.59ms\n",
            "iter 1950: loss 1.1654, time 10.56ms\n",
            "iter 1960: loss 1.1403, time 11.75ms\n",
            "iter 1970: loss 1.1387, time 10.95ms\n",
            "iter 1980: loss 1.1552, time 10.62ms\n",
            "iter 1990: loss 1.1426, time 10.63ms\n",
            "step 2000: train loss 1.0531, val loss 1.4774\n",
            "iter 2000: loss 1.1531, time 2699.61ms\n",
            "iter 2010: loss 1.1332, time 10.54ms\n",
            "iter 2020: loss 1.1469, time 10.73ms\n",
            "iter 2030: loss 1.1276, time 10.52ms\n",
            "iter 2040: loss 1.1429, time 10.62ms\n",
            "iter 2050: loss 1.1473, time 10.64ms\n",
            "iter 2060: loss 1.1636, time 11.97ms\n",
            "iter 2070: loss 1.1595, time 10.78ms\n",
            "iter 2080: loss 1.1458, time 11.75ms\n",
            "iter 2090: loss 1.1177, time 10.56ms\n",
            "iter 2100: loss 1.1147, time 10.64ms\n",
            "iter 2110: loss 1.1110, time 10.58ms\n",
            "iter 2120: loss 1.0844, time 10.62ms\n",
            "iter 2130: loss 1.1193, time 10.62ms\n",
            "iter 2140: loss 1.1242, time 10.60ms\n",
            "iter 2150: loss 1.1287, time 10.59ms\n",
            "iter 2160: loss 1.1420, time 10.66ms\n",
            "iter 2170: loss 1.1471, time 10.59ms\n",
            "iter 2180: loss 1.1389, time 10.87ms\n",
            "iter 2190: loss 1.1287, time 11.17ms\n",
            "iter 2200: loss 1.1112, time 10.69ms\n",
            "iter 2210: loss 1.1140, time 10.53ms\n",
            "iter 2220: loss 1.1090, time 10.51ms\n",
            "iter 2230: loss 1.1028, time 15.18ms\n",
            "iter 2240: loss 1.1219, time 12.21ms\n",
            "step 2250: train loss 1.0099, val loss 1.4890\n",
            "iter 2250: loss 1.1050, time 2693.62ms\n",
            "iter 2260: loss 1.1007, time 11.20ms\n",
            "iter 2270: loss 1.1270, time 11.48ms\n",
            "iter 2280: loss 1.1100, time 10.73ms\n",
            "iter 2290: loss 1.0751, time 10.58ms\n",
            "iter 2300: loss 1.0722, time 11.53ms\n",
            "iter 2310: loss 1.0987, time 11.12ms\n",
            "iter 2320: loss 1.0948, time 10.73ms\n",
            "iter 2330: loss 1.1247, time 10.62ms\n",
            "iter 2340: loss 1.0837, time 10.54ms\n",
            "iter 2350: loss 1.1094, time 11.14ms\n",
            "iter 2360: loss 1.0827, time 10.71ms\n",
            "iter 2370: loss 1.0745, time 10.74ms\n",
            "iter 2380: loss 1.0944, time 10.99ms\n",
            "iter 2390: loss 1.0780, time 10.59ms\n",
            "iter 2400: loss 1.0986, time 10.78ms\n",
            "iter 2410: loss 1.0762, time 11.02ms\n",
            "iter 2420: loss 1.0566, time 10.45ms\n",
            "iter 2430: loss 1.0888, time 10.65ms\n",
            "iter 2440: loss 1.0906, time 10.63ms\n",
            "iter 2450: loss 1.0829, time 10.67ms\n",
            "iter 2460: loss 1.0399, time 11.02ms\n",
            "iter 2470: loss 1.0909, time 10.56ms\n",
            "iter 2480: loss 1.0721, time 10.50ms\n",
            "iter 2490: loss 1.0825, time 10.68ms\n",
            "step 2500: train loss 0.9636, val loss 1.5088\n",
            "iter 2500: loss 1.0494, time 2663.40ms\n",
            "iter 2510: loss 1.0774, time 10.57ms\n",
            "iter 2520: loss 1.0703, time 10.65ms\n",
            "iter 2530: loss 1.0725, time 10.58ms\n",
            "iter 2540: loss 1.0660, time 11.23ms\n",
            "iter 2550: loss 1.0731, time 10.51ms\n",
            "iter 2560: loss 1.0591, time 10.49ms\n",
            "iter 2570: loss 1.0760, time 10.54ms\n",
            "iter 2580: loss 1.0557, time 10.46ms\n",
            "iter 2590: loss 1.0777, time 10.48ms\n",
            "iter 2600: loss 1.0829, time 10.47ms\n",
            "iter 2610: loss 1.0686, time 10.57ms\n",
            "iter 2620: loss 1.0599, time 11.84ms\n",
            "iter 2630: loss 1.0636, time 10.59ms\n",
            "iter 2640: loss 1.0493, time 10.55ms\n",
            "iter 2650: loss 1.0489, time 10.57ms\n",
            "iter 2660: loss 1.0579, time 10.48ms\n",
            "iter 2670: loss 1.0266, time 10.60ms\n",
            "iter 2680: loss 1.0412, time 10.68ms\n",
            "iter 2690: loss 1.0625, time 10.55ms\n",
            "iter 2700: loss 1.0701, time 10.49ms\n",
            "iter 2710: loss 1.0426, time 10.55ms\n",
            "iter 2720: loss 1.0286, time 10.69ms\n",
            "iter 2730: loss 1.0389, time 10.80ms\n",
            "iter 2740: loss 1.0456, time 10.72ms\n",
            "step 2750: train loss 0.9111, val loss 1.5220\n",
            "iter 2750: loss 1.0350, time 2704.32ms\n",
            "iter 2760: loss 1.0118, time 10.80ms\n",
            "iter 2770: loss 1.0026, time 11.11ms\n",
            "iter 2780: loss 1.0236, time 10.57ms\n",
            "iter 2790: loss 1.0484, time 11.55ms\n",
            "iter 2800: loss 1.0211, time 11.17ms\n",
            "iter 2810: loss 0.9950, time 10.75ms\n",
            "iter 2820: loss 1.0188, time 10.89ms\n",
            "iter 2830: loss 0.9840, time 11.43ms\n",
            "iter 2840: loss 1.0412, time 10.90ms\n",
            "iter 2850: loss 1.0266, time 11.07ms\n",
            "iter 2860: loss 1.0286, time 11.62ms\n",
            "iter 2870: loss 1.0317, time 13.15ms\n",
            "iter 2880: loss 1.0165, time 10.96ms\n",
            "iter 2890: loss 0.9830, time 11.68ms\n",
            "iter 2900: loss 1.0091, time 11.82ms\n",
            "iter 2910: loss 1.0236, time 10.51ms\n",
            "iter 2920: loss 1.0215, time 10.64ms\n",
            "iter 2930: loss 0.9947, time 10.50ms\n",
            "iter 2940: loss 0.9866, time 10.59ms\n",
            "iter 2950: loss 0.9995, time 10.89ms\n",
            "iter 2960: loss 1.0307, time 12.22ms\n",
            "iter 2970: loss 0.9860, time 11.85ms\n",
            "iter 2980: loss 0.9956, time 11.04ms\n",
            "iter 2990: loss 0.9862, time 10.78ms\n",
            "step 3000: train loss 0.8675, val loss 1.5357\n",
            "iter 3000: loss 0.9942, time 2669.06ms\n",
            "iter 3010: loss 0.9748, time 10.76ms\n",
            "iter 3020: loss 1.0184, time 10.59ms\n",
            "iter 3030: loss 0.9925, time 10.65ms\n",
            "iter 3040: loss 0.9721, time 10.64ms\n",
            "iter 3050: loss 0.9908, time 10.64ms\n",
            "iter 3060: loss 1.0075, time 10.61ms\n",
            "iter 3070: loss 0.9988, time 10.65ms\n",
            "iter 3080: loss 0.9787, time 11.10ms\n",
            "iter 3090: loss 1.0129, time 10.55ms\n",
            "iter 3100: loss 0.9943, time 10.55ms\n",
            "iter 3110: loss 1.0140, time 10.63ms\n",
            "iter 3120: loss 0.9749, time 10.59ms\n",
            "iter 3130: loss 0.9753, time 10.83ms\n",
            "iter 3140: loss 0.9822, time 10.62ms\n",
            "iter 3150: loss 0.9987, time 10.54ms\n",
            "iter 3160: loss 0.9653, time 10.55ms\n",
            "iter 3170: loss 0.9619, time 11.93ms\n",
            "iter 3180: loss 0.9821, time 10.77ms\n",
            "iter 3190: loss 0.9579, time 10.57ms\n",
            "iter 3200: loss 0.9593, time 10.60ms\n",
            "iter 3210: loss 0.9496, time 11.82ms\n",
            "iter 3220: loss 0.9458, time 10.67ms\n",
            "iter 3230: loss 0.9573, time 13.18ms\n",
            "iter 3240: loss 0.9578, time 10.68ms\n",
            "step 3250: train loss 0.8221, val loss 1.5475\n",
            "iter 3250: loss 0.9448, time 2667.18ms\n",
            "iter 3260: loss 0.9535, time 10.75ms\n",
            "iter 3270: loss 0.9500, time 13.56ms\n",
            "iter 3280: loss 0.9362, time 11.74ms\n",
            "iter 3290: loss 0.9782, time 10.71ms\n",
            "iter 3300: loss 0.9521, time 10.68ms\n",
            "iter 3310: loss 0.9757, time 11.31ms\n",
            "iter 3320: loss 0.9197, time 10.63ms\n",
            "iter 3330: loss 0.9567, time 11.15ms\n",
            "iter 3340: loss 0.9733, time 11.02ms\n",
            "iter 3350: loss 0.9569, time 10.70ms\n",
            "iter 3360: loss 0.9646, time 10.77ms\n",
            "iter 3370: loss 0.9457, time 10.66ms\n",
            "iter 3380: loss 0.9420, time 10.78ms\n",
            "iter 3390: loss 0.9247, time 10.82ms\n",
            "iter 3400: loss 0.9771, time 10.98ms\n",
            "iter 3410: loss 0.9771, time 11.12ms\n",
            "iter 3420: loss 0.9374, time 11.00ms\n",
            "iter 3430: loss 0.9257, time 10.68ms\n",
            "iter 3440: loss 0.9522, time 10.68ms\n",
            "iter 3450: loss 0.9529, time 12.05ms\n",
            "iter 3460: loss 0.9474, time 10.68ms\n",
            "iter 3470: loss 0.9350, time 10.67ms\n",
            "iter 3480: loss 0.9065, time 10.69ms\n",
            "iter 3490: loss 0.9459, time 10.87ms\n",
            "step 3500: train loss 0.7820, val loss 1.5702\n",
            "iter 3500: loss 0.9155, time 2680.74ms\n",
            "iter 3510: loss 0.9218, time 10.50ms\n",
            "iter 3520: loss 0.9450, time 10.51ms\n",
            "iter 3530: loss 0.9376, time 10.68ms\n",
            "iter 3540: loss 0.9303, time 10.81ms\n",
            "iter 3550: loss 0.9409, time 11.78ms\n",
            "iter 3560: loss 0.9383, time 10.92ms\n",
            "iter 3570: loss 0.9282, time 10.50ms\n",
            "iter 3580: loss 0.9288, time 10.96ms\n",
            "iter 3590: loss 0.9126, time 10.58ms\n",
            "iter 3600: loss 0.9316, time 11.33ms\n",
            "iter 3610: loss 0.9073, time 10.68ms\n",
            "iter 3620: loss 0.9159, time 10.62ms\n",
            "iter 3630: loss 0.9255, time 10.78ms\n",
            "iter 3640: loss 0.9299, time 11.90ms\n",
            "iter 3650: loss 0.8995, time 10.50ms\n",
            "iter 3660: loss 0.9273, time 10.53ms\n",
            "iter 3670: loss 0.9174, time 13.06ms\n",
            "iter 3680: loss 0.9035, time 10.58ms\n",
            "iter 3690: loss 0.9288, time 10.90ms\n",
            "iter 3700: loss 0.9268, time 10.56ms\n",
            "iter 3710: loss 0.9216, time 10.58ms\n",
            "iter 3720: loss 0.8894, time 10.62ms\n",
            "iter 3730: loss 0.9212, time 10.64ms\n",
            "iter 3740: loss 0.8989, time 10.58ms\n",
            "step 3750: train loss 0.7435, val loss 1.6001\n",
            "iter 3750: loss 0.9363, time 2670.75ms\n",
            "iter 3760: loss 0.9129, time 10.76ms\n",
            "iter 3770: loss 0.9029, time 10.85ms\n",
            "iter 3780: loss 0.9074, time 10.82ms\n",
            "iter 3790: loss 0.9152, time 12.52ms\n",
            "iter 3800: loss 0.9136, time 10.76ms\n",
            "iter 3810: loss 0.9000, time 10.84ms\n",
            "iter 3820: loss 0.8737, time 10.72ms\n",
            "iter 3830: loss 0.8762, time 10.86ms\n",
            "iter 3840: loss 0.9171, time 10.84ms\n",
            "iter 3850: loss 0.8632, time 10.78ms\n",
            "iter 3860: loss 0.9076, time 10.86ms\n",
            "iter 3870: loss 0.8778, time 12.78ms\n",
            "iter 3880: loss 0.8917, time 10.66ms\n",
            "iter 3890: loss 0.9168, time 11.26ms\n",
            "iter 3900: loss 0.8697, time 10.64ms\n",
            "iter 3910: loss 0.9052, time 12.69ms\n",
            "iter 3920: loss 0.8841, time 10.58ms\n",
            "iter 3930: loss 0.8606, time 10.61ms\n",
            "iter 3940: loss 0.8791, time 10.62ms\n",
            "iter 3950: loss 0.9206, time 10.64ms\n",
            "iter 3960: loss 0.8893, time 10.61ms\n",
            "iter 3970: loss 0.8959, time 14.35ms\n",
            "iter 3980: loss 0.8809, time 10.73ms\n",
            "iter 3990: loss 0.8858, time 10.83ms\n",
            "step 4000: train loss 0.7088, val loss 1.6260\n",
            "iter 4000: loss 0.8736, time 2661.58ms\n",
            "iter 4010: loss 0.8569, time 10.70ms\n",
            "iter 4020: loss 0.8782, time 10.77ms\n",
            "iter 4030: loss 0.9098, time 10.72ms\n",
            "iter 4040: loss 0.8886, time 10.74ms\n",
            "iter 4050: loss 0.8822, time 10.73ms\n",
            "iter 4060: loss 0.8690, time 10.75ms\n",
            "iter 4070: loss 0.8565, time 10.72ms\n",
            "iter 4080: loss 0.8583, time 10.79ms\n",
            "iter 4090: loss 0.8660, time 10.70ms\n",
            "iter 4100: loss 0.8384, time 10.70ms\n",
            "iter 4110: loss 0.8695, time 10.67ms\n",
            "iter 4120: loss 0.8844, time 10.70ms\n",
            "iter 4130: loss 0.8628, time 10.67ms\n",
            "iter 4140: loss 0.8687, time 10.65ms\n",
            "iter 4150: loss 0.8736, time 10.64ms\n",
            "iter 4160: loss 0.8423, time 10.70ms\n",
            "iter 4170: loss 0.8700, time 10.70ms\n",
            "iter 4180: loss 0.8689, time 10.75ms\n",
            "iter 4190: loss 0.8585, time 10.75ms\n",
            "iter 4200: loss 0.8488, time 10.67ms\n",
            "iter 4210: loss 0.8508, time 10.72ms\n",
            "iter 4220: loss 0.8763, time 10.70ms\n",
            "iter 4230: loss 0.8674, time 10.72ms\n",
            "iter 4240: loss 0.8697, time 10.71ms\n",
            "step 4250: train loss 0.6801, val loss 1.6480\n",
            "iter 4250: loss 0.8650, time 2657.46ms\n",
            "iter 4260: loss 0.8817, time 10.74ms\n",
            "iter 4270: loss 0.8621, time 10.73ms\n",
            "iter 4280: loss 0.8663, time 10.66ms\n",
            "iter 4290: loss 0.8325, time 10.74ms\n",
            "iter 4300: loss 0.8635, time 10.72ms\n",
            "iter 4310: loss 0.8381, time 10.65ms\n",
            "iter 4320: loss 0.8825, time 10.73ms\n",
            "iter 4330: loss 0.8690, time 10.81ms\n",
            "iter 4340: loss 0.8291, time 10.53ms\n",
            "iter 4350: loss 0.8467, time 10.46ms\n",
            "iter 4360: loss 0.8379, time 10.59ms\n",
            "iter 4370: loss 0.8367, time 10.57ms\n",
            "iter 4380: loss 0.8232, time 10.59ms\n",
            "iter 4390: loss 0.8639, time 10.47ms\n",
            "iter 4400: loss 0.8546, time 13.18ms\n",
            "iter 4410: loss 0.8528, time 10.72ms\n",
            "iter 4420: loss 0.8557, time 10.68ms\n",
            "iter 4430: loss 0.8349, time 10.68ms\n",
            "iter 4440: loss 0.8588, time 12.16ms\n",
            "iter 4450: loss 0.8526, time 10.72ms\n",
            "iter 4460: loss 0.8335, time 10.70ms\n",
            "iter 4470: loss 0.8602, time 10.70ms\n",
            "iter 4480: loss 0.8232, time 10.66ms\n",
            "iter 4490: loss 0.8630, time 10.67ms\n",
            "step 4500: train loss 0.6560, val loss 1.6656\n",
            "iter 4500: loss 0.8353, time 2684.50ms\n",
            "iter 4510: loss 0.8553, time 10.72ms\n",
            "iter 4520: loss 0.8312, time 10.65ms\n",
            "iter 4530: loss 0.8709, time 10.47ms\n",
            "iter 4540: loss 0.8364, time 10.42ms\n",
            "iter 4550: loss 0.8652, time 10.47ms\n",
            "iter 4560: loss 0.8634, time 13.29ms\n",
            "iter 4570: loss 0.8453, time 10.56ms\n",
            "iter 4580: loss 0.8112, time 10.53ms\n",
            "iter 4590: loss 0.8350, time 10.57ms\n",
            "iter 4600: loss 0.8294, time 10.88ms\n",
            "iter 4610: loss 0.8190, time 10.56ms\n",
            "iter 4620: loss 0.8266, time 10.56ms\n",
            "iter 4630: loss 0.8299, time 10.69ms\n",
            "iter 4640: loss 0.8491, time 11.75ms\n",
            "iter 4650: loss 0.8322, time 10.70ms\n",
            "iter 4660: loss 0.8399, time 10.50ms\n",
            "iter 4670: loss 0.8415, time 10.70ms\n",
            "iter 4680: loss 0.8482, time 10.45ms\n",
            "iter 4690: loss 0.8368, time 10.45ms\n",
            "iter 4700: loss 0.8260, time 10.64ms\n",
            "iter 4710: loss 0.8525, time 10.49ms\n",
            "iter 4720: loss 0.8384, time 10.56ms\n",
            "iter 4730: loss 0.8325, time 12.38ms\n",
            "iter 4740: loss 0.8194, time 11.68ms\n",
            "step 4750: train loss 0.6363, val loss 1.6793\n",
            "iter 4750: loss 0.8437, time 2668.19ms\n",
            "iter 4760: loss 0.8151, time 10.57ms\n",
            "iter 4770: loss 0.8197, time 10.45ms\n",
            "iter 4780: loss 0.8436, time 10.54ms\n",
            "iter 4790: loss 0.8229, time 10.50ms\n",
            "iter 4800: loss 0.8513, time 10.60ms\n",
            "iter 4810: loss 0.8332, time 10.64ms\n",
            "iter 4820: loss 0.8257, time 10.53ms\n",
            "iter 4830: loss 0.8309, time 10.58ms\n",
            "iter 4840: loss 0.8253, time 10.67ms\n",
            "iter 4850: loss 0.8458, time 10.81ms\n",
            "iter 4860: loss 0.8269, time 10.53ms\n",
            "iter 4870: loss 0.8129, time 10.52ms\n",
            "iter 4880: loss 0.8212, time 10.61ms\n",
            "iter 4890: loss 0.8005, time 10.46ms\n",
            "iter 4900: loss 0.8342, time 10.71ms\n",
            "iter 4910: loss 0.8387, time 10.66ms\n",
            "iter 4920: loss 0.8345, time 11.90ms\n",
            "iter 4930: loss 0.8180, time 12.26ms\n",
            "iter 4940: loss 0.8293, time 10.52ms\n",
            "iter 4950: loss 0.8235, time 10.60ms\n",
            "iter 4960: loss 0.8153, time 10.67ms\n",
            "iter 4970: loss 0.8263, time 10.63ms\n",
            "iter 4980: loss 0.8284, time 10.56ms\n",
            "iter 4990: loss 0.7916, time 10.58ms\n",
            "step 5000: train loss 0.6209, val loss 1.6908\n",
            "iter 5000: loss 0.8176, time 2688.25ms\n",
            "training done\n",
            "Best validation loss: 1.4685019254684448\n",
            "Total train time: 1.95 mins\n",
            "Loading meta from ../../data/shakespeare_char/meta.pkl...\n",
            "Sample 1:\n",
            " the convoy.\n",
            "\n",
            "First Senator:\n",
            "Noble Coriolanus!\n",
            "\n",
            "Second Senator:\n",
            "We have a strange a brother, but a slave; for the\n",
            "corn o' the Volsces are now in arms. Take your carters\n",
            "and little Menenius.\n",
            "\n",
            "AUFIDIUS:\n",
            "If it please thee with us, or in a mine arm of being\n",
            "dead, we hear the gods; where we nothing stolen us\n",
            "this sound, as the sea was cause; meak ere now I let them\n",
            "down by the contrary.\n",
            "\n",
            "AUFIDIUS:\n",
            "One of them!\n",
            "\n",
            "First Senator:\n",
            "They shall be satisfied.\n",
            "\n",
            "AUFIDIUS:\n",
            "We know not to know the friar.\n",
            "\n",
            "AUFIDIUS\n",
            "Inference time: 1.82 seconds\n",
            "Tokens per second: 275.35\n",
            "---------------\n",
            "Sample 2:\n",
            " away.\n",
            "\n",
            "DUKE OF YORK:\n",
            "Why then he did say 'Alas,' quoth he that were none?'\n",
            "Ah, which sister, he would be the house of York!'\n",
            "And, whiles he betray'd and was the faces\n",
            "That Richmond was the chiefest of the king!\n",
            "Betwixt the case not was wont to Crosby Place,\n",
            "Whose colours is the father that the waste was\n",
            "He proclaim'd to remote.\n",
            "\n",
            "HERMIONE:\n",
            "What's the news?\n",
            "\n",
            "MAMILLIUS:\n",
            "Why, noble Marcius; the keys hangs off,\n",
            "Because we are but a burthen all to them,\n",
            "For then they love them but better how their hin\n",
            "Inference time: 1.82 seconds\n",
            "Tokens per second: 274.31\n",
            "---------------\n",
            "Sample 3:\n",
            " of love,\n",
            "And I have not touch'd for my death,\n",
            "Nor do meet my excuse to thee,\n",
            "Or, if thou wilt be torment of thy speech,\n",
            "Or else thou thy hit'st a son bear.\n",
            "\n",
            "BRAKENBURY:\n",
            "If thou wouldst keep with intelligence,\n",
            "Were it not reason with thought of wounded victory.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "O, that with the word will it sortly ride.\n",
            "\n",
            "GLOUCESTER:\n",
            "And now is from the welsh of such a door:\n",
            "How will they remain?\n",
            "\n",
            "BUCKINGHAM:\n",
            "What would you perceive me now?\n",
            "\n",
            "QUEEN MARGARET:\n",
            "To form that art thou didst deserve me q\n",
            "Inference time: 1.80 seconds\n",
            "Tokens per second: 277.17\n",
            "---------------\n",
            "Sample 4:\n",
            " not be so.\n",
            "\n",
            "CLAUDIO:\n",
            "Ha! what says my son?\n",
            "\n",
            "ISABELLA:\n",
            "That is the duke?\n",
            "\n",
            "ISABELLA:\n",
            "The duke is not yet?\n",
            "\n",
            "CLAUDIO:\n",
            "Hold, hold; farewell.\n",
            "\n",
            "ISABELLA:\n",
            "Hold, hold; I cry a course; a brief.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Why, very well; 'tis an orators: I warrant you.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "No more but you spoke with me?\n",
            "\n",
            "LUCIO:\n",
            "Then drinkins such a person of the world: the\n",
            "was found the duke's with's to him, and the very word of\n",
            "your due old profit.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Give him head; and, and with some thought in heaven wi\n",
            "Inference time: 1.78 seconds\n",
            "Tokens per second: 280.13\n",
            "---------------\n",
            "Sample 5:\n",
            " this, the tongueless shall see\n",
            "The clouds and piece of stains, and that the manner slew with\n",
            "his sister. The matter was content; but, in man\n",
            "shame to make him a carver with the fairest speech and gold\n",
            "money. Therefore have you any, sir, the poor gentleman rare\n",
            "his head and so well-advocated in a farmer's hot a father, a\n",
            "good accord a trencher; is the letter than a fardel?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "A very resemblance and say it is a matter for the\n",
            "singleness, and a bowl play, it fits for me.\n",
            "\n",
            "LUCIO:\n",
            "\n",
            "ANGE\n",
            "Inference time: 1.82 seconds\n",
            "Tokens per second: 275.04\n",
            "---------------\n",
            "Sample 6:\n",
            " your conscience take on the crown,\n",
            "Do me with your knees, and my brother but a suit;\n",
            "Or, if you do promise me a wrong,\n",
            "I'll bring you your son, on him at all.\n",
            "Here comes the way: for the last, here we'll make his\n",
            "As far as you will, on my ships disgrace.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Well, no more. What counterfeit can you give,\n",
            "Respect my inhuman that will be touch'd\n",
            "Unto the green that you have spoke to my grief?\n",
            "\n",
            "Provost:\n",
            "None of this.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Is it the law will return to your grace?\n",
            "\n",
            "Provost:\n",
            "Ca\n",
            "Inference time: 1.82 seconds\n",
            "Tokens per second: 274.22\n",
            "---------------\n",
            "Sample 7:\n",
            " their stabbles\n",
            "Which should command, as preserve all to take\n",
            "The envious seat, to the common people,\n",
            "Whose house haunts spirit upon them, then mock'd\n",
            "Their heads of soldiers, to fall proclaim\n",
            "Above the moon leads of April's regiment.\n",
            "Come, come, seek what ladybert, seeming souls\n",
            "That, like persuading streets, of breacherous wars\n",
            "That hunts from the sweetest body of the earth\n",
            "The son of heaven and make an egg majesty\n",
            "Where now he shall slay the Sixth\n",
            "And the Lords of Richard Stafford, by his titl\n",
            "Inference time: 1.79 seconds\n",
            "Tokens per second: 279.79\n",
            "---------------\n",
            "Sample 8:\n",
            " and profit to make my\n",
            "services. I shall counsell him for the purpose.\n",
            "\n",
            "Clown:\n",
            "We are the soldier of our bearing affairs; and then\n",
            "these three-love hours should perform accuse me of the\n",
            "shepherds, which if they have stood before no more.\n",
            "\n",
            "AUTOLYCUS:\n",
            "I hope the promising still them safeguardly; but they\n",
            "shall have received them in mind that you still perchance them all while\n",
            "think they live.\n",
            "\n",
            "Clown:\n",
            "You do it even in manners.\n",
            "\n",
            "AUTOLYCUS:\n",
            "Why, sir, sir, I have known by my drunkand, and my\n",
            "friends a\n",
            "Inference time: 1.82 seconds\n",
            "Tokens per second: 275.37\n",
            "---------------\n",
            "Sample 9:\n",
            " and from thy father's head;\n",
            "And then in the sepulchre that I should reach\n",
            "I dreamt the blow of a place, it shall bear,\n",
            "Not so far from thee. The second more I spoke,\n",
            "That I, my minds, my consenting looks\n",
            "With a dear monument, and gives it it.\n",
            "\n",
            "First Citizen:\n",
            "I have not the fearful nor your highness' sweet youth,\n",
            "Nor do me well.\n",
            "\n",
            "First Citizen:\n",
            "We have not you ever a strange abuse, nor else it should\n",
            "remaint consul.\n",
            "\n",
            "Second Citizen:\n",
            "An you so held enough.\n",
            "\n",
            "MENENIUS:\n",
            "That you have pushed me the sp\n",
            "Inference time: 1.79 seconds\n",
            "Tokens per second: 278.96\n",
            "---------------\n",
            "Sample 10:\n",
            " nor fames--\n",
            "\n",
            "LEONTES:\n",
            "Traitors!\n",
            "\n",
            "Officer:\n",
            "I will to him that best action\n",
            "Thou wouldst not be but the lists of ill.\n",
            "\n",
            "DION:\n",
            "O Perdita,\n",
            "The gods think we hear them!\n",
            "\n",
            "LEONTES:\n",
            "What noise the matter\n",
            "He that makes the fame of sense to you,\n",
            "Who has coming to yourselves?\n",
            "\n",
            "LEONTES:\n",
            "With what? what, ho?\n",
            "What's this? cannot this gentleman born?\n",
            "O that a case curding wounds a shining show!\n",
            "What doth she husband in my foot?\n",
            "\n",
            "PAULINA:\n",
            "O my lady's face,\n",
            "As mine is a month pride these of men\n",
            "Whom forth all my k\n",
            "Inference time: 1.81 seconds\n",
            "Tokens per second: 276.14\n",
            "---------------\n",
            "Average tokens per second: 276.65\n",
            "tokens per iteration will be: 8,192\n",
            "found vocab_size = 205 (inside ../../data/enwik8/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 10.70M\n",
            "num decayed parameter tensors: 26, with 10,793,856 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 5.3185, val loss 5.3184\n",
            "iter 0: loss 5.3229, time 33096.10ms\n",
            "iter 100: loss 2.8817, time 9.88ms\n",
            "iter 200: loss 2.6490, time 9.66ms\n",
            "iter 300: loss 2.5468, time 9.67ms\n",
            "iter 400: loss 2.4135, time 9.62ms\n",
            "iter 500: loss 2.3444, time 9.78ms\n",
            "iter 600: loss 2.1677, time 9.75ms\n",
            "iter 700: loss 2.1478, time 11.36ms\n",
            "iter 800: loss 2.0709, time 9.99ms\n",
            "iter 900: loss 1.9550, time 9.71ms\n",
            "step 1000: train loss 1.8117, val loss 1.8177\n",
            "iter 1000: loss 1.9606, time 1659.79ms\n",
            "iter 1100: loss 1.8805, time 9.69ms\n",
            "iter 1200: loss 1.8382, time 9.83ms\n",
            "iter 1300: loss 1.8038, time 9.71ms\n",
            "iter 1400: loss 1.6590, time 9.79ms\n",
            "iter 1500: loss 1.7801, time 9.77ms\n",
            "iter 1600: loss 1.6246, time 9.88ms\n",
            "iter 1700: loss 1.6795, time 9.74ms\n",
            "iter 1800: loss 1.5778, time 10.29ms\n",
            "iter 1900: loss 1.5461, time 9.94ms\n",
            "step 2000: train loss 1.4613, val loss 1.4673\n",
            "iter 2000: loss 1.5414, time 1674.75ms\n",
            "iter 2100: loss 1.5800, time 9.94ms\n",
            "iter 2200: loss 1.4540, time 9.94ms\n",
            "iter 2300: loss 1.3902, time 11.44ms\n",
            "iter 2400: loss 1.5115, time 9.67ms\n",
            "iter 2500: loss 1.4819, time 9.76ms\n",
            "iter 2600: loss 1.5176, time 9.70ms\n",
            "iter 2700: loss 1.4567, time 9.82ms\n",
            "iter 2800: loss 1.5078, time 11.48ms\n",
            "iter 2900: loss 1.4978, time 10.53ms\n",
            "step 3000: train loss 1.3412, val loss 1.3573\n",
            "iter 3000: loss 1.4456, time 1674.73ms\n",
            "iter 3100: loss 1.4312, time 9.72ms\n",
            "iter 3200: loss 1.3084, time 9.99ms\n",
            "iter 3300: loss 1.4066, time 9.73ms\n",
            "iter 3400: loss 1.4018, time 9.89ms\n",
            "iter 3500: loss 1.3776, time 9.83ms\n",
            "iter 3600: loss 1.3407, time 9.74ms\n",
            "iter 3700: loss 1.4217, time 10.27ms\n",
            "iter 3800: loss 1.4059, time 9.91ms\n",
            "iter 3900: loss 1.3879, time 9.70ms\n",
            "step 4000: train loss 1.2902, val loss 1.2984\n",
            "iter 4000: loss 1.3318, time 1738.89ms\n",
            "iter 4100: loss 1.3628, time 11.56ms\n",
            "iter 4200: loss 1.2645, time 9.65ms\n",
            "iter 4300: loss 1.3521, time 9.76ms\n",
            "iter 4400: loss 1.4319, time 9.79ms\n",
            "iter 4500: loss 1.3009, time 9.72ms\n",
            "iter 4600: loss 1.3854, time 9.63ms\n",
            "iter 4700: loss 1.3737, time 9.59ms\n",
            "iter 4800: loss 1.3563, time 9.64ms\n",
            "iter 4900: loss 1.2278, time 9.62ms\n",
            "step 5000: train loss 1.2663, val loss 1.2685\n",
            "iter 5000: loss 1.4060, time 1686.12ms\n",
            "iter 5100: loss 1.3254, time 9.85ms\n",
            "iter 5200: loss 1.2673, time 9.77ms\n",
            "iter 5300: loss 1.3191, time 11.33ms\n",
            "iter 5400: loss 1.3163, time 9.72ms\n",
            "iter 5500: loss 1.3729, time 9.76ms\n",
            "iter 5600: loss 1.2704, time 9.70ms\n",
            "iter 5700: loss 1.3144, time 9.70ms\n",
            "iter 5800: loss 1.2860, time 9.78ms\n",
            "iter 5900: loss 1.3486, time 9.86ms\n",
            "step 6000: train loss 1.2301, val loss 1.2399\n",
            "iter 6000: loss 1.2756, time 1694.60ms\n",
            "iter 6100: loss 1.3424, time 9.73ms\n",
            "iter 6200: loss 1.3667, time 9.65ms\n",
            "iter 6300: loss 1.2063, time 9.81ms\n",
            "iter 6400: loss 1.2998, time 9.75ms\n",
            "iter 6500: loss 1.3145, time 9.70ms\n",
            "iter 6600: loss 1.2716, time 9.76ms\n",
            "iter 6700: loss 1.3462, time 9.72ms\n",
            "iter 6800: loss 1.2903, time 9.82ms\n",
            "iter 6900: loss 1.3058, time 9.76ms\n",
            "step 7000: train loss 1.2142, val loss 1.2293\n",
            "iter 7000: loss 1.2665, time 1699.66ms\n",
            "iter 7100: loss 1.2462, time 9.58ms\n",
            "iter 7200: loss 1.1867, time 9.68ms\n",
            "iter 7300: loss 1.3317, time 9.60ms\n",
            "iter 7400: loss 1.2642, time 9.68ms\n",
            "iter 7500: loss 1.3549, time 9.80ms\n",
            "iter 7600: loss 1.2581, time 9.65ms\n",
            "iter 7700: loss 1.2244, time 9.78ms\n",
            "iter 7800: loss 1.3219, time 9.75ms\n",
            "iter 7900: loss 1.2676, time 9.90ms\n",
            "step 8000: train loss 1.1989, val loss 1.2092\n",
            "iter 8000: loss 1.3167, time 1689.24ms\n",
            "iter 8100: loss 1.2474, time 10.00ms\n",
            "iter 8200: loss 1.2266, time 9.76ms\n",
            "iter 8300: loss 1.2694, time 10.00ms\n",
            "iter 8400: loss 1.1946, time 9.85ms\n",
            "iter 8500: loss 1.3122, time 9.66ms\n",
            "iter 8600: loss 1.2104, time 9.84ms\n",
            "iter 8700: loss 1.2293, time 9.69ms\n",
            "iter 8800: loss 1.2802, time 9.65ms\n",
            "iter 8900: loss 1.1927, time 11.03ms\n",
            "step 9000: train loss 1.1823, val loss 1.1935\n",
            "iter 9000: loss 1.2248, time 1671.74ms\n",
            "iter 9100: loss 1.2075, time 10.74ms\n",
            "iter 9200: loss 1.1914, time 10.85ms\n",
            "iter 9300: loss 1.2097, time 9.64ms\n",
            "iter 9400: loss 1.2028, time 9.82ms\n",
            "iter 9500: loss 1.2199, time 9.59ms\n",
            "iter 9600: loss 1.3070, time 9.56ms\n",
            "iter 9700: loss 1.2689, time 9.66ms\n",
            "iter 9800: loss 1.2539, time 9.79ms\n",
            "iter 9900: loss 1.2357, time 9.90ms\n",
            "step 10000: train loss 1.1708, val loss 1.1888\n",
            "iter 10000: loss 1.2570, time 1687.64ms\n",
            "iter 10100: loss 1.2871, time 9.68ms\n",
            "iter 10200: loss 1.2166, time 10.46ms\n",
            "iter 10300: loss 1.2528, time 10.88ms\n",
            "iter 10400: loss 1.2423, time 9.76ms\n",
            "iter 10500: loss 1.2601, time 9.88ms\n",
            "iter 10600: loss 1.2213, time 9.92ms\n",
            "iter 10700: loss 1.1926, time 9.93ms\n",
            "iter 10800: loss 1.2618, time 9.87ms\n",
            "iter 10900: loss 1.2581, time 9.95ms\n",
            "step 11000: train loss 1.1671, val loss 1.1787\n",
            "iter 11000: loss 1.2839, time 1679.07ms\n",
            "iter 11100: loss 1.1659, time 9.70ms\n",
            "iter 11200: loss 1.1849, time 9.69ms\n",
            "iter 11300: loss 1.2890, time 9.93ms\n",
            "iter 11400: loss 1.2167, time 10.00ms\n",
            "iter 11500: loss 1.2565, time 9.71ms\n",
            "iter 11600: loss 1.2241, time 9.76ms\n",
            "iter 11700: loss 1.2241, time 9.79ms\n",
            "iter 11800: loss 1.2943, time 9.88ms\n",
            "iter 11900: loss 1.2399, time 9.67ms\n",
            "step 12000: train loss 1.1590, val loss 1.1763\n",
            "iter 12000: loss 1.2804, time 1662.73ms\n",
            "iter 12100: loss 1.2030, time 9.66ms\n",
            "iter 12200: loss 1.2696, time 9.88ms\n",
            "iter 12300: loss 1.1754, time 10.01ms\n",
            "iter 12400: loss 1.2176, time 9.82ms\n",
            "iter 12500: loss 1.1337, time 9.77ms\n",
            "iter 12600: loss 1.2243, time 9.75ms\n",
            "iter 12700: loss 1.1121, time 9.79ms\n",
            "iter 12800: loss 1.2201, time 9.63ms\n",
            "iter 12900: loss 1.2302, time 9.62ms\n",
            "step 13000: train loss 1.1495, val loss 1.1629\n",
            "iter 13000: loss 1.1673, time 1661.68ms\n",
            "iter 13100: loss 1.2076, time 9.69ms\n",
            "iter 13200: loss 1.1694, time 9.71ms\n",
            "iter 13300: loss 1.2510, time 9.67ms\n",
            "iter 13400: loss 1.2276, time 10.06ms\n",
            "iter 13500: loss 1.1747, time 9.70ms\n",
            "iter 13600: loss 1.1629, time 9.62ms\n",
            "iter 13700: loss 1.2276, time 9.72ms\n",
            "iter 13800: loss 1.1566, time 9.63ms\n",
            "iter 13900: loss 1.2092, time 9.63ms\n",
            "step 14000: train loss 1.1394, val loss 1.1603\n",
            "iter 14000: loss 1.1773, time 1670.82ms\n",
            "iter 14100: loss 1.2198, time 9.74ms\n",
            "iter 14200: loss 1.1574, time 9.62ms\n",
            "iter 14300: loss 1.2530, time 9.95ms\n",
            "iter 14400: loss 1.1997, time 9.66ms\n",
            "iter 14500: loss 1.2316, time 9.61ms\n",
            "iter 14600: loss 1.2283, time 9.59ms\n",
            "iter 14700: loss 1.1477, time 9.52ms\n",
            "iter 14800: loss 1.1562, time 9.53ms\n",
            "iter 14900: loss 1.2026, time 9.54ms\n",
            "step 15000: train loss 1.1384, val loss 1.1500\n",
            "iter 15000: loss 1.2638, time 1689.06ms\n",
            "iter 15100: loss 1.2254, time 9.65ms\n",
            "iter 15200: loss 1.2278, time 9.68ms\n",
            "iter 15300: loss 1.2064, time 9.60ms\n",
            "iter 15400: loss 1.2328, time 10.13ms\n",
            "iter 15500: loss 1.1896, time 10.18ms\n",
            "iter 15600: loss 1.1821, time 9.80ms\n",
            "iter 15700: loss 1.1521, time 10.37ms\n",
            "iter 15800: loss 1.1916, time 10.83ms\n",
            "iter 15900: loss 1.1160, time 9.70ms\n",
            "step 16000: train loss 1.1303, val loss 1.1587\n",
            "iter 16000: loss 1.1899, time 1695.08ms\n",
            "iter 16100: loss 1.1946, time 9.77ms\n",
            "iter 16200: loss 1.1593, time 9.58ms\n",
            "iter 16300: loss 1.1775, time 9.71ms\n",
            "iter 16400: loss 1.1557, time 9.73ms\n",
            "iter 16500: loss 1.2447, time 9.60ms\n",
            "iter 16600: loss 1.2117, time 9.87ms\n",
            "iter 16700: loss 1.1578, time 9.57ms\n",
            "iter 16800: loss 1.2405, time 9.83ms\n",
            "iter 16900: loss 1.1874, time 9.69ms\n",
            "step 17000: train loss 1.1216, val loss 1.1452\n",
            "iter 17000: loss 1.1784, time 1658.62ms\n",
            "iter 17100: loss 1.1462, time 13.32ms\n",
            "iter 17200: loss 1.1618, time 9.68ms\n",
            "iter 17300: loss 1.2779, time 9.69ms\n",
            "iter 17400: loss 1.1858, time 10.09ms\n",
            "iter 17500: loss 1.2013, time 10.19ms\n",
            "iter 17600: loss 1.2512, time 9.87ms\n",
            "iter 17700: loss 1.2143, time 10.25ms\n",
            "iter 17800: loss 1.2312, time 9.78ms\n",
            "iter 17900: loss 1.1804, time 9.68ms\n",
            "step 18000: train loss 1.1196, val loss 1.1443\n",
            "iter 18000: loss 1.2203, time 1720.57ms\n",
            "iter 18100: loss 1.2081, time 9.69ms\n",
            "iter 18200: loss 1.2088, time 9.68ms\n",
            "iter 18300: loss 1.1827, time 9.70ms\n",
            "iter 18400: loss 1.2605, time 9.67ms\n",
            "iter 18500: loss 1.2546, time 9.76ms\n",
            "iter 18600: loss 1.2618, time 9.79ms\n",
            "iter 18700: loss 1.2299, time 9.84ms\n",
            "iter 18800: loss 1.1445, time 11.33ms\n",
            "iter 18900: loss 1.2657, time 9.73ms\n",
            "step 19000: train loss 1.1174, val loss 1.1355\n",
            "iter 19000: loss 1.1880, time 1681.37ms\n",
            "iter 19100: loss 1.1189, time 9.71ms\n",
            "iter 19200: loss 1.1554, time 9.81ms\n",
            "iter 19300: loss 1.2204, time 9.71ms\n",
            "iter 19400: loss 1.1599, time 9.73ms\n",
            "iter 19500: loss 1.2416, time 9.99ms\n",
            "iter 19600: loss 1.1603, time 9.70ms\n",
            "iter 19700: loss 1.1636, time 9.91ms\n",
            "iter 19800: loss 1.1905, time 10.37ms\n",
            "iter 19900: loss 1.1128, time 9.56ms\n",
            "step 20000: train loss 1.1125, val loss 1.1315\n",
            "iter 20000: loss 1.1634, time 1653.18ms\n",
            "iter 20100: loss 1.1821, time 9.60ms\n",
            "iter 20200: loss 1.2012, time 9.63ms\n",
            "iter 20300: loss 1.1246, time 9.59ms\n",
            "iter 20400: loss 1.2105, time 9.65ms\n",
            "iter 20500: loss 1.1602, time 9.58ms\n",
            "iter 20600: loss 1.1005, time 9.64ms\n",
            "iter 20700: loss 1.1893, time 9.62ms\n",
            "iter 20800: loss 1.1806, time 10.36ms\n",
            "iter 20900: loss 1.2044, time 9.69ms\n",
            "step 21000: train loss 1.1135, val loss 1.1343\n",
            "iter 21000: loss 1.1943, time 1653.59ms\n",
            "iter 21100: loss 1.1990, time 9.56ms\n",
            "iter 21200: loss 1.2421, time 9.53ms\n",
            "iter 21300: loss 1.2213, time 9.53ms\n",
            "iter 21400: loss 1.1105, time 9.78ms\n",
            "iter 21500: loss 1.1404, time 9.95ms\n",
            "iter 21600: loss 1.1432, time 9.65ms\n",
            "iter 21700: loss 1.1827, time 9.69ms\n",
            "iter 21800: loss 1.0617, time 10.01ms\n",
            "iter 21900: loss 1.2461, time 11.04ms\n",
            "step 22000: train loss 1.1071, val loss 1.1233\n",
            "iter 22000: loss 1.1842, time 1655.96ms\n",
            "iter 22100: loss 1.1656, time 9.68ms\n",
            "iter 22200: loss 1.2154, time 9.68ms\n",
            "iter 22300: loss 1.1521, time 13.00ms\n",
            "iter 22400: loss 1.1635, time 9.70ms\n",
            "iter 22500: loss 1.1425, time 10.00ms\n",
            "iter 22600: loss 1.1644, time 9.68ms\n",
            "iter 22700: loss 1.1190, time 9.74ms\n",
            "iter 22800: loss 1.1651, time 9.73ms\n",
            "iter 22900: loss 1.1762, time 9.71ms\n",
            "step 23000: train loss 1.1074, val loss 1.1262\n",
            "iter 23000: loss 1.2383, time 1683.00ms\n",
            "iter 23100: loss 1.1364, time 9.78ms\n",
            "iter 23200: loss 1.0952, time 9.69ms\n",
            "iter 23300: loss 1.0596, time 9.68ms\n",
            "iter 23400: loss 1.1869, time 9.75ms\n",
            "iter 23500: loss 1.1985, time 9.67ms\n",
            "iter 23600: loss 1.0760, time 9.72ms\n",
            "iter 23700: loss 1.1702, time 9.60ms\n",
            "iter 23800: loss 1.1442, time 9.62ms\n",
            "iter 23900: loss 1.1333, time 9.93ms\n",
            "step 24000: train loss 1.1022, val loss 1.1209\n",
            "iter 24000: loss 1.0944, time 1685.57ms\n",
            "iter 24100: loss 1.1438, time 9.65ms\n",
            "iter 24200: loss 1.1791, time 9.69ms\n",
            "iter 24300: loss 1.1870, time 9.83ms\n",
            "iter 24400: loss 1.2502, time 9.87ms\n",
            "iter 24500: loss 1.1272, time 9.85ms\n",
            "iter 24600: loss 1.1201, time 10.13ms\n",
            "iter 24700: loss 1.1687, time 10.14ms\n",
            "iter 24800: loss 1.2058, time 9.77ms\n",
            "iter 24900: loss 1.1959, time 10.00ms\n",
            "step 25000: train loss 1.0959, val loss 1.1178\n",
            "iter 25000: loss 1.1414, time 1703.70ms\n",
            "iter 25100: loss 1.1853, time 9.56ms\n",
            "iter 25200: loss 1.2112, time 10.14ms\n",
            "iter 25300: loss 1.0574, time 9.70ms\n",
            "iter 25400: loss 1.2062, time 9.85ms\n",
            "iter 25500: loss 1.1596, time 9.67ms\n",
            "iter 25600: loss 1.2232, time 9.59ms\n",
            "iter 25700: loss 1.1962, time 9.85ms\n",
            "iter 25800: loss 1.1011, time 9.71ms\n",
            "iter 25900: loss 1.1228, time 9.65ms\n",
            "step 26000: train loss 1.0921, val loss 1.1190\n",
            "iter 26000: loss 1.2368, time 1687.08ms\n",
            "iter 26100: loss 1.1201, time 9.74ms\n",
            "iter 26200: loss 1.1434, time 9.68ms\n",
            "iter 26300: loss 1.1630, time 9.70ms\n",
            "iter 26400: loss 1.1257, time 9.89ms\n",
            "iter 26500: loss 1.1506, time 9.91ms\n",
            "iter 26600: loss 1.2125, time 9.74ms\n",
            "iter 26700: loss 1.0610, time 9.74ms\n",
            "iter 26800: loss 1.0781, time 9.74ms\n",
            "iter 26900: loss 1.1757, time 9.86ms\n",
            "step 27000: train loss 1.0969, val loss 1.1137\n",
            "iter 27000: loss 1.1900, time 1694.05ms\n",
            "iter 27100: loss 1.1435, time 9.75ms\n",
            "iter 27200: loss 1.1765, time 9.87ms\n",
            "iter 27300: loss 1.1092, time 9.82ms\n",
            "iter 27400: loss 1.1260, time 9.66ms\n",
            "iter 27500: loss 1.1665, time 13.55ms\n",
            "iter 27600: loss 1.1716, time 9.77ms\n",
            "iter 27700: loss 1.1526, time 9.68ms\n",
            "iter 27800: loss 1.1128, time 9.92ms\n",
            "iter 27900: loss 1.1953, time 9.66ms\n",
            "step 28000: train loss 1.0884, val loss 1.1087\n",
            "iter 28000: loss 1.1542, time 1710.12ms\n",
            "iter 28100: loss 1.0643, time 10.90ms\n",
            "iter 28200: loss 1.0964, time 9.81ms\n",
            "iter 28300: loss 1.1508, time 11.27ms\n",
            "iter 28400: loss 1.2322, time 9.74ms\n",
            "iter 28500: loss 1.0688, time 9.79ms\n",
            "iter 28600: loss 1.1442, time 9.80ms\n",
            "iter 28700: loss 1.1275, time 9.75ms\n",
            "iter 28800: loss 1.1409, time 9.75ms\n",
            "iter 28900: loss 1.0571, time 9.85ms\n",
            "step 29000: train loss 1.0805, val loss 1.1054\n",
            "iter 29000: loss 1.1256, time 1673.52ms\n",
            "iter 29100: loss 1.1477, time 10.80ms\n",
            "iter 29200: loss 1.0785, time 9.63ms\n",
            "iter 29300: loss 1.1518, time 9.60ms\n",
            "iter 29400: loss 1.1415, time 9.61ms\n",
            "iter 29500: loss 1.1357, time 9.62ms\n",
            "iter 29600: loss 1.0573, time 9.61ms\n",
            "iter 29700: loss 1.1422, time 9.68ms\n",
            "iter 29800: loss 1.1756, time 9.57ms\n",
            "iter 29900: loss 1.1805, time 11.48ms\n",
            "step 30000: train loss 1.0813, val loss 1.1033\n",
            "iter 30000: loss 1.1073, time 1666.62ms\n",
            "iter 30100: loss 1.0580, time 9.67ms\n",
            "iter 30200: loss 1.1202, time 10.39ms\n",
            "iter 30300: loss 1.1683, time 9.71ms\n",
            "iter 30400: loss 1.1691, time 9.90ms\n",
            "iter 30500: loss 1.1739, time 9.61ms\n",
            "iter 30600: loss 1.1773, time 9.47ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2D Diffussion**\n",
        "\n",
        "Description: This template studies improving the performance of diffusion generative models on low-dimensional datasets."
      ],
      "metadata": {
        "id": "EBtTx0Q0jsST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install dependencies:"
      ],
      "metadata": {
        "id": "McfKJWYaunq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up 2D Diffusion\n",
        "!git clone https://github.com/gregversteeg/NPEET.git\n",
        "!cd NPEET\n",
        "#!pip install .\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "r_Gp4iYfjr6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create baseline runs:"
      ],
      "metadata": {
        "id": "UYgciyzYknAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkL-AmyG_U0F",
        "outputId": "77a256ef-4ac8-4e94-cebb-25323a7d09a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasaurusDozen.tsv  ema_pytorch.py  ideas.json  plot.py      seed_ideas.json\n",
            "datasets.py          experiment.py   \u001b[0m\u001b[01;34mlatex\u001b[0m/      prompt.json  train_loss.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up 2D Diffusion baseline run\n",
        "\n",
        "%cd /content/AI-Scientist/templates/2d_diffusion\n",
        "#%cd templates/2d_diffusion\n",
        "!python experiment.py --out_dir run_0\n",
        "!python plot.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o4XdPdqux7v",
        "outputId": "865d0af5-0458-48dd-d102-9c70b8f2685b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-Scientist/templates/2d_diffusion\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AI-Scientist/templates/2d_diffusion/experiment.py\", line 10, in <module>\n",
            "    import npeet.entropy_estimators as ee\n",
            "ModuleNotFoundError: No module named 'npeet'\n",
            "Figure(1400x800)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AI-Scientist/templates/2d_diffusion/plot.py\", line 81, in <module>\n",
            "    fig, axs = plt.subplots(num_runs, 4, figsize=(14, 3 * num_runs))\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\", line 1776, in subplots\n",
            "    axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/figure.py\", line 918, in subplots\n",
            "    gs = self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/figure.py\", line 1600, in add_gridspec\n",
            "    gs = GridSpec(nrows=nrows, ncols=ncols, figure=self, **kwargs)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/gridspec.py\", line 363, in __init__\n",
            "    super().__init__(nrows, ncols,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/gridspec.py\", line 48, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: Number of rows must be a positive integer, not 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grokking**\n",
        "\n",
        "Description: This template investigates questions about generalization and learning speed in deep neural networks."
      ],
      "metadata": {
        "id": "tewoMBa0wUaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install dependencies:"
      ],
      "metadata": {
        "id": "zaWOhD-YwUaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Grokking\n",
        "\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930c6e43-3819-4571-dfb7-cf38fb5c7448",
        "id": "71zOLTqqwUaE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create baseline runs:"
      ],
      "metadata": {
        "id": "XULjC7HfwUaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up 2D Diffusion baseline run\n",
        "\n",
        "%cd /content/AI-Scientist/templates/grokking\n",
        "\n",
        "!python experiment.py --out_dir run_0\n",
        "!python plot.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqC4xf_AwUaF",
        "outputId": "66d42af4-eb0f-45ea-d76c-7088eb718d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-Scientist/templates/grokking\n",
            "Running x_div_y with seed offset 0\n",
            "{'final_train_loss': 0.0043488978408277035, 'final_val_loss': 0.00575057789683342, 'final_train_acc': 1.0, 'final_val_acc': 1.0, 'step_val_acc_99': 4470}\n",
            "Running x_div_y with seed offset 1\n",
            "{'final_train_loss': 0.005255431402474642, 'final_val_loss': 0.006333010271191597, 'final_train_acc': 1.0, 'final_val_acc': 1.0, 'step_val_acc_99': 4200}\n",
            "Running x_div_y with seed offset 2\n",
            "{'final_train_loss': 1.6195591688156128, 'final_val_loss': 0.6360082030296326, 'final_train_acc': 0.644335925579071, 'final_val_acc': 0.873779296875, 'step_val_acc_99': 5380}\n",
            "Running x_minus_y with seed offset 0\n",
            "{'final_train_loss': 0.004558430518954992, 'final_val_loss': 0.005506541114300489, 'final_train_acc': 1.0, 'final_val_acc': 1.0, 'step_val_acc_99': 4210}\n",
            "Running x_minus_y with seed offset 1\n",
            "{'final_train_loss': 0.047082994133234024, 'final_val_loss': 0.054392553865909576, 'final_train_acc': 0.999218761920929, 'final_val_acc': 0.9970703125, 'step_val_acc_99': 5410}\n",
            "Running x_minus_y with seed offset 2\n",
            "{'final_train_loss': 0.008925261907279491, 'final_val_loss': 0.016474248841404915, 'final_train_acc': 1.0, 'final_val_acc': 1.0, 'step_val_acc_99': 5620}\n",
            "Running x_plus_y with seed offset 0\n",
            "{'final_train_loss': 1.8999789953231812, 'final_val_loss': 0.7317614555358887, 'final_train_acc': 0.601367175579071, 'final_val_acc': 0.8935546875, 'step_val_acc_99': 3730}\n",
            "Running x_plus_y with seed offset 1\n",
            "{'final_train_loss': 0.004320650827139616, 'final_val_loss': 0.00445975549519062, 'final_train_acc': 1.0, 'final_val_acc': 1.0, 'step_val_acc_99': 1790}\n",
            "Running x_plus_y with seed offset 2\n",
            "{'final_train_loss': 0.005429127253592014, 'final_val_loss': 0.005694805644452572, 'final_train_acc': 1.0, 'final_val_acc': 1.0, 'step_val_acc_99': 1960}\n",
            "Running permutation with seed offset 0\n",
            "{'final_train_loss': 0.0038787114899605513, 'final_val_loss': 0.383646160364151, 'final_train_acc': 1.0, 'final_val_acc': 0.91162109375, 'step_val_acc_99': 7500}\n",
            "Running permutation with seed offset 1\n",
            "{'final_train_loss': 0.01667962782084942, 'final_val_loss': 7.446049213409424, 'final_train_acc': 0.999804675579071, 'final_val_acc': 0.0185546875, 'step_val_acc_99': 7500}\n",
            "Running permutation with seed offset 2\n",
            "{'final_train_loss': 0.010082538239657879, 'final_val_loss': 8.043066024780273, 'final_train_acc': 1.0, 'final_val_acc': 0.01025390625, 'step_val_acc_99': 7500}\n",
            "dict_keys(['x_div_y_0_final_info', 'x_div_y_0_train_info', 'x_div_y_0_val_info', 'x_div_y_1_final_info', 'x_div_y_1_train_info', 'x_div_y_1_val_info', 'x_div_y_2_final_info', 'x_div_y_2_train_info', 'x_div_y_2_val_info', 'x_minus_y_0_final_info', 'x_minus_y_0_train_info', 'x_minus_y_0_val_info', 'x_minus_y_1_final_info', 'x_minus_y_1_train_info', 'x_minus_y_1_val_info', 'x_minus_y_2_final_info', 'x_minus_y_2_train_info', 'x_minus_y_2_val_info', 'x_plus_y_0_final_info', 'x_plus_y_0_train_info', 'x_plus_y_0_val_info', 'x_plus_y_1_final_info', 'x_plus_y_1_train_info', 'x_plus_y_1_val_info', 'x_plus_y_2_final_info', 'x_plus_y_2_train_info', 'x_plus_y_2_val_info', 'permutation_0_final_info', 'permutation_0_train_info', 'permutation_0_val_info', 'permutation_1_final_info', 'permutation_1_train_info', 'permutation_1_val_info', 'permutation_2_final_info', 'permutation_2_train_info', 'permutation_2_val_info'])\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform_experiments.py\n",
        "\n",
        "import json\n",
        "import os.path as osp\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from subprocess import TimeoutExpired\n",
        "\n",
        "MAX_ITERS = 4\n",
        "MAX_RUNS = 5\n",
        "MAX_STDERR_OUTPUT = 1500\n",
        "\n",
        "coder_prompt = \"\"\"Your goal is to implement the following idea: {title}.\n",
        "The proposed experiment is as follows: {idea}.\n",
        "You are given a total of up to {max_runs} runs to complete the necessary experiments. You do not need to use all {max_runs}.\n",
        "\n",
        "First, plan the list of experiments you would like to run. For example, if you are sweeping over a specific hyperparameter, plan each value you would like to test for each run.\n",
        "\n",
        "Note that we already provide the vanilla baseline results, so you do not need to re-run it.\n",
        "\n",
        "For reference, the baseline results are as follows:\n",
        "\n",
        "{baseline_results}\n",
        "\n",
        "After you complete each change, we will run the command `python experiment.py --out_dir=run_i' where i is the run number and evaluate the results.\n",
        "YOUR PROPOSED CHANGE MUST USE THIS COMMAND FORMAT, DO NOT ADD ADDITIONAL COMMAND LINE ARGS.\n",
        "You can then implement the next thing on your list.\"\"\"\n",
        "\n",
        "\n",
        "# RUN EXPERIMENT\n",
        "def run_experiment(folder_name, run_num, timeout=7200):\n",
        "    cwd = osp.abspath(folder_name)\n",
        "    # COPY CODE SO WE CAN SEE IT.\n",
        "    shutil.copy(\n",
        "        osp.join(folder_name, \"experiment.py\"),\n",
        "        osp.join(folder_name, f\"run_{run_num}.py\"),\n",
        "    )\n",
        "\n",
        "    # LAUNCH COMMAND\n",
        "    command = [\n",
        "        \"python\",\n",
        "        \"experiment.py\",\n",
        "        f\"--out_dir=run_{run_num}\",\n",
        "    ]\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            command, cwd=cwd, stderr=subprocess.PIPE, text=True, timeout=timeout\n",
        "        )\n",
        "\n",
        "        if result.stderr:\n",
        "            print(result.stderr, file=sys.stderr)\n",
        "\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Run {run_num} failed with return code {result.returncode}\")\n",
        "            if osp.exists(osp.join(cwd, f\"run_{run_num}\")):\n",
        "                shutil.rmtree(osp.join(cwd, f\"run_{run_num}\"))\n",
        "            print(f\"Run failed with the following error {result.stderr}\")\n",
        "            stderr_output = result.stderr\n",
        "            if len(stderr_output) > MAX_STDERR_OUTPUT:\n",
        "                stderr_output = \"...\" + stderr_output[-MAX_STDERR_OUTPUT:]\n",
        "            next_prompt = f\"Run failed with the following error {stderr_output}\"\n",
        "        else:\n",
        "            with open(osp.join(cwd, f\"run_{run_num}\", \"final_info.json\"), \"r\") as f:\n",
        "                results = json.load(f)\n",
        "            results = {k: v[\"means\"] for k, v in results.items()}\n",
        "\n",
        "            next_prompt = f\"\"\"Run {run_num} completed. Here are the results:\n",
        "{results}\n",
        "\n",
        "Decide if you need to re-plan your experiments given the result (you often will not need to).\n",
        "\n",
        "Someone else will be using `notes.txt` to perform a writeup on this in the future.\n",
        "Please include *all* relevant information for the writeup on Run {run_num}, including an experiment description and the run number. Be as verbose as necessary.\n",
        "\n",
        "Then, implement the next thing on your list.\n",
        "We will then run the command `python experiment.py --out_dir=run_{run_num + 1}'.\n",
        "YOUR PROPOSED CHANGE MUST USE THIS COMMAND FORMAT, DO NOT ADD ADDITIONAL COMMAND LINE ARGS.\n",
        "If you are finished with experiments, respond with 'ALL_COMPLETED'.\"\"\"\n",
        "        return result.returncode, next_prompt\n",
        "    except TimeoutExpired:\n",
        "        print(f\"Run {run_num} timed out after {timeout} seconds\")\n",
        "        if osp.exists(osp.join(cwd, f\"run_{run_num}\")):\n",
        "            shutil.rmtree(osp.join(cwd, f\"run_{run_num}\"))\n",
        "        next_prompt = f\"Run timed out after {timeout} seconds\"\n",
        "        return 1, next_prompt\n",
        "\n",
        "\n",
        "# RUN PLOTTING\n",
        "def run_plotting(folder_name, timeout=600):\n",
        "    cwd = osp.abspath(folder_name)\n",
        "    # LAUNCH COMMAND\n",
        "    command = [\n",
        "        \"python\",\n",
        "        \"plot.py\",\n",
        "    ]\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            command, cwd=cwd, stderr=subprocess.PIPE, text=True, timeout=timeout\n",
        "        )\n",
        "\n",
        "        if result.stderr:\n",
        "            print(result.stderr, file=sys.stderr)\n",
        "\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Plotting failed with return code {result.returncode}\")\n",
        "            next_prompt = f\"Plotting failed with the following error {result.stderr}\"\n",
        "        else:\n",
        "            next_prompt = \"\"\n",
        "        return result.returncode, next_prompt\n",
        "    except TimeoutExpired:\n",
        "        print(f\"Plotting timed out after {timeout} seconds\")\n",
        "        next_prompt = f\"Plotting timed out after {timeout} seconds\"\n",
        "        return 1, next_prompt\n",
        "\n",
        "\n",
        "# PERFORM EXPERIMENTS\n",
        "def perform_experiments(idea, folder_name, coder, baseline_results) -> bool:\n",
        "    ## RUN EXPERIMENT\n",
        "    current_iter = 0\n",
        "    run = 1\n",
        "    next_prompt = coder_prompt.format(\n",
        "        title=idea[\"Title\"],\n",
        "        idea=idea[\"Experiment\"],\n",
        "        max_runs=MAX_RUNS,\n",
        "        baseline_results=baseline_results,\n",
        "    )\n",
        "    while run < MAX_RUNS + 1:\n",
        "        if current_iter >= MAX_ITERS:\n",
        "            print(\"Max iterations reached\")\n",
        "            break\n",
        "        coder_out = coder.run(next_prompt)\n",
        "        print(coder_out)\n",
        "        if \"ALL_COMPLETED\" in coder_out:\n",
        "            break\n",
        "        return_code, next_prompt = run_experiment(folder_name, run)\n",
        "        if return_code == 0:\n",
        "            run += 1\n",
        "            current_iter = 0\n",
        "        current_iter += 1\n",
        "    if current_iter >= MAX_ITERS:\n",
        "        print(\"Not all experiments completed.\")\n",
        "        return False\n",
        "\n",
        "    current_iter = 0\n",
        "    next_prompt = \"\"\"\n",
        "Great job! Please modify `plot.py` to generate the most relevant plots for the final writeup.\n",
        "\n",
        "In particular, be sure to fill in the \"labels\" dictionary with the correct names for each run that you want to plot.\n",
        "\n",
        "Only the runs in the `labels` dictionary will be plotted, so make sure to include all relevant runs.\n",
        "\n",
        "We will be running the command `python plot.py` to generate the plots.\n",
        "\"\"\"\n",
        "    while True:\n",
        "        _ = coder.run(next_prompt)\n",
        "        return_code, next_prompt = run_plotting(folder_name)\n",
        "        current_iter += 1\n",
        "        if return_code == 0 or current_iter >= MAX_ITERS:\n",
        "            break\n",
        "    next_prompt = \"\"\"\n",
        "Please modify `notes.txt` with a description of what each plot shows along with the filename of the figure. Please do so in-depth.\n",
        "\n",
        "Somebody else will be using `notes.txt` to write a report on this in the future.\n",
        "\"\"\"\n",
        "    coder.run(next_prompt)\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "ZvWR_A6KPHsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wujSuT95O5-H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tWyBE-IO5rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run AI Scientist Paper Generation Experiments**"
      ],
      "metadata": {
        "id": "AJNuFPRRGELO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run paper generation\n",
        "\n",
        "!python launch_scientist.py --model \"gpt-4o-2024-05-13\" --experiment nanoGPT_lite --num-ideas 2\n",
        "#!python launch_scientist.py --model \"claude-3-5-sonnet-20241022\" --experiment nanoGPT_lite --num-ideas"
      ],
      "metadata": {
        "id": "1j68V8bXGD6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting an LLM-Generated Paper Review**\n"
      ],
      "metadata": {
        "id": "nex6pFyaGeG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n",
        "!pip install pymupdf\n",
        "!pip install pymupdf4llm\n",
        "!pip install backoff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGAme5bKKU8_",
        "outputId": "710f8cad-35b4-49dd-af51-4fa22f97c29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.4)\n",
            "Collecting pymupdf4llm\n",
            "  Downloading pymupdf4llm-0.0.17-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: pymupdf>=1.24.10 in /usr/local/lib/python3.11/dist-packages (from pymupdf4llm) (1.25.4)\n",
            "Downloading pymupdf4llm-0.0.17-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pymupdf4llm\n",
            "Successfully installed pymupdf4llm-0.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNNkoTZHM24m",
        "outputId": "66efc103-04c3-465d-aff8-848fed719bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.2)\n",
            "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/243.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.49.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm.py\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import anthropic\n",
        "import backoff\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import GenerationConfig\n",
        "\n",
        "MAX_NUM_TOKENS = 4096\n",
        "\n",
        "AVAILABLE_LLMS = [\n",
        "    # Anthropic models\n",
        "    \"claude-3-5-sonnet-20240620\",\n",
        "    \"claude-3-5-sonnet-20241022\",\n",
        "    # OpenAI models\n",
        "    \"gpt-4o-mini-2024-07-18\",\n",
        "    \"gpt-4o-2024-05-13\",\n",
        "    \"gpt-4o-2024-08-06\",\n",
        "    \"o1-preview-2024-09-12\",\n",
        "    \"o1-mini-2024-09-12\",\n",
        "    \"o1-2024-12-17\",\n",
        "    # OpenRouter models\n",
        "    \"llama3.1-405b\",\n",
        "    # Anthropic Claude models via Amazon Bedrock\n",
        "    \"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\",\n",
        "    \"bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
        "    \"bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
        "    \"bedrock/anthropic.claude-3-haiku-20240307-v1:0\",\n",
        "    \"bedrock/anthropic.claude-3-opus-20240229-v1:0\",\n",
        "    # Anthropic Claude models Vertex AI\n",
        "    \"vertex_ai/claude-3-opus@20240229\",\n",
        "    \"vertex_ai/claude-3-5-sonnet@20240620\",\n",
        "    \"vertex_ai/claude-3-5-sonnet-v2@20241022\",\n",
        "    \"vertex_ai/claude-3-sonnet@20240229\",\n",
        "    \"vertex_ai/claude-3-haiku@20240307\",\n",
        "    # DeepSeek models\n",
        "    \"deepseek-chat\",\n",
        "    \"deepseek-coder\",\n",
        "    \"deepseek-reasoner\",\n",
        "    # Google Gemini models\n",
        "    \"gemini-1.5-flash\",\n",
        "    \"gemini-1.5-pro\",\n",
        "]\n",
        "\n",
        "\n",
        "# Get N responses from a single message, used for ensembling.\n",
        "@backoff.on_exception(backoff.expo, (openai.RateLimitError, openai.APITimeoutError))\n",
        "def get_batch_responses_from_llm(\n",
        "        msg,\n",
        "        client,\n",
        "        model,\n",
        "        system_message,\n",
        "        print_debug=False,\n",
        "        msg_history=None,\n",
        "        temperature=0.75,\n",
        "        n_responses=1,\n",
        "):\n",
        "    if msg_history is None:\n",
        "        msg_history = []\n",
        "\n",
        "    if model in [\n",
        "        \"gpt-4o-2024-05-13\",\n",
        "        \"gpt-4o-mini-2024-07-18\",\n",
        "        \"gpt-4o-2024-08-06\",\n",
        "    ]:\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                *new_msg_history,\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=MAX_NUM_TOKENS,\n",
        "            n=n_responses,\n",
        "            stop=None,\n",
        "            seed=0,\n",
        "        )\n",
        "        content = [r.message.content for r in response.choices]\n",
        "        new_msg_history = [\n",
        "            new_msg_history + [{\"role\": \"assistant\", \"content\": c}] for c in content\n",
        "        ]\n",
        "    elif model == \"llama-3-1-405b-instruct\":\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"meta-llama/llama-3.1-405b-instruct\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                *new_msg_history,\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=MAX_NUM_TOKENS,\n",
        "            n=n_responses,\n",
        "            stop=None,\n",
        "        )\n",
        "        content = [r.message.content for r in response.choices]\n",
        "        new_msg_history = [\n",
        "            new_msg_history + [{\"role\": \"assistant\", \"content\": c}] for c in content\n",
        "        ]\n",
        "    else:\n",
        "        content, new_msg_history = [], []\n",
        "        for _ in range(n_responses):\n",
        "            c, hist = get_response_from_llm(\n",
        "                msg,\n",
        "                client,\n",
        "                model,\n",
        "                system_message,\n",
        "                print_debug=False,\n",
        "                msg_history=None,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            content.append(c)\n",
        "            new_msg_history.append(hist)\n",
        "\n",
        "    if print_debug:\n",
        "        print()\n",
        "        print(\"*\" * 20 + \" LLM START \" + \"*\" * 20)\n",
        "        for j, msg in enumerate(new_msg_history[0]):\n",
        "            print(f'{j}, {msg[\"role\"]}: {msg[\"content\"]}')\n",
        "        print(content)\n",
        "        print(\"*\" * 21 + \" LLM END \" + \"*\" * 21)\n",
        "        print()\n",
        "\n",
        "    return content, new_msg_history\n",
        "\n",
        "\n",
        "@backoff.on_exception(backoff.expo, (openai.RateLimitError, openai.APITimeoutError))\n",
        "def get_response_from_llm(\n",
        "        msg,\n",
        "        client,\n",
        "        model,\n",
        "        system_message,\n",
        "        print_debug=False,\n",
        "        msg_history=None,\n",
        "        temperature=0.75,\n",
        "):\n",
        "    if msg_history is None:\n",
        "        msg_history = []\n",
        "\n",
        "    if \"claude\" in model:\n",
        "        new_msg_history = msg_history + [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": msg,\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "        response = client.messages.create(\n",
        "            model=model,\n",
        "            max_tokens=MAX_NUM_TOKENS,\n",
        "            temperature=temperature,\n",
        "            system=system_message,\n",
        "            messages=new_msg_history,\n",
        "        )\n",
        "        content = response.content[0].text\n",
        "        new_msg_history = new_msg_history + [\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": content,\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "    elif model in [\n",
        "        \"gpt-4o-2024-05-13\",\n",
        "        \"gpt-4o-mini-2024-07-18\",\n",
        "        \"gpt-4o-2024-08-06\",\n",
        "    ]:\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                *new_msg_history,\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=MAX_NUM_TOKENS,\n",
        "            n=1,\n",
        "            stop=None,\n",
        "            seed=0,\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        new_msg_history = new_msg_history + [{\"role\": \"assistant\", \"content\": content}]\n",
        "    elif model in [\"o1-preview-2024-09-12\", \"o1-mini-2024-09-12\"]:\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": system_message},\n",
        "                *new_msg_history,\n",
        "            ],\n",
        "            temperature=1,\n",
        "            max_completion_tokens=MAX_NUM_TOKENS,\n",
        "            n=1,\n",
        "            seed=0,\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        new_msg_history = new_msg_history + [{\"role\": \"assistant\", \"content\": content}]\n",
        "    elif model in [\"meta-llama/llama-3.1-405b-instruct\", \"llama-3-1-405b-instruct\"]:\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"meta-llama/llama-3.1-405b-instruct\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                *new_msg_history,\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=MAX_NUM_TOKENS,\n",
        "            n=1,\n",
        "            stop=None,\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        new_msg_history = new_msg_history + [{\"role\": \"assistant\", \"content\": content}]\n",
        "    elif model in [\"deepseek-chat\", \"deepseek-coder\"]:\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                *new_msg_history,\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=MAX_NUM_TOKENS,\n",
        "            n=1,\n",
        "            stop=None,\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        new_msg_history = new_msg_history + [{\"role\": \"assistant\", \"content\": content}]\n",
        "    elif model in [\"deepseek-reasoner\"]:\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                *new_msg_history,\n",
        "            ],\n",
        "            n=1,\n",
        "            stop=None,\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        new_msg_history = new_msg_history + [{\"role\": \"assistant\", \"content\": content}]\n",
        "    elif \"gemini\" in model:\n",
        "        new_msg_history = msg_history + [{\"role\": \"user\", \"content\": msg}]\n",
        "        gemini_contents = [{\"role\": \"system\", \"parts\": system_message}]\n",
        "        for m in new_msg_history:\n",
        "            gemini_contents.append({\"role\": m[\"role\"], \"parts\": m[\"content\"]})\n",
        "        response = client.generate_content(\n",
        "            contents=gemini_contents,\n",
        "            generation_config=GenerationConfig(\n",
        "                temperature=temperature,\n",
        "                max_output_tokens=MAX_NUM_TOKENS,\n",
        "                candidate_count=1,\n",
        "            ),\n",
        "        )\n",
        "        content = response.text\n",
        "        new_msg_history = new_msg_history + [{\"role\": \"assistant\", \"content\": content}]\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model} not supported.\")\n",
        "\n",
        "    if print_debug:\n",
        "        print()\n",
        "        print(\"*\" * 20 + \" LLM START \" + \"*\" * 20)\n",
        "        for j, msg in enumerate(new_msg_history):\n",
        "            print(f'{j}, {msg[\"role\"]}: {msg[\"content\"]}')\n",
        "        print(content)\n",
        "        print(\"*\" * 21 + \" LLM END \" + \"*\" * 21)\n",
        "        print()\n",
        "\n",
        "    return content, new_msg_history\n",
        "\n",
        "\n",
        "def extract_json_between_markers(llm_output):\n",
        "    # Regular expression pattern to find JSON content between ```json and ```\n",
        "    json_pattern = r\"```json(.*?)```\"\n",
        "    matches = re.findall(json_pattern, llm_output, re.DOTALL)\n",
        "\n",
        "    if not matches:\n",
        "        # Fallback: Try to find any JSON-like content in the output\n",
        "        json_pattern = r\"\\{.*?\\}\"\n",
        "        matches = re.findall(json_pattern, llm_output, re.DOTALL)\n",
        "\n",
        "    for json_string in matches:\n",
        "        json_string = json_string.strip()\n",
        "        try:\n",
        "            parsed_json = json.loads(json_string)\n",
        "            return parsed_json\n",
        "        except json.JSONDecodeError:\n",
        "            # Attempt to fix common JSON issues\n",
        "            try:\n",
        "                # Remove invalid control characters\n",
        "                json_string_clean = re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", json_string)\n",
        "                parsed_json = json.loads(json_string_clean)\n",
        "                return parsed_json\n",
        "            except json.JSONDecodeError:\n",
        "                continue  # Try next match\n",
        "\n",
        "    return None  # No valid JSON found\n",
        "\n",
        "\n",
        "def create_client(model):\n",
        "    if model.startswith(\"claude-\"):\n",
        "        print(f\"Using Anthropic API with model {model}.\")\n",
        "        return anthropic.Anthropic(), model\n",
        "    elif model.startswith(\"bedrock\") and \"claude\" in model:\n",
        "        client_model = model.split(\"/\")[-1]\n",
        "        print(f\"Using Amazon Bedrock with model {client_model}.\")\n",
        "        return anthropic.AnthropicBedrock(), client_model\n",
        "    elif model.startswith(\"vertex_ai\") and \"claude\" in model:\n",
        "        client_model = model.split(\"/\")[-1]\n",
        "        print(f\"Using Vertex AI with model {client_model}.\")\n",
        "        return anthropic.AnthropicVertex(), client_model\n",
        "    elif 'gpt' in model:\n",
        "        print(f\"Using OpenAI API with model {model}.\")\n",
        "        return openai.OpenAI(), model\n",
        "    elif model in [\"o1-preview-2024-09-12\", \"o1-mini-2024-09-12\"]:\n",
        "        print(f\"Using OpenAI API with model {model}.\")\n",
        "        return openai.OpenAI(), model\n",
        "    elif model in [\"deepseek-chat\", \"deepseek-reasoner\"]:\n",
        "        print(f\"Using OpenAI API with {model}.\")\n",
        "        return openai.OpenAI(\n",
        "            api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
        "            base_url=\"https://api.deepseek.com\"\n",
        "        ), model\n",
        "    elif model == \"llama3.1-405b\":\n",
        "        print(f\"Using OpenAI API with {model}.\")\n",
        "        return openai.OpenAI(\n",
        "            api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "            base_url=\"https://openrouter.ai/api/v1\"\n",
        "        ), \"meta-llama/llama-3.1-405b-instruct\"\n",
        "    elif \"gemini\" in model:\n",
        "        print(f\"Using Google Generative AI with model {model}.\")\n",
        "        genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "        client = genai.GenerativeModel(model)\n",
        "        return client, model\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model} not supported.\")"
      ],
      "metadata": {
        "id": "4_qA7wvPKnge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aHIitkjeNGEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform_writeup\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import os.path as osp\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "from ai_scientist.generate_ideas import search_for_papers\n",
        "from ai_scientist.llm import get_response_from_llm, extract_json_between_markers, create_client, AVAILABLE_LLMS\n",
        "\n",
        "\n",
        "# GENERATE LATEX\n",
        "def generate_latex(coder, folder_name, pdf_file, timeout=30, num_error_corrections=5):\n",
        "    folder = osp.abspath(folder_name)\n",
        "    cwd = osp.join(folder, \"latex\")  # Fixed potential issue with path\n",
        "    writeup_file = osp.join(cwd, \"template.tex\")\n",
        "\n",
        "    # Check all references are valid and in the references.bib file\n",
        "    with open(writeup_file, \"r\") as f:\n",
        "        tex_text = f.read()\n",
        "    cites = re.findall(r\"\\\\cite[a-z]*{([^}]*)}\", tex_text)\n",
        "    references_bib = re.search(\n",
        "        r\"\\\\begin{filecontents}{references.bib}(.*?)\\\\end{filecontents}\",\n",
        "        tex_text,\n",
        "        re.DOTALL,\n",
        "    )\n",
        "    if references_bib is None:\n",
        "        print(\"No references.bib found in template.tex\")\n",
        "        return\n",
        "    bib_text = references_bib.group(1)\n",
        "    cites = [cite.strip() for item in cites for cite in item.split(\",\")]\n",
        "    for cite in cites:\n",
        "        if cite not in bib_text:\n",
        "            print(f\"Reference {cite} not found in references.\")\n",
        "            prompt = f\"\"\"Reference {cite} not found in references.bib. Is this included under a different name?\n",
        "If so, please modify the citation in template.tex to match the name in references.bib at the top. Otherwise, remove the cite.\"\"\"\n",
        "            coder.run(prompt)\n",
        "\n",
        "    # Check all included figures are actually in the directory.\n",
        "    with open(writeup_file, \"r\") as f:\n",
        "        tex_text = f.read()\n",
        "    referenced_figs = re.findall(r\"\\\\includegraphics.*?{(.*?)}\", tex_text)\n",
        "    all_figs = [f for f in os.listdir(folder) if f.endswith(\".png\")]\n",
        "    for figure in referenced_figs:\n",
        "        if figure not in all_figs:\n",
        "            print(f\"Figure {figure} not found in directory.\")\n",
        "            prompt = f\"\"\"The image {figure} not found in the directory. The images in the directory are: {all_figs}.\n",
        "Please ensure that the figure is in the directory and that the filename is correct. Check the notes to see what each figure contains.\"\"\"\n",
        "            coder.run(prompt)\n",
        "\n",
        "    # Remove duplicate figures.\n",
        "    with open(writeup_file, \"r\") as f:\n",
        "        tex_text = f.read()\n",
        "    referenced_figs = re.findall(r\"\\\\includegraphics.*?{(.*?)}\", tex_text)\n",
        "    duplicates = {x for x in referenced_figs if referenced_figs.count(x) > 1}\n",
        "    if duplicates:\n",
        "        for dup in duplicates:\n",
        "            print(f\"Duplicate figure found: {dup}.\")\n",
        "            prompt = f\"\"\"Duplicate figures found: {dup}. Ensure any figure is only included once.\n",
        "If duplicated, identify the best location for the figure and remove any other.\"\"\"\n",
        "            coder.run(prompt)\n",
        "\n",
        "    # Remove duplicate section headers.\n",
        "    with open(writeup_file, \"r\") as f:\n",
        "        tex_text = f.read()\n",
        "    sections = re.findall(r\"\\\\section{([^}]*)}\", tex_text)\n",
        "    duplicates = {x for x in sections if sections.count(x) > 1}\n",
        "    if duplicates:\n",
        "        for dup in duplicates:\n",
        "            print(f\"Duplicate section header found: {dup}\")\n",
        "            prompt = f\"\"\"Duplicate section header found: {dup}. Ensure any section header is declared once.\n",
        "If duplicated, identify the best location for the section header and remove any other.\"\"\"\n",
        "            coder.run(prompt)\n",
        "\n",
        "    # Iteratively fix any LaTeX bugs\n",
        "    for i in range(num_error_corrections):\n",
        "        # Filter trivial bugs in chktex\n",
        "        check_output = os.popen(f\"chktex {writeup_file} -q -n2 -n24 -n13 -n1\").read()\n",
        "        if check_output:\n",
        "            prompt = f\"\"\"Please fix the following LaTeX errors in `template.tex` guided by the output of `chktek`:\n",
        "{check_output}.\n",
        "\n",
        "Make the minimal fix required and do not remove or change any packages.\n",
        "Pay attention to any accidental uses of HTML syntax, e.g. </end instead of \\\\end.\n",
        "\"\"\"\n",
        "            coder.run(prompt)\n",
        "        else:\n",
        "            break\n",
        "    compile_latex(cwd, pdf_file, timeout=timeout)\n",
        "\n",
        "\n",
        "def compile_latex(cwd, pdf_file, timeout=30):\n",
        "    print(\"GENERATING LATEX\")\n",
        "\n",
        "    commands = [\n",
        "        [\"pdflatex\", \"-interaction=nonstopmode\", \"template.tex\"],\n",
        "        [\"bibtex\", \"template\"],\n",
        "        [\"pdflatex\", \"-interaction=nonstopmode\", \"template.tex\"],\n",
        "        [\"pdflatex\", \"-interaction=nonstopmode\", \"template.tex\"],\n",
        "    ]\n",
        "\n",
        "    for command in commands:\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                cwd=cwd,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                text=True,\n",
        "                timeout=timeout,\n",
        "            )\n",
        "            print(\"Standard Output:\\n\", result.stdout)\n",
        "            print(\"Standard Error:\\n\", result.stderr)\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"Latex timed out after {timeout} seconds\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error running command {' '.join(command)}: {e}\")\n",
        "\n",
        "    print(\"FINISHED GENERATING LATEX\")\n",
        "\n",
        "    # Attempt to move the PDF to the desired location\n",
        "    try:\n",
        "        shutil.move(osp.join(cwd, \"template.pdf\"), pdf_file)\n",
        "    except FileNotFoundError:\n",
        "        print(\"Failed to rename PDF.\")\n",
        "\n",
        "\n",
        "per_section_tips = {\n",
        "    \"Abstract\": \"\"\"\n",
        "- TL;DR of the paper\n",
        "- What are we trying to do and why is it relevant?\n",
        "- Why is this hard?\n",
        "- How do we solve it (i.e. our contribution!)\n",
        "- How do we verify that we solved it (e.g. Experiments and results)\n",
        "\n",
        "Please make sure the abstract reads smoothly and is well-motivated. This should be one continuous paragraph with no breaks between the lines.\n",
        "\"\"\",\n",
        "    \"Introduction\": \"\"\"\n",
        "- Longer version of the Abstract, i.e. of the entire paper\n",
        "- What are we trying to do and why is it relevant?\n",
        "- Why is this hard?\n",
        "- How do we solve it (i.e. our contribution!)\n",
        "- How do we verify that we solved it (e.g. Experiments and results)\n",
        "- New trend: specifically list your contributions as bullet points\n",
        "- Extra space? Future work!\n",
        "\"\"\",\n",
        "    \"Related Work\": \"\"\"\n",
        "- Academic siblings of our work, i.e. alternative attempts in literature at trying to solve the same problem.\n",
        "- Goal is to “Compare and contrast” - how does their approach differ in either assumptions or method? If their method is applicable to our Problem Setting I expect a comparison in the experimental section. If not, there needs to be a clear statement why a given method is not applicable.\n",
        "- Note: Just describing what another paper is doing is not enough. We need to compare and contrast.\n",
        "\"\"\",\n",
        "    \"Background\": \"\"\"\n",
        "- Academic Ancestors of our work, i.e. all concepts and prior work that are required for understanding our method.\n",
        "- Usually includes a subsection, Problem Setting, which formally introduces the problem setting and notation (Formalism) for our method. Highlights any specific assumptions that are made that are unusual.\n",
        "- Note: If our paper introduces a novel problem setting as part of its contributions, it's best to have a separate Section.\n",
        "\"\"\",\n",
        "    \"Method\": \"\"\"\n",
        "- What we do. Why we do it. All described using the general Formalism introduced in the Problem Setting and building on top of the concepts / foundations introduced in Background.\n",
        "\"\"\",\n",
        "    \"Experimental Setup\": \"\"\"\n",
        "- How do we test that our stuff works? Introduces a specific instantiation of the Problem Setting and specific implementation details of our Method for this Problem Setting.\n",
        "- Do not imagine unknown hardware details.\n",
        "- Includes a description of the dataset, evaluation metrics, important hyperparameters, and implementation details.\n",
        "\"\"\",\n",
        "    \"Results\": \"\"\"\n",
        "- Shows the results of running Method on our problem described in Experimental Setup.\n",
        "- Includes statements on hyperparameters and other potential issues of fairness.\n",
        "- Only includes results that have actually been run and saved in the logs. Do not hallucinate results that don't exist.\n",
        "- If results exist: compares to baselines and includes statistics and confidence intervals.\n",
        "- If results exist: includes ablation studies to show that specific parts of the method are relevant.\n",
        "- Discusses limitations of the method.\n",
        "- Make sure to include all the results from the experiments, and include all relevant figures.\n",
        "\"\"\",\n",
        "    \"Conclusion\": \"\"\"\n",
        "- Brief recap of the entire paper.\n",
        "- To keep going with the analogy, you can think of future work as (potential) academic offspring.\n",
        "\"\"\",\n",
        "}\n",
        "\n",
        "error_list = \"\"\"- Unenclosed math symbols\n",
        "- Only reference figures that exist in our directory\n",
        "- LaTeX syntax errors\n",
        "- Numerical results that do not come from explicit experiments and logs\n",
        "- Repeatedly defined figure labels\n",
        "- References to papers that are not in the .bib file, DO NOT ADD ANY NEW CITATIONS!\n",
        "- Unnecessary verbosity or repetition, unclear text\n",
        "- Results or insights in the `notes.txt` that have not yet need included\n",
        "- Any relevant figures that have not yet been included in the text\n",
        "- Closing any \\\\begin{{figure}} with a \\\\end{{figure}} and \\\\begin{{table}} with a \\\\end{{table}}, etc.\n",
        "- Duplicate headers, e.g. duplicated \\\\section{{Introduction}} or \\\\end{{document}}\n",
        "- Unescaped symbols, e.g. shakespeare_char should be shakespeare\\\\_char in text\n",
        "- Incorrect closing of environments, e.g. </end{{figure}}> instead of \\\\end{{figure}}\n",
        "\"\"\"\n",
        "\n",
        "refinement_prompt = (\n",
        "    \"\"\"Great job! Now criticize and refine only the {section} that you just wrote.\n",
        "Make this complete in this pass, do not leave any placeholders.\n",
        "\n",
        "Pay particular attention to fixing any errors such as:\n",
        "\"\"\"\n",
        "    + error_list\n",
        ")\n",
        "\n",
        "second_refinement_prompt = (\n",
        "    \"\"\"Criticize and refine the {section} only. Recall the advice:\n",
        "{tips}\n",
        "Make this complete in this pass, do not leave any placeholders.\n",
        "\n",
        "Pay attention to how it fits in with the rest of the paper.\n",
        "Identify any redundancies (e.g. repeated figures or repeated text), if there are any, decide where in the paper things should be cut.\n",
        "Identify where we can save space, and be more concise without weakening the message of the text.\n",
        "Fix any remaining errors as before:\n",
        "\"\"\"\n",
        "    + error_list\n",
        ")\n",
        "\n",
        "# CITATION HELPERS\n",
        "citation_system_msg = \"\"\"You are an ambitious AI PhD student who is looking to publish a paper that will contribute significantly to the field.\n",
        "You have already written an initial draft of the paper and now you are looking to add missing citations to related papers throughout the paper.\n",
        "The related work section already has some initial comments on which papers to add and discuss.\n",
        "\n",
        "Focus on completing the existing write-up and do not add entirely new elements unless necessary.\n",
        "Ensure every point in the paper is substantiated with sufficient evidence.\n",
        "Feel free to add more cites to a particular point if there is only one or two references.\n",
        "Ensure no paper is cited without a corresponding reference in the `references.bib` file.\n",
        "Ensure each paragraph of the related work has sufficient background, e.g. a few papers cited.\n",
        "You will be given access to the Semantic Scholar API, only add citations that you have found using the API.\n",
        "Aim to discuss a broad range of relevant papers, not just the most popular ones.\n",
        "Make sure not to copy verbatim from prior literature to avoid plagiarism.\n",
        "\n",
        "You will be prompted to give a precise description of where and how to add the cite, and a search query for the paper to be cited.\n",
        "Finally, you will select the most relevant cite from the search results (top 10 results will be shown).\n",
        "You will have {total_rounds} rounds to add to the references, but do not need to use them all.\n",
        "\n",
        "DO NOT ADD A CITATION THAT ALREADY EXISTS!\"\"\"\n",
        "\n",
        "citation_first_prompt = '''Round {current_round}/{total_rounds}:\n",
        "\n",
        "You have written this LaTeX draft so far:\n",
        "\n",
        "\"\"\"\n",
        "{draft}\n",
        "\"\"\"\n",
        "\n",
        "Identify the most important citation that you still need to add, and the query to find the paper.\n",
        "\n",
        "Respond in the following format:\n",
        "\n",
        "THOUGHT:\n",
        "<THOUGHT>\n",
        "\n",
        "RESPONSE:\n",
        "```json\n",
        "<JSON>\n",
        "```\n",
        "\n",
        "In <THOUGHT>, first briefly reason over the paper and identify where citations should be added.\n",
        "If no more citations are needed, add \"No more citations needed\" to your thoughts.\n",
        "Do not add \"No more citations needed\" if you are adding citations this round.\n",
        "\n",
        "In <JSON>, respond in JSON format with the following fields:\n",
        "- \"Description\": A precise description of the required edit, along with the proposed text and location where it should be made.\n",
        "- \"Query\": The search query to find the paper (e.g. attention is all you need).\n",
        "\n",
        "Ensure the description is sufficient to make the change without further context. Someone else will make the change.\n",
        "The query will work best if you are able to recall the exact name of the paper you are looking for, or the authors.\n",
        "This JSON will be automatically parsed, so ensure the format is precise.'''\n",
        "\n",
        "citation_second_prompt = \"\"\"Search has recovered the following articles:\n",
        "\n",
        "{papers}\n",
        "\n",
        "Respond in the following format:\n",
        "\n",
        "THOUGHT:\n",
        "<THOUGHT>\n",
        "\n",
        "RESPONSE:\n",
        "```json\n",
        "<JSON>\n",
        "```\n",
        "\n",
        "In <THOUGHT>, first briefly reason over the search results and identify which citation best fits your paper and the location is to be added at.\n",
        "If none are appropriate, add \"Do not add any\" to your thoughts.\n",
        "\n",
        "In <JSON>, respond in JSON format with the following fields:\n",
        "- \"Selected\": A list of the indices of the selected papers to be cited, e.g. \"[0, 1]\". Can be \"[]\" if no papers are selected. This must be a string.\n",
        "- \"Description\": Update the previous description of the required edit if needed. Ensure that any cites precisely match the name in the bibtex!!!\n",
        "\n",
        "Do not select papers that are already in the `references.bib` file at the top of the draft, or if the same citation exists under a different name.\n",
        "This JSON will be automatically parsed, so ensure the format is precise.\"\"\"\n",
        "\n",
        "\n",
        "def get_citation_aider_prompt(\n",
        "        client, model, draft, current_round, total_rounds, engine=\"semanticscholar\"\n",
        ") -> Tuple[Optional[str], bool]:\n",
        "    msg_history = []\n",
        "    try:\n",
        "        text, msg_history = get_response_from_llm(\n",
        "            citation_first_prompt.format(\n",
        "                draft=draft, current_round=current_round, total_rounds=total_rounds\n",
        "            ),\n",
        "            client=client,\n",
        "            model=model,\n",
        "            system_message=citation_system_msg.format(total_rounds=total_rounds),\n",
        "            msg_history=msg_history,\n",
        "        )\n",
        "        if \"No more citations needed\" in text:\n",
        "            print(\"No more citations needed.\")\n",
        "            return None, True\n",
        "\n",
        "        ## PARSE OUTPUT\n",
        "        json_output = extract_json_between_markers(text)\n",
        "        assert json_output is not None, \"Failed to extract JSON from LLM output\"\n",
        "        query = json_output[\"Query\"]\n",
        "        papers = search_for_papers(query, engine=engine)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, False\n",
        "\n",
        "    if papers is None:\n",
        "        print(\"No papers found.\")\n",
        "        return None, False\n",
        "\n",
        "    paper_strings = []\n",
        "    for i, paper in enumerate(papers):\n",
        "        paper_strings.append(\n",
        "            \"\"\"{i}: {title}. {authors}. {venue}, {year}.\\nAbstract: {abstract}\"\"\".format(\n",
        "                i=i,\n",
        "                title=paper[\"title\"],\n",
        "                authors=paper[\"authors\"],\n",
        "                venue=paper[\"venue\"],\n",
        "                year=paper[\"year\"],\n",
        "                abstract=paper[\"abstract\"],\n",
        "            )\n",
        "        )\n",
        "    papers_str = \"\\n\\n\".join(paper_strings)\n",
        "\n",
        "    try:\n",
        "        text, msg_history = get_response_from_llm(\n",
        "            citation_second_prompt.format(\n",
        "                papers=papers_str,\n",
        "                current_round=current_round,\n",
        "                total_rounds=total_rounds,\n",
        "            ),\n",
        "            client=client,\n",
        "            model=model,\n",
        "            system_message=citation_system_msg.format(total_rounds=total_rounds),\n",
        "            msg_history=msg_history,\n",
        "        )\n",
        "        if \"Do not add any\" in text:\n",
        "            print(\"Do not add any.\")\n",
        "            return None, False\n",
        "        ## PARSE OUTPUT\n",
        "        json_output = extract_json_between_markers(text)\n",
        "        assert json_output is not None, \"Failed to extract JSON from LLM output\"\n",
        "        desc = json_output[\"Description\"]\n",
        "        selected_papers = json_output[\"Selected\"]\n",
        "        selected_papers = str(selected_papers)\n",
        "\n",
        "        # convert to list\n",
        "        if selected_papers != \"[]\":\n",
        "            selected_papers = list(map(int, selected_papers.strip(\"[]\").split(\",\")))\n",
        "            assert all(\n",
        "                [0 <= i < len(papers) for i in selected_papers]\n",
        "            ), \"Invalid paper index\"\n",
        "            bibtexs = [papers[i][\"citationStyles\"][\"bibtex\"] for i in selected_papers]\n",
        "            bibtex_string = \"\\n\".join(bibtexs)\n",
        "        else:\n",
        "            return None, False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, False\n",
        "\n",
        "    # Add citation to draft\n",
        "    aider_format = '''The following citations have just been added to the end of the `references.bib` file definition at the top of the file:\n",
        "\"\"\"\n",
        "{bibtex}\n",
        "\"\"\"\n",
        "You do not need to add them yourself.\n",
        "ABSOLUTELY DO NOT ADD IT AGAIN!!!\n",
        "\n",
        "Make the proposed change to the draft incorporating these new cites:\n",
        "{description}\n",
        "\n",
        "Use your judgment for whether these should be cited anywhere else.\n",
        "Make sure that any citation precisely matches the name in `references.bib`. Change its name to the correct name in the bibtex if needed.\n",
        "Ensure the citation is well-integrated into the text.'''\n",
        "\n",
        "    aider_prompt = (\n",
        "            aider_format.format(bibtex=bibtex_string, description=desc)\n",
        "            + \"\"\"\\n You must use \\cite or \\citet to reference papers, do not manually type out author names.\"\"\"\n",
        "    )\n",
        "    return aider_prompt, False\n",
        "\n",
        "\n",
        "# PERFORM WRITEUP\n",
        "def perform_writeup(\n",
        "        idea, folder_name, coder, cite_client, cite_model, num_cite_rounds=20, engine=\"semanticscholar\"\n",
        "):\n",
        "    # CURRENTLY ASSUMES LATEX\n",
        "    abstract_prompt = f\"\"\"We've provided the `latex/template.tex` file to the project. We will be filling it in section by section.\n",
        "\n",
        "First, please fill in the \"Title\" and \"Abstract\" sections of the writeup.\n",
        "\n",
        "Some tips are provided below:\n",
        "{per_section_tips[\"Abstract\"]}\n",
        "\n",
        "Before every paragraph, please include a brief description of what you plan to write in that paragraph in a comment.\n",
        "\n",
        "Be sure to first name the file and use *SEARCH/REPLACE* blocks to perform these edits.\n",
        "\"\"\"\n",
        "    coder_out = coder.run(abstract_prompt)\n",
        "    coder_out = coder.run(\n",
        "        refinement_prompt.format(section=\"Abstract\")\n",
        "        .replace(r\"{{\", \"{\")\n",
        "        .replace(r\"}}\", \"}\")\n",
        "    )\n",
        "    for section in [\n",
        "        \"Introduction\",\n",
        "        \"Background\",\n",
        "        \"Method\",\n",
        "        \"Experimental Setup\",\n",
        "        \"Results\",\n",
        "        \"Conclusion\",\n",
        "    ]:\n",
        "        section_prompt = f\"\"\"Please fill in the {section} of the writeup. Some tips are provided below:\n",
        "{per_section_tips[section]}\n",
        "\n",
        "Be sure to use \\cite or \\citet where relevant, referring to the works provided in the file.\n",
        "Do not cite anything that is not already in `references.bib`. Do not add any new entries to this.\n",
        "\n",
        "Keep the experimental results (figures and tables) only in the Results section, and make sure that any captions are filled in.\n",
        "In this pass, do not reference anything in later sections of the paper.\n",
        "\n",
        "Before every paragraph, please include a brief description of what you plan to write in that paragraph in a comment.\n",
        "\n",
        "Be sure to first name the file and use *SEARCH/REPLACE* blocks to perform these edits.\n",
        "\"\"\"\n",
        "        coder_out = coder.run(section_prompt)\n",
        "        coder_out = coder.run(\n",
        "            refinement_prompt.format(section=section)\n",
        "            .replace(r\"{{\", \"{\")\n",
        "            .replace(r\"}}\", \"}\")\n",
        "        )\n",
        "\n",
        "    # SKETCH THE RELATED WORK\n",
        "    section_prompt = f\"\"\"Please fill in the Related Work of the writeup. Some tips are provided below:\n",
        "\n",
        "{per_section_tips[\"Related Work\"]}\n",
        "\n",
        "For this section, very briefly sketch out the structure of the section, and clearly indicate what papers you intend to include.\n",
        "Do this all in LaTeX comments using %.\n",
        "The related work should be concise, only plan to discuss the most relevant work.\n",
        "Do not modify `references.bib` to add any new citations, this will be filled in at a later stage.\n",
        "\n",
        "Be sure to first name the file and use *SEARCH/REPLACE* blocks to perform these edits.\n",
        "\"\"\"\n",
        "    coder_out = coder.run(section_prompt)\n",
        "\n",
        "    # Fill paper with cites.\n",
        "    for _ in range(num_cite_rounds):\n",
        "        with open(osp.join(folder_name, \"latex\", \"template.tex\"), \"r\") as f:\n",
        "            draft = f.read()\n",
        "        prompt, done = get_citation_aider_prompt(\n",
        "            cite_client, cite_model, draft, _, num_cite_rounds, engine=engine\n",
        "        )\n",
        "        if done:\n",
        "            break\n",
        "        if prompt is not None:\n",
        "            # extract bibtex string\n",
        "            bibtex_string = prompt.split('\"\"\"')[1]\n",
        "            # insert this into draft before the \"\\end{filecontents}\" line\n",
        "            search_str = r\"\\end{filecontents}\"\n",
        "            draft = draft.replace(search_str, f\"{bibtex_string}{search_str}\")\n",
        "            with open(osp.join(folder_name, \"latex\", \"template.tex\"), \"w\") as f:\n",
        "                f.write(draft)\n",
        "            coder_out = coder.run(prompt)\n",
        "\n",
        "    coder_out = coder.run(\n",
        "        refinement_prompt.format(section=\"Related Work\")\n",
        "        .replace(r\"{{\", \"{\")\n",
        "        .replace(r\"}}\", \"}\")\n",
        "    )\n",
        "\n",
        "    ## SECOND REFINEMENT LOOP\n",
        "    coder.run(\n",
        "        \"\"\"Great job! Now that there is a complete draft of the entire paper, let's refine each section again.\n",
        "First, re-think the Title if necessary. Keep this concise and descriptive of the paper's concept, but try by creative with it.\"\"\"\n",
        "    )\n",
        "    for section in [\n",
        "        \"Abstract\",\n",
        "        \"Related Work\",\n",
        "        \"Introduction\",\n",
        "        \"Background\",\n",
        "        \"Method\",\n",
        "        \"Experimental Setup\",\n",
        "        \"Results\",\n",
        "        \"Conclusion\",\n",
        "    ]:\n",
        "        coder_out = coder.run(\n",
        "            second_refinement_prompt.format(\n",
        "                section=section, tips=per_section_tips[section]\n",
        "            )\n",
        "            .replace(r\"{{\", \"{\")\n",
        "            .replace(r\"}}\", \"}\")\n",
        "        )\n",
        "\n",
        "    generate_latex(coder, folder_name, f\"{folder_name}/{idea['Name']}.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from aider.coders import Coder\n",
        "    from aider.models import Model\n",
        "    from aider.io import InputOutput\n",
        "    import json\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Perform writeup for a project\")\n",
        "    parser.add_argument(\"--folder\", type=str)\n",
        "    parser.add_argument(\"--no-writing\", action=\"store_true\", help=\"Only generate\")\n",
        "    parser.add_argument(\n",
        "        \"--model\",\n",
        "        type=str,\n",
        "        default=\"gpt-4o-2024-05-13\",\n",
        "        choices=AVAILABLE_LLMS,\n",
        "        help=\"Model to use for AI Scientist.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--engine\",\n",
        "        type=str,\n",
        "        default=\"semanticscholar\",\n",
        "        choices=[\"semanticscholar\", \"openalex\"],\n",
        "        help=\"Scholar engine to use.\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "    client, client_model = create_client(args.model)\n",
        "    print(\"Make sure you cleaned the Aider logs if re-generating the writeup!\")\n",
        "    folder_name = args.folder\n",
        "    idea_name = osp.basename(folder_name)\n",
        "    exp_file = osp.join(folder_name, \"experiment.py\")\n",
        "    vis_file = osp.join(folder_name, \"plot.py\")\n",
        "    notes = osp.join(folder_name, \"notes.txt\")\n",
        "    model = args.model\n",
        "    writeup_file = osp.join(folder_name, \"latex\", \"template.tex\")\n",
        "    ideas_file = osp.join(folder_name, \"ideas.json\")\n",
        "    with open(ideas_file, \"r\") as f:\n",
        "        ideas = json.load(f)\n",
        "    for idea in ideas:\n",
        "        if idea[\"Name\"] in idea_name:\n",
        "            print(f\"Found idea: {idea['Name']}\")\n",
        "            break\n",
        "    if idea[\"Name\"] not in idea_name:\n",
        "        raise ValueError(f\"Idea {idea_name} not found\")\n",
        "    fnames = [exp_file, writeup_file, notes]\n",
        "    io = InputOutput(yes=True, chat_history_file=f\"{folder_name}/{idea_name}_aider.txt\")\n",
        "    if args.model == \"deepseek-coder-v2-0724\":\n",
        "        main_model = Model(\"deepseek/deepseek-coder\")\n",
        "    elif args.model == \"llama3.1-405b\":\n",
        "        main_model = Model(\"openrouter/meta-llama/llama-3.1-405b-instruct\")\n",
        "    else:\n",
        "        main_model = Model(model)\n",
        "    coder = Coder.create(\n",
        "        main_model=main_model,\n",
        "        fnames=fnames,\n",
        "        io=io,\n",
        "        stream=False,\n",
        "        use_git=False,\n",
        "        edit_format=\"diff\",\n",
        "    )\n",
        "    if args.no_writing:\n",
        "        generate_latex(coder, args.folder, f\"{args.folder}/test.pdf\")\n",
        "    else:\n",
        "        try:\n",
        "            perform_writeup(idea, folder_name, coder, client, client_model, engine=args.engine)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to perform writeup: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "LbTE1e2LNFbV",
        "outputId": "85c15a3f-e94c-4f48-c2d9-c7837c15d8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'aider'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-17ff1b30d90e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0maider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0maider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0maider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aider'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform_review.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from pypdf import PdfReader\n",
        "import pymupdf\n",
        "import pymupdf4llm\n",
        "from ai_scientist.llm import (\n",
        "    get_response_from_llm,\n",
        "    get_batch_responses_from_llm,\n",
        "    extract_json_between_markers,\n",
        ")\n",
        "\n",
        "reviewer_system_prompt_base = (\n",
        "    \"You are an AI researcher who is reviewing a paper that was submitted to a prestigious ML venue.\"\n",
        "    \"Be critical and cautious in your decision.\"\n",
        ")\n",
        "\n",
        "reviewer_system_prompt_neg = (\n",
        "    reviewer_system_prompt_base\n",
        "    + \"If a paper is bad or you are unsure, give it bad scores and reject it.\"\n",
        ")\n",
        "reviewer_system_prompt_pos = (\n",
        "    reviewer_system_prompt_base\n",
        "    + \"If a paper is good or you are unsure, give it good scores and accept it.\"\n",
        ")\n",
        "\n",
        "template_instructions = \"\"\"\n",
        "Respond in the following format:\n",
        "\n",
        "THOUGHT:\n",
        "<THOUGHT>\n",
        "\n",
        "REVIEW JSON:\n",
        "```json\n",
        "<JSON>\n",
        "```\n",
        "\n",
        "In <THOUGHT>, first briefly discuss your intuitions and reasoning for the evaluation.\n",
        "Detail your high-level arguments, necessary choices and desired outcomes of the review.\n",
        "Do not make generic comments here, but be specific to your current paper.\n",
        "Treat this as the note-taking phase of your review.\n",
        "\n",
        "In <JSON>, provide the review in JSON format with the following fields in the order:\n",
        "- \"Summary\": A summary of the paper content and its contributions.\n",
        "- \"Strengths\": A list of strengths of the paper.\n",
        "- \"Weaknesses\": A list of weaknesses of the paper.\n",
        "- \"Originality\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Quality\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Clarity\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Significance\": A rating from 1 to 4 (low, medium, high, very high).\n",
        "- \"Questions\": A set of clarifying questions to be answered by the paper authors.\n",
        "- \"Limitations\": A set of limitations and potential negative societal impacts of the work.\n",
        "- \"Ethical Concerns\": A boolean value indicating whether there are ethical concerns.\n",
        "- \"Soundness\": A rating from 1 to 4 (poor, fair, good, excellent).\n",
        "- \"Presentation\": A rating from 1 to 4 (poor, fair, good, excellent).\n",
        "- \"Contribution\": A rating from 1 to 4 (poor, fair, good, excellent).\n",
        "- \"Overall\": A rating from 1 to 10 (very strong reject to award quality).\n",
        "- \"Confidence\": A rating from 1 to 5 (low, medium, high, very high, absolute).\n",
        "- \"Decision\": A decision that has to be one of the following: Accept, Reject.\n",
        "\n",
        "For the \"Decision\" field, don't use Weak Accept, Borderline Accept, Borderline Reject, or Strong Reject. Instead, only use Accept or Reject.\n",
        "This JSON will be automatically parsed, so ensure the format is precise.\n",
        "\"\"\"\n",
        "\n",
        "neurips_form = (\n",
        "    \"\"\"\n",
        "## Review Form\n",
        "Below is a description of the questions you will be asked on the review form for each paper and some guidelines on what to consider when answering these questions.\n",
        "When writing your review, please keep in mind that after decisions have been made, reviews and meta-reviews of accepted papers and opted-in rejected papers will be made public.\n",
        "\n",
        "1. Summary: Briefly summarize the paper and its contributions. This is not the place to critique the paper; the authors should generally agree with a well-written summary.\n",
        "  - Strengths and Weaknesses: Please provide a thorough assessment of the strengths and weaknesses of the paper, touching on each of the following dimensions:\n",
        "  - Originality: Are the tasks or methods new? Is the work a novel combination of well-known techniques? (This can be valuable!) Is it clear how this work differs from previous contributions? Is related work adequately cited\n",
        "  - Quality: Is the submission technically sound? Are claims well supported (e.g., by theoretical analysis or experimental results)? Are the methods used appropriate? Is this a complete piece of work or work in progress? Are the authors careful and honest about evaluating both the strengths and weaknesses of their work\n",
        "  - Clarity: Is the submission clearly written? Is it well organized? (If not, please make constructive suggestions for improving its clarity.) Does it adequately inform the reader? (Note that a superbly written paper provides enough information for an expert reader to reproduce its results.)\n",
        "  - Significance: Are the results important? Are others (researchers or practitioners) likely to use the ideas or build on them? Does the submission address a difficult task in a better way than previous work? Does it advance the state of the art in a demonstrable way? Does it provide unique data, unique conclusions about existing data, or a unique theoretical or experimental approach?\n",
        "\n",
        "2. Questions: Please list up and carefully describe any questions and suggestions for the authors. Think of the things where a response from the author can change your opinion, clarify a confusion or address a limitation. This can be very important for a productive rebuttal and discussion phase with the authors.\n",
        "\n",
        "3. Limitations: Have the authors adequately addressed the limitations and potential negative societal impact of their work? If not, please include constructive suggestions for improvement.\n",
        "In general, authors should be rewarded rather than punished for being up front about the limitations of their work and any potential negative societal impact. You are encouraged to think through whether any critical points are missing and provide these as feedback for the authors.\n",
        "\n",
        "4. Ethical concerns: If there are ethical issues with this paper, please flag the paper for an ethics review. For guidance on when this is appropriate, please review the NeurIPS ethics guidelines.\n",
        "\n",
        "5. Soundness: Please assign the paper a numerical rating on the following scale to indicate the soundness of the technical claims, experimental and research methodology and on whether the central claims of the paper are adequately supported with evidence.\n",
        "  4: excellent\n",
        "  3: good\n",
        "  2: fair\n",
        "  1: poor\n",
        "\n",
        "6. Presentation: Please assign the paper a numerical rating on the following scale to indicate the quality of the presentation. This should take into account the writing style and clarity, as well as contextualization relative to prior work.\n",
        "  4: excellent\n",
        "  3: good\n",
        "  2: fair\n",
        "  1: poor\n",
        "\n",
        "7. Contribution: Please assign the paper a numerical rating on the following scale to indicate the quality of the overall contribution this paper makes to the research area being studied. Are the questions being asked important? Does the paper bring a significant originality of ideas and/or execution? Are the results valuable to share with the broader NeurIPS community.\n",
        "  4: excellent\n",
        "  3: good\n",
        "  2: fair\n",
        "  1: poor\n",
        "\n",
        "8. Overall: Please provide an \"overall score\" for this submission. Choices:\n",
        "  10: Award quality: Technically flawless paper with groundbreaking impact on one or more areas of AI, with exceptionally strong evaluation, reproducibility, and resources, and no unaddressed ethical considerations.\n",
        "  9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI and excellent impact on multiple areas of AI, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\n",
        "  8: Strong Accept: Technically strong paper with, with novel ideas, excellent impact on at least one area of AI or high-to-excellent impact on multiple areas of AI, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.\n",
        "  7: Accept: Technically solid paper, with high impact on at least one sub-area of AI or moderate-to-high impact on more than one area of AI, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.\n",
        "  6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.\n",
        "  5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.\n",
        "  4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly.\n",
        "  3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.\n",
        "  2: Strong Reject: For instance, a paper with major technical flaws, and/or poor evaluation, limited impact, poor reproducibility and mostly unaddressed ethical considerations.\n",
        "  1: Very Strong Reject: For instance, a paper with trivial results or unaddressed ethical considerations\n",
        "\n",
        "9. Confidence:  Please provide a \"confidence score\" for your assessment of this submission to indicate how confident you are in your evaluation. Choices:\n",
        "  5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\n",
        "  4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\n",
        "  3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\n",
        "  2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\n",
        "  1: Your assessment is an educated guess. The submission is not in your area or the submission was difficult to understand. Math/other details were not carefully checked.\n",
        "\"\"\"\n",
        "    + template_instructions\n",
        ")\n",
        "\n",
        "\n",
        "def perform_review(\n",
        "    text,\n",
        "    model,\n",
        "    client,\n",
        "    num_reflections=1,\n",
        "    num_fs_examples=1,\n",
        "    num_reviews_ensemble=1,\n",
        "    temperature=0.75,\n",
        "    msg_history=None,\n",
        "    return_msg_history=False,\n",
        "    reviewer_system_prompt=reviewer_system_prompt_neg,\n",
        "    review_instruction_form=neurips_form,\n",
        "):\n",
        "    if num_fs_examples > 0:\n",
        "        fs_prompt = get_review_fewshot_examples(num_fs_examples)\n",
        "        base_prompt = review_instruction_form + fs_prompt\n",
        "    else:\n",
        "        base_prompt = review_instruction_form\n",
        "\n",
        "    base_prompt += f\"\"\"\n",
        "Here is the paper you are asked to review:\n",
        "```\n",
        "{text}\n",
        "```\"\"\"\n",
        "\n",
        "    if num_reviews_ensemble > 1:\n",
        "        llm_review, msg_histories = get_batch_responses_from_llm(\n",
        "            base_prompt,\n",
        "            model=model,\n",
        "            client=client,\n",
        "            system_message=reviewer_system_prompt,\n",
        "            print_debug=False,\n",
        "            msg_history=msg_history,\n",
        "            # Higher temperature to encourage diversity.\n",
        "            temperature=0.75,\n",
        "            n_responses=num_reviews_ensemble,\n",
        "        )\n",
        "        parsed_reviews = []\n",
        "        for idx, rev in enumerate(llm_review):\n",
        "            try:\n",
        "                parsed_reviews.append(extract_json_between_markers(rev))\n",
        "            except Exception as e:\n",
        "                print(f\"Ensemble review {idx} failed: {e}\")\n",
        "        parsed_reviews = [r for r in parsed_reviews if r is not None]\n",
        "        review = get_meta_review(model, client, temperature, parsed_reviews)\n",
        "\n",
        "        # take first valid in case meta-reviewer fails\n",
        "        if review is None:\n",
        "            review = parsed_reviews[0]\n",
        "\n",
        "        # Replace numerical scores with the average of the ensemble.\n",
        "        for score, limits in [\n",
        "            (\"Originality\", (1, 4)),\n",
        "            (\"Quality\", (1, 4)),\n",
        "            (\"Clarity\", (1, 4)),\n",
        "            (\"Significance\", (1, 4)),\n",
        "            (\"Soundness\", (1, 4)),\n",
        "            (\"Presentation\", (1, 4)),\n",
        "            (\"Contribution\", (1, 4)),\n",
        "            (\"Overall\", (1, 10)),\n",
        "            (\"Confidence\", (1, 5)),\n",
        "        ]:\n",
        "            scores = []\n",
        "            for r in parsed_reviews:\n",
        "                if score in r and limits[1] >= r[score] >= limits[0]:\n",
        "                    scores.append(r[score])\n",
        "            review[score] = int(round(np.mean(scores)))\n",
        "\n",
        "        # Rewrite the message history with the valid one and new aggregated review.\n",
        "        msg_history = msg_histories[0][:-1]\n",
        "        msg_history += [\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": f\"\"\"\n",
        "THOUGHT:\n",
        "I will start by aggregating the opinions of {num_reviews_ensemble} reviewers that I previously obtained.\n",
        "\n",
        "REVIEW JSON:\n",
        "```json\n",
        "{json.dumps(review)}\n",
        "```\n",
        "\"\"\",\n",
        "            }\n",
        "        ]\n",
        "    else:\n",
        "        llm_review, msg_history = get_response_from_llm(\n",
        "            base_prompt,\n",
        "            model=model,\n",
        "            client=client,\n",
        "            system_message=reviewer_system_prompt,\n",
        "            print_debug=False,\n",
        "            msg_history=msg_history,\n",
        "            temperature=temperature,\n",
        "        )\n",
        "        review = extract_json_between_markers(llm_review)\n",
        "\n",
        "    if num_reflections > 1:\n",
        "        for j in range(num_reflections - 1):\n",
        "            # print(f\"Relection: {j + 2}/{num_reflections}\")\n",
        "            text, msg_history = get_response_from_llm(\n",
        "                reviewer_reflection_prompt,\n",
        "                client=client,\n",
        "                model=model,\n",
        "                system_message=reviewer_system_prompt,\n",
        "                msg_history=msg_history,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "            review = extract_json_between_markers(text)\n",
        "            assert review is not None, \"Failed to extract JSON from LLM output\"\n",
        "\n",
        "            if \"I am done\" in text:\n",
        "                # print(f\"Review generation converged after {j + 2} iterations.\")\n",
        "                break\n",
        "\n",
        "    if return_msg_history:\n",
        "        return review, msg_history\n",
        "    else:\n",
        "        return review\n",
        "\n",
        "\n",
        "reviewer_reflection_prompt = \"\"\"Round {current_round}/{num_reflections}.\n",
        "In your thoughts, first carefully consider the accuracy and soundness of the review you just created.\n",
        "Include any other factors that you think are important in evaluating the paper.\n",
        "Ensure the review is clear and concise, and the JSON is in the correct format.\n",
        "Do not make things overly complicated.\n",
        "In the next attempt, try and refine and improve your review.\n",
        "Stick to the spirit of the original review unless there are glaring issues.\n",
        "\n",
        "Respond in the same format as before:\n",
        "THOUGHT:\n",
        "<THOUGHT>\n",
        "\n",
        "REVIEW JSON:\n",
        "```json\n",
        "<JSON>\n",
        "```\n",
        "\n",
        "If there is nothing to improve, simply repeat the previous JSON EXACTLY after the thought and include \"I am done\" at the end of the thoughts but before the JSON.\n",
        "ONLY INCLUDE \"I am done\" IF YOU ARE MAKING NO MORE CHANGES.\"\"\"\n",
        "\n",
        "\n",
        "def load_paper(pdf_path, num_pages=None, min_size=100):\n",
        "    try:\n",
        "        if num_pages is None:\n",
        "            text = pymupdf4llm.to_markdown(pdf_path)\n",
        "        else:\n",
        "            reader = PdfReader(pdf_path)\n",
        "            min_pages = min(len(reader.pages), num_pages)\n",
        "            text = pymupdf4llm.to_markdown(pdf_path, pages=list(range(min_pages)))\n",
        "        if len(text) < min_size:\n",
        "            raise Exception(\"Text too short\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error with pymupdf4llm, falling back to pymupdf: {e}\")\n",
        "        try:\n",
        "            doc = pymupdf.open(pdf_path)  # open a document\n",
        "            if num_pages:\n",
        "                doc = doc[:num_pages]\n",
        "            text = \"\"\n",
        "            for page in doc:  # iterate the document pages\n",
        "                text = text + page.get_text()  # get plain text encoded as UTF-8\n",
        "            if len(text) < min_size:\n",
        "                raise Exception(\"Text too short\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error with pymupdf, falling back to pypdf: {e}\")\n",
        "            reader = PdfReader(pdf_path)\n",
        "            if num_pages is None:\n",
        "                text = \"\".join(page.extract_text() for page in reader.pages)\n",
        "            else:\n",
        "                text = \"\".join(page.extract_text() for page in reader.pages[:num_pages])\n",
        "            if len(text) < min_size:\n",
        "                raise Exception(\"Text too short\")\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def load_review(path):\n",
        "    with open(path, \"r\") as json_file:\n",
        "        loaded = json.load(json_file)\n",
        "    return loaded[\"review\"]\n",
        "\n",
        "\n",
        "# get directory of this file\n",
        "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "fewshot_papers = [\n",
        "    os.path.join(dir_path, \"fewshot_examples/132_automated_relational.pdf\"),\n",
        "    os.path.join(dir_path, \"fewshot_examples/attention.pdf\"),\n",
        "    os.path.join(dir_path, \"fewshot_examples/2_carpe_diem.pdf\"),\n",
        "]\n",
        "\n",
        "fewshot_reviews = [\n",
        "    os.path.join(dir_path, \"fewshot_examples/132_automated_relational.json\"),\n",
        "    os.path.join(dir_path, \"fewshot_examples/attention.json\"),\n",
        "    os.path.join(dir_path, \"fewshot_examples/2_carpe_diem.json\"),\n",
        "]\n",
        "\n",
        "\n",
        "def get_review_fewshot_examples(num_fs_examples=1):\n",
        "    fewshot_prompt = \"\"\"\n",
        "Below are some sample reviews, copied from previous machine learning conferences.\n",
        "Note that while each review is formatted differently according to each reviewer's style, the reviews are well-structured and therefore easy to navigate.\n",
        "\"\"\"\n",
        "    for paper, review in zip(\n",
        "        fewshot_papers[:num_fs_examples], fewshot_reviews[:num_fs_examples]\n",
        "    ):\n",
        "        txt_path = paper.replace(\".pdf\", \".txt\")\n",
        "        if os.path.exists(txt_path):\n",
        "            with open(txt_path, \"r\") as f:\n",
        "                paper_text = f.read()\n",
        "        else:\n",
        "            paper_text = load_paper(paper)\n",
        "        review_text = load_review(review)\n",
        "        fewshot_prompt += f\"\"\"\n",
        "Paper:\n",
        "\n",
        "```\n",
        "{paper_text}\n",
        "```\n",
        "\n",
        "Review:\n",
        "\n",
        "```\n",
        "{review_text}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "    return fewshot_prompt\n",
        "\n",
        "\n",
        "meta_reviewer_system_prompt = \"\"\"You are an Area Chair at a machine learning conference.\n",
        "You are in charge of meta-reviewing a paper that was reviewed by {reviewer_count} reviewers.\n",
        "Your job is to aggregate the reviews into a single meta-review in the same format.\n",
        "Be critical and cautious in your decision, find consensus, and respect the opinion of all the reviewers.\"\"\"\n",
        "\n",
        "\n",
        "def get_meta_review(model, client, temperature, reviews):\n",
        "    # Write a meta-review from a set of individual reviews\n",
        "    review_text = \"\"\n",
        "    for i, r in enumerate(reviews):\n",
        "        review_text += f\"\"\"\n",
        "Review {i + 1}/{len(reviews)}:\n",
        "```\n",
        "{json.dumps(r)}\n",
        "```\n",
        "\"\"\"\n",
        "    base_prompt = neurips_form + review_text\n",
        "\n",
        "    llm_review, msg_history = get_response_from_llm(\n",
        "        base_prompt,\n",
        "        model=model,\n",
        "        client=client,\n",
        "        system_message=meta_reviewer_system_prompt.format(reviewer_count=len(reviews)),\n",
        "        print_debug=False,\n",
        "        msg_history=None,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    meta_review = extract_json_between_markers(llm_review)\n",
        "    return meta_review\n",
        "\n",
        "\n",
        "def perform_improvement(review, coder):\n",
        "    improvement_prompt = '''The following review has been created for your research paper:\n",
        "\"\"\"\n",
        "{review}\n",
        "\"\"\"\n",
        "\n",
        "Improve the text using the review.'''.format(\n",
        "        review=json.dumps(review)\n",
        "    )\n",
        "    coder_out = coder.run(improvement_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "CvOIyqnfKGRY",
        "outputId": "8ca783a5-24a5-4bb9-a372-050e8b716767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ffcc24210bca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;31m# get directory of this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m fewshot_papers = [\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "\n",
        "import openai\n",
        "from ai_scientist.perform_review import load_paper, perform_review\n",
        "\n",
        "client = openai.OpenAI()\n",
        "model = \"gpt-4o-2024-05-13\"\n",
        "\n",
        "# Load paper from PDF file (raw text)\n",
        "paper_txt = load_paper(\"report.pdf\")\n",
        "\n",
        "# Get the review dictionary\n",
        "review = perform_review(\n",
        "    paper_txt,\n",
        "    model,\n",
        "    client,\n",
        "    num_reflections=5,\n",
        "    num_fs_examples=1,\n",
        "    num_reviews_ensemble=5,\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "# Inspect review results\n",
        "review[\"Overall\"]    # Overall score (1-10)\n",
        "review[\"Decision\"]   # 'Accept' or 'Reject'\n",
        "review[\"Weaknesses\"] # List of weaknesses (strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "eESbyO-uGdzd",
        "outputId": "d78f2542-cdea-4ed2-8695-5b97dd4c14be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b902e5d7aa88>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from ai_scientist.perform_review import load_paper, perform_review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-4o-2024-05-13\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1JQT0p-aJ7ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Your Own Template**\n",
        "\n",
        "If there is an area of study you would like The AI Scientist to explore, it is straightforward to create your own templates. In general, follow the structure of the existing templates, which consist of:\n",
        "\n",
        "* **experiment.py** — This is the main script where the core content is. It takes an argument --out_dir, which specifies where it should create the folder and save the relevant information from the run.\n",
        "* **plot.py** — This script takes the information from the run folders and creates plots. The code should be clear and easy to edit.\n",
        "* **prompt.json** — Put information about your template here.\n",
        "* **seed_ideas.json** — Place example ideas here. You can also try to generate ideas without any examples and then pick the best one or two to put here.\n",
        "* **latex/template.tex** — We recommend using our LaTeX folder but be sure to replace the pre-loaded citations with ones that you expect to be more relevant.\n",
        "\n",
        "The key to making new templates work is matching the base filenames and output JSONs to the existing format; everything else is free to change. You should also ensure that the template.tex file is updated to use the correct citation style / base plots for your template.\n",
        "\n",
        "## **Community-Contributed Templates**\n",
        "\n",
        "We welcome community contributions in the form of new templates. While these are not maintained by us, we are delighted to highlight your templates to others. Below, we list community-contributed templates along with links to their pull requests (PRs):\n",
        "\n",
        "* Infectious Disease Modeling (seir) - PR #137\n",
        "* Image Classification with MobileNetV3 (mobilenetV3) - PR #141\n",
        "* Sketch RNN (sketch_rnn) - PR #143\n",
        "* AI in Quantum Chemistry (MACE) - PR#157\n",
        "* Earthquake Prediction (earthquake-prediction) - PR #167\n",
        "* Tensorial Radiance Fields (tensorf) - PR #175"
      ],
      "metadata": {
        "id": "Lrja3ipvGxRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Template Resources**\n",
        "\n",
        "We provide three templates, which heavily use code from other repositories, credited below:\n",
        "\n",
        "* NanoGPT Template uses code from NanoGPT and this PR.\n",
        "* 2D Diffusion Template uses code from tiny-diffusion, ema-pytorch, and Datasaur.\n",
        "* Grokking Template uses code from Sea-Snell/grokking and danielmamay/grokking.\n",
        "\n",
        "We would like to thank the developers of the open-source models and packages for their contributions and for making their work available."
      ],
      "metadata": {
        "id": "Sv39Of2rIe3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Citing The AI Scientist**\n",
        "\n",
        "If you use The AI Scientist in your research, please cite it as follows:\n",
        "\n",
        "~~~text\n",
        "@article{lu2024aiscientist,\n",
        "  title={The {AI} {S}cientist: Towards Fully Automated Open-Ended Scientific Discovery},\n",
        "  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},\n",
        "  journal={arXiv preprint arXiv:2408.06292},\n",
        "  year={2024}\n",
        "}\n",
        "~~~"
      ],
      "metadata": {
        "id": "_sbUbaBbIRF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Frequently Asked Questions**\n",
        "\n",
        "We recommend reading our paper first for any questions you have on The AI Scientist.\n",
        "\n",
        "**Why am I missing files when running The AI Scientist?**\n",
        "\n",
        "Ensure you have completed all the setup and preparation steps before the main experiment script.\n",
        "\n",
        "**Why has a PDF or a review not been generated?**\n",
        "\n",
        "The AI Scientist finishes an idea with a success rate that depends on the template, the base foundation model, and the complexity of the idea. We advise referring to our main paper. The highest success rates are observed with Claude Sonnet 3.5. Reviews are best done with GPT-4o; all other models have issues with positivity bias or failure to conform to required outputs.\n",
        "\n",
        "**What is the cost of each idea generated?**\n",
        "\n",
        "Typically less than $15 per paper with Claude Sonnet 3.5. We recommend DeepSeek Coder V2 for a much more cost-effective approach. A good place to look for new models is the Aider leaderboard.\n",
        "\n",
        "**How do I change the base conference format associated with the write-ups?**\n",
        "\n",
        "Change the base template.tex files contained within each template.\n",
        "\n",
        "**How do I run The AI Scientist for different subject fields?**\n",
        "\n",
        "Please refer to the instructions for different templates. In this current iteration, this is restricted to ideas that can be expressed in code. However, lifting this restriction would represent exciting future work! :)\n",
        "\n",
        "**How do I add support for a new foundation model?**\n",
        "\n",
        "You may modify ai_scientist/llm.py to add support for a new foundation model. We do not advise using any model that is significantly weaker than GPT-4 level for The AI Scientist.\n",
        "\n",
        "**Why do I need to run the baseline runs myself?**\n",
        "\n",
        "These appear as run_0 and should be run per machine you execute The AI Scientist on for accurate run-time comparisons due to hardware differences.\n",
        "\n",
        "**What if I have problems accessing the Semantic Scholar API?**\n",
        "\n",
        "We use the Semantic Scholar API to check ideas for novelty and collect citations for the paper write-up. You may be able to skip these phases if you don't have an API key or the API is slow to access."
      ],
      "metadata": {
        "id": "9SlzF8PiHpXp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "18orCxP4IEio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}